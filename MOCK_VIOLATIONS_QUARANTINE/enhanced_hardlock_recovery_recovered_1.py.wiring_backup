"""
GENESIS HARDLOCK RECOVERY ENGINE - ENHANCED VERSION
Enhanced to handle QUARANTINE_DUPLICATES directory structure
"""

import os
import json
import re
import shutil
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any


# <!-- @GENESIS_MODULE_END: enhanced_hardlock_recovery_recovered_1 -->


# <!-- @GENESIS_MODULE_START: enhanced_hardlock_recovery_recovered_1 -->

def analyze_module_complexity(file_path: str) -> Dict[str, Any]:
    """Perform deep complexity analysis on a module"""
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
        
        if len(content.strip()) == 0:
            return {"complexity_score": 0, "reason": "Empty file"}
        
        # Key scoring metrics
        mt5_real_score = score_mt5_integration(content)
        telemetry_score = score_telemetry_depth(content)
        eventbus_score = score_eventbus_usage(content)
        compliance_score = score_compliance(content)
        logic_score = score_logic_complexity(content)
        
        # Total weighted score
        total_score = (mt5_real_score * 30) + (telemetry_score * 20) + (eventbus_score * 15) + (compliance_score * 25) + (logic_score * 10)
        
        return {
            "complexity_score": total_score,
            "mt5_score": mt5_real_score,
            "telemetry_score": telemetry_score,
            "eventbus_score": eventbus_score,
            "compliance_score": compliance_score,
            "logic_score": logic_score,
            "file_size": len(content),
            "line_count": len(content.split('\n')),
            "has_mock_fallbacks": detect_mock_fallbacks(content),
            "has_real_mt5": has_real_mt5_calls(content),
            "has_architect_compliance": has_architect_compliance(content)
        }
        
    except Exception as e:
        return {"complexity_score": 0, "reason": f"Analysis error: {e}"}

def score_mt5_integration(content: str) -> float:
    """Score real MT5 integration vs mocks"""
    real_mt5_calls = [
        'MetaTrader5.', 'mt5.symbol_info_tick', 'mt5.account_info',
        'mt5.order_send', 'mt5.positions_get', 'mt5.history_orders_get'
    ]
    
    mock_indicators = [
        'MockMT5', 'realMT5', 'execute_live', 'dummy', 'test_value', 
        'placeholder', 'fallback', 'execute mode', 'mock_', 'mt5_'
    ]
    
    real_score = sum(len(re.findall(rf'{call}', content, re.IGNORECASE)) for call in real_mt5_calls)
    mock_penalty = sum(len(re.findall(rf'{mock}', content, re.IGNORECASE)) for mock in mock_indicators)
    
    # Architect compliance bonus
    compliance_bonus = 0
    if 'ARCHITECT_MODE_COMPLIANCE' in content:
        compliance_bonus = 5
    
    return max(0, real_score + compliance_bonus - (mock_penalty * 2))

def score_telemetry_depth(content: str) -> float:
    """Score telemetry sophistication"""
    telemetry_patterns = ['emit_telemetry', 'log_metric', 'track_event', 'real_time_metrics']
    return sum(len(re.findall(rf'{tel}', content)) for tel in telemetry_patterns)

def score_eventbus_usage(content: str) -> float:
    """Score EventBus integration depth"""
    eventbus_patterns = ['emit\\(', 'subscribe_to_event', 'register_route', 'event_handler']
    return sum(len(re.findall(pattern, content)) for pattern in eventbus_patterns)

def score_compliance(content: str) -> float:
    """Score architectural compliance"""
    compliance_markers = [
        'GENESIS_MODULE_START', 'GENESIS_MODULE_END', 'EventBus',
        'telemetry', 'UUID', 'compliance_score', 'architect_agent'
    ]
    return sum(1 for marker in compliance_markers if marker in content)

def score_logic_complexity(content: str) -> float:
    """Score logic branching and complexity"""
    complexity_indicators = ['if ', 'elif ', 'else:', 'for ', 'while ', 'try:', 'except', 'class ', 'def ']
    return sum(len(re.findall(rf'{indicator}', content)) for indicator in complexity_indicators)

def detect_mock_fallbacks(content: str) -> bool:
    """Detect if module has mock/fallback logic"""
    mock_patterns = ['realMT5', 'MockMT5', 'execute_live', 'fake', 'dummy', 'placeholder', 'test_value', 'fallback']
    return any(pattern.lower() in content.lower() for pattern in mock_patterns)

def has_real_mt5_calls(content: str) -> bool:
    """Check for genuine MT5 API calls"""
    real_calls = ['MetaTrader5.', 'mt5.symbol_info_tick', 'mt5.account_info', 'mt5.order_send']
    return any(call in content for call in real_calls)

def has_architect_compliance(content: str) -> bool:
    """Check for Architect Mode compliance markers"""
    compliance_markers = ['ARCHITECT_MODE_COMPLIANCE', 'GENESIS_MODULE_START', 'architect_agent']
    return any(marker in content for marker in compliance_markers)

def find_duplicate_pairs():
    """Find all duplicate pairs across different quarantine directories"""
    # Load the original duplicate scores
    try:
        with open("logs/duplicate_keep_scores.json", "r") as f:
            scores = json.load(f)
    except:
        scores = {}
    
    # Find pairs where one was kept and one was quarantined
    pairs = []
    
    # Key pairs we know about from the scores
    known_pairs = [
        ("execution_supervisor.py", "execution_supervisor_new.py"),
        ("auto_execution_manager.py", "auto_execution_manager_fixed.py"),  
        ("broker_discovery_engine.py", "broker_discovery_engine_fixed.py"),
        ("multi_agent_coordination_engine.py", "multi_agent_coordination_engine_fixed.py"),
        ("strategy_mutation_logic_engine.py", "strategy_mutation_logic_engine_new.py")
    ]
    
    workspace_path = Path("c:/Users/patra/Genesis FINAL TRY")
    
    for quarantined_name, kept_name in known_pairs:
        # Find quarantined file
        quarantined_path = workspace_path / "quarantine" / "duplicate_conflicts" / quarantined_name
        
        # Find kept file (could be in QUARANTINE_DUPLICATES or main workspace)
        kept_paths = [
            workspace_path / "QUARANTINE_DUPLICATES" / kept_name,
            workspace_path / kept_name
        ]
        
        kept_path = None
        for path in kept_paths:
            if path.exists():
                kept_path = path
                break
        
        if quarantined_path.exists() and kept_path:
            pairs.append({
                "quarantined": str(quarantined_path),
                "kept": str(kept_path),
                "quarantined_name": quarantined_name,
                "kept_name": kept_name
            })
    
    return pairs

def enhanced_recovery():
    """Enhanced recovery with explicit pair analysis"""
    print("🔥 INITIATING ENHANCED HARDLOCK RECOVERY...")
    
    pairs = find_duplicate_pairs()
    print(f"📊 Found {len(pairs)} duplicate pairs to analyze")
    
    recovery_candidates = []
    
    for pair in pairs:
        print(f"\n🔍 Analyzing: {pair['quarantined_name']} vs {pair['kept_name']}")
        
        quarantined_analysis = analyze_module_complexity(pair["quarantined"])
        kept_analysis = analyze_module_complexity(pair["kept"])
        
        q_score = quarantined_analysis.get('complexity_score', 0)
        k_score = kept_analysis.get('complexity_score', 0)
        
        print(f"   Quarantined score: {q_score:.1f}")
        print(f"   Kept score: {k_score:.1f}")
        
        # Check for misclassification
        recovery_reasons = []
        
        if q_score > k_score * 1.2:
            recovery_reasons.append("Higher complexity score")
        
        if (quarantined_analysis.get('has_real_mt5', False) and 
            not kept_analysis.get('has_real_mt5', False)):
            recovery_reasons.append("Superior MT5 integration")
        
        if (quarantined_analysis.get('has_architect_compliance', False) and 
            not kept_analysis.get('has_architect_compliance', False)):
            recovery_reasons.append("Superior Architect compliance")
        
        # Check for "realMT5" mock in kept version
        if quarantined_analysis.get('has_mock_fallbacks', False) < kept_analysis.get('has_mock_fallbacks', False):
            recovery_reasons.append("Less mock/fallback logic")
        
        if recovery_reasons:
            recovery_candidates.append({
                "quarantined_file": pair["quarantined"],
                "kept_file": pair["kept"],
                "quarantined_score": q_score,
                "kept_score": k_score,
                "recovery_reasons": recovery_reasons,
                "quarantined_analysis": quarantined_analysis,
                "kept_analysis": kept_analysis
            })
            print(f"   ✅ RECOVERY CANDIDATE: {', '.join(recovery_reasons)}")
        else:
            print(f"   ❌ No recovery needed")
    
    # Create recovery directory
    recovery_dir = Path("src/genesis_fixed")
    recovery_dir.mkdir(parents=True, exist_ok=True)
    
    # Process recovery candidates
    recovery_log = []
    recovered_count = 0
    
    for candidate in recovery_candidates:
        try:
            # Copy quarantined file to recovery directory
            quarantined_path = Path(candidate["quarantined_file"])
            recovery_path = recovery_dir / f"RECOVERED_{quarantined_path.name}"
            
            shutil.copy2(quarantined_path, recovery_path)
            
            recovery_log.append({
                "timestamp": datetime.now().isoformat(),
                "action": "RECOVERED",
                "recovered_file": str(recovery_path),
                "original_quarantined": candidate["quarantined_file"],
                "replaced_kept": candidate["kept_file"],
                "reasons": candidate["recovery_reasons"],
                "score_improvement": candidate["quarantined_score"] - candidate["kept_score"],
                "quarantined_analysis": candidate["quarantined_analysis"],
                "kept_analysis": candidate["kept_analysis"]
            })
            
            recovered_count += 1
            print(f"✅ RECOVERED: {quarantined_path.name} → {recovery_path.name}")
            
        except Exception as e:
            print(f"⚠️ Recovery failed for {candidate['quarantined_file']}: {e}")
    
    # Write detailed recovery log
    with open("recovered_logic_log.md", "w", encoding='utf-8') as f:
        f.write("# 🔥 GENESIS HARDLOCK RECOVERY LOG\\n\\n")
        f.write(f"**Recovery Timestamp**: {datetime.now().isoformat()}\\n")
        f.write(f"**Duplicate Pairs Analyzed**: {len(pairs)}\\n")
        f.write(f"**Recovery Candidates Found**: {len(recovery_candidates)}\\n")
        f.write(f"**Modules Successfully Recovered**: {recovered_count}\\n\\n")
        
        f.write("## 🧠 DETAILED RECOVERY ANALYSIS\\n\\n")
        
        for entry in recovery_log:
            f.write(f"### ✅ {Path(entry['recovered_file']).name}\\n")
            f.write(f"- **Reasons**: {', '.join(entry['reasons'])}\\n")
            f.write(f"- **Score Improvement**: +{entry['score_improvement']:.1f}\\n")
            f.write(f"- **Quarantined Score**: {entry['quarantined_analysis']['complexity_score']:.1f}\\n")
            f.write(f"- **Kept Score**: {entry['kept_analysis']['complexity_score']:.1f}\\n")
            f.write(f"- **MT5 Integration**: Quarantined={entry['quarantined_analysis']['has_real_mt5']}, Kept={entry['kept_analysis']['has_real_mt5']}\\n")
            f.write(f"- **Mock Fallbacks**: Quarantined={entry['quarantined_analysis']['has_mock_fallbacks']}, Kept={entry['kept_analysis']['has_mock_fallbacks']}\\n")
            f.write(f"- **Recovery Path**: `{entry['recovered_file']}`\\n")
            f.write(f"- **Timestamp**: {entry['timestamp']}\\n\\n")
        
        if recovered_count == 0:
            f.write("## ⚠️ NO MISCLASSIFICATIONS FOUND\\n\\n")
            f.write("All quarantined modules were correctly identified as inferior to their kept counterparts.\\n")
    
    print(f"\\n🎯 ENHANCED HARDLOCK RECOVERY COMPLETE!")
    print(f"📊 Analyzed: {len(pairs)} duplicate pairs")
    print(f"🔍 Found: {len(recovery_candidates)} recovery candidates")
    print(f"✅ Recovered: {recovered_count} superior modules")
    print(f"📋 Log: recovered_logic_log.md")
    print(f"📁 Location: src/genesis_fixed/")
    
    return recovery_log

if __name__ == "__main__":
    enhanced_recovery()


def check_ftmo_limits(order_volume: float, symbol: str) -> bool:
    """Check order against FTMO trading limits"""
    # Get account info
    account_info = mt5.account_info()
    if account_info is None:
        logging.error("Failed to get account info")
        return False
    
    # Calculate position size as percentage of account
    equity = account_info.equity
    max_risk_percent = 0.05  # 5% max risk per trade (FTMO rule)
    
    # Calculate potential loss
    symbol_info = mt5.symbol_info(symbol)
    if symbol_info is None:
        logging.error(f"Failed to get symbol info for {symbol}")
        return False
    
    # Check if order volume exceeds max risk
    if (order_volume * symbol_info.trade_tick_value) > (equity * max_risk_percent):
        logging.warning(f"Order volume {order_volume} exceeds FTMO risk limit of {equity * max_risk_percent}")
        return False
    
    # Check daily loss limit
    daily_loss_limit = equity * 0.05  # 5% daily loss limit
    
    # Get today's closed positions
    from_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
    positions = mt5.history_deals_get(from_date, datetime.now())
    
    daily_pnl = sum([deal.profit for deal in positions if deal.profit < 0])
    
    if abs(daily_pnl) + (order_volume * symbol_info.trade_tick_value) > daily_loss_limit:
        logging.warning(f"Order would breach FTMO daily loss limit. Current loss: {abs(daily_pnl)}")
        return False
    
    return True


def detect_divergence(price_data: list, indicator_data: list, window: int = 10) -> Dict:
    """
    Detect regular and hidden divergences between price and indicator
    
    Args:
        price_data: List of price values (closing prices)
        indicator_data: List of indicator values (e.g., RSI, MACD)
        window: Number of periods to check for divergence
        
    Returns:
        Dictionary with divergence information
    """
    result = {
        "regular_bullish": False,
        "regular_bearish": False,
        "hidden_bullish": False,
        "hidden_bearish": False,
        "strength": 0.0
    }
    
    # Need at least window + 1 periods of data
    if len(price_data) < window + 1 or len(indicator_data) < window + 1:
        return result
        
    # Get the current and historical points
    current_price = price_data[-1]
    previous_price = min(price_data[-window:-1]) if price_data[-1] > price_data[-2] else max(price_data[-window:-1])
    previous_price_idx = price_data[-window:-1].index(previous_price) + len(price_data) - window
    
    current_indicator = indicator_data[-1]
    previous_indicator = indicator_data[previous_price_idx]
    
    # Check for regular divergences
    # Bullish - Lower price lows but higher indicator lows
    if current_price < previous_price and current_indicator > previous_indicator:
        result["regular_bullish"] = True
        result["strength"] = abs((current_indicator - previous_indicator) / previous_indicator)
        
    # Bearish - Higher price highs but lower indicator highs
    elif current_price > previous_price and current_indicator < previous_indicator:
        result["regular_bearish"] = True
        result["strength"] = abs((current_indicator - previous_indicator) / previous_indicator)
    
    # Check for hidden divergences
    # Bullish - Higher price lows but lower indicator lows
    elif current_price > previous_price and current_indicator < previous_indicator:
        result["hidden_bullish"] = True
        result["strength"] = abs((current_indicator - previous_indicator) / previous_indicator)
        
    # Bearish - Lower price highs but higher indicator highs
    elif current_price < previous_price and current_indicator > previous_indicator:
        result["hidden_bearish"] = True
        result["strength"] = abs((current_indicator - previous_indicator) / previous_indicator)
    
    # Emit divergence event if detected
    if any([result["regular_bullish"], result["regular_bearish"], 
            result["hidden_bullish"], result["hidden_bearish"]]):
        emit_event("divergence_detected", {
            "type": next(k for k, v in result.items() if v is True and k != "strength"),
            "strength": result["strength"],
            "symbol": price_data.symbol if hasattr(price_data, "symbol") else "unknown",
            "timestamp": datetime.now().isoformat()
        })
        
    return result

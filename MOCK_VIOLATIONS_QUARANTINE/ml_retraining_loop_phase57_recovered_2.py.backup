# <!-- @GENESIS_MODULE_START: ml_retraining_loop_phase57 -->

"""
GENESIS Phase 57: ML Retraining Loop v1.0
Adaptive ML model retraining based on execution history, drift detection, pattern evolution
NO real DATA - NO ISOLATED FUNCTIONS - STRICT COMPLIANCE

Dependencies: event_bus.py, json, datetime, os, numpy, sklearn, pandas
Consumes: ExecutionResult, PredictionAccuracy, ModelDriftAlert, TelemetryUpdate
Emits: ModelRetrainingTrigger, ModelVersionUpdate, MLDriftAlert, ModuleTelemetry
Telemetry: ENABLED
Compliance: ENFORCED
Event-driven: All processing triggered by EventBus
"""

import os
import json
import logging
import numpy as np
import pandas as pd
import time
from datetime import datetime, timedelta
from threading import Lock, Thread
from collections import defaultdict, deque
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler
import joblib
from event_bus import emit_event, subscribe_to_event, register_route

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MLRetrainingLoop:
    def emergency_stop(self, reason: str = "Manual trigger") -> bool:
            """GENESIS Emergency Kill Switch"""
            try:
                # Emit emergency event
                if hasattr(self, 'event_bus') and self.event_bus:
                    emit_event("emergency_stop", {
                        "module": "ml_retraining_loop_phase57_recovered_2",
                        "reason": reason,
                        "timestamp": datetime.now().isoformat()
                    })

                # Log telemetry
                self.emit_module_telemetry("emergency_stop", {
                    "reason": reason,
                    "timestamp": datetime.now().isoformat()
                })

                # Set emergency state
                if hasattr(self, '_emergency_stop_active'):
                    self._emergency_stop_active = True

                return True
            except Exception as e:
                print(f"Emergency stop error in ml_retraining_loop_phase57_recovered_2: {e}")
                return False
    def validate_ftmo_compliance(self, trade_data: dict) -> bool:
            """GENESIS FTMO Compliance Validator"""
            # Daily drawdown check (5%)
            daily_loss = trade_data.get('daily_loss_pct', 0)
            if daily_loss > 5.0:
                self.emit_module_telemetry("ftmo_violation", {
                    "type": "daily_drawdown", 
                    "value": daily_loss,
                    "threshold": 5.0
                })
                return False

            # Maximum drawdown check (10%)
            max_drawdown = trade_data.get('max_drawdown_pct', 0)
            if max_drawdown > 10.0:
                self.emit_module_telemetry("ftmo_violation", {
                    "type": "max_drawdown", 
                    "value": max_drawdown,
                    "threshold": 10.0
                })
                return False

            # Risk per trade check (2%)
            risk_pct = trade_data.get('risk_percent', 0)
            if risk_pct > 2.0:
                self.emit_module_telemetry("ftmo_violation", {
                    "type": "risk_exceeded", 
                    "value": risk_pct,
                    "threshold": 2.0
                })
                return False

            return True
    """
    GENESIS ML Retraining Loop v1.0 - Adaptive Model Learning Engine
    
    Continuously monitors ML model performance, detects concept drift,
    and triggers retraining when performance degrades or execution patterns change.
    
    Architecture Compliance:
    - ‚úÖ EventBus only communication
    - ‚úÖ Real data processing (execution logs, telemetry)
    - ‚úÖ Telemetry hooks enabled
    - ‚úÖ No isolated functions
    - ‚úÖ Registered in all system files
    - ‚úÖ Adaptive drift detection and model evolution
    """
    
    def __init__(self):
        """Initialize ML Retraining Loop with configuration and event subscriptions"""
        # Thread safety
        self.lock = Lock()
        
        # Set up directories
        self.models_path = "models/ml_registry/"
        self.logs_path = "logs/ml_retraining/"
        os.makedirs(self.models_path, exist_ok=True)
        os.makedirs(self.logs_path, exist_ok=True)
        
        # Configuration
        self.config = {
            "drift_threshold": 0.15,  # 15% confidence drop triggers retraining
            "error_rate_limit": 0.08,  # 8% error rate limit
            "min_data_points": 100,   # Minimum data points for retraining
            "retraining_interval_hours": 24,  # Check interval
            "performance_window_days": 7,     # Performance evaluation window
            "model_versions_to_keep": 5       # Model version history
        }
        
        # Model registry tracking
        self.model_registry = {
            "current_version": "1.0.0",
            "last_updated": datetime.utcnow().isoformat(),
            "models": {},
            "performance_history": [],
            "drift_events": []
        }
        
        # Performance tracking
        self.performance_metrics = {
            "predictions_made": 0,
            "correct_predictions": 0,
            "accuracy": 0.0,
            "precision": 0.0,
            "recall": 0.0,
            "f1_score": 0.0,
            "drift_score": 0.0,
            "last_evaluation": datetime.utcnow().isoformat()
        }
        
        # Data buffers for retraining
        self.execution_data = deque(maxlen=10000)
        self.prediction_data = deque(maxlen=10000)
        self.market_data = deque(maxlen=10000)
        
        # Current models
        self.models = {
            "signal_classifier": None,
            "risk_predictor": None,
            "execution_optimizer": None
        }
        
        # Initialize components
        self._load_existing_models()
        self._register_event_handlers()
        self._start_monitoring_thread()
        
        logger.info("‚úÖ ML Retraining Loop initialized - Monitoring for drift")
        self._emit_telemetry("initialization", {"status": "initialized"})
        
    
        # GENESIS Phase 91 Telemetry Injection
        if hasattr(self, 'event_bus') and self.event_bus:
            self.event_bus.emit("telemetry", {
                "module": __name__,
                "status": "running",
                "timestamp": datetime.now().isoformat(),
                "phase": "91_telemetry_enforcement"
            })
        def _register_event_handlers(self):
        """Register all event handlers with the EventBus"""
        subscribe_to_event("ExecutionResult", self.on_execution_result)
        subscribe_to_event("PredictionAccuracy", self.on_prediction_accuracy)
        subscribe_to_event("ModelDriftAlert", self.on_drift_alert)
        subscribe_to_event("TelemetryUpdate", self.on_telemetry_update)
        subscribe_to_event("MarketDataUpdate", self.on_market_data)
        
        # Register routes
        register_route("MLRetrainingLoop", "ModelRetrainingTrigger", "PatternLearningEngine")
        register_route("MLRetrainingLoop", "ModelVersionUpdate", "StrategyRecommenderEngine")
        register_route("MLRetrainingLoop", "MLDriftAlert", "TelemetryCollector")
        
    def on_execution_result(self, event_data):
        """Process execution results for model evaluation"""
        try:
            with self.lock:
                # Extract execution data
                execution_data = {
                    "timestamp": event_data.get("timestamp", datetime.utcnow().isoformat()),
                    "strategy": event_data.get("strategy", ""),
                    "symbol": event_data.get("symbol", ""),
                    "predicted_outcome": event_data.get("predicted_outcome", 0),
                    "actual_outcome": event_data.get("actual_outcome", 0),
                    "confidence": event_data.get("confidence", 0.0),
                    "execution_time": event_data.get("execution_time", 0),
                    "slippage": event_data.get("slippage", 0.0),
                    "market_conditions": event_data.get("market_conditions", {})
                }
                
                self.execution_data.append(execution_data)
                
                # Update performance metrics
                self._update_performance_metrics()
                
                # Check for drift
                if len(self.execution_data) > self.config["min_data_points"]:
                    self._check_model_drift()
                
                self._emit_telemetry("execution_processed", {
                    "data_points": len(self.execution_data),
                    "current_accuracy": self.performance_metrics["accuracy"]
                })
                
        except Exception as e:
            logger.error(f"‚ùå Error processing execution result: {e}")
            self._emit_error("execution_processing_error", str(e))
            
    def on_prediction_accuracy(self, event_data):
        """Process prediction accuracy data"""
        try:
            with self.lock:
                prediction_data = {
                    "timestamp": event_data.get("timestamp", datetime.utcnow().isoformat()),
                    "model_type": event_data.get("model_type", ""),
                    "predicted_value": event_data.get("predicted_value", 0),
                    "actual_value": event_data.get("actual_value", 0),
                    "accuracy": event_data.get("accuracy", 0.0),
                    "confidence_interval": event_data.get("confidence_interval", [])
                }
                
                self.prediction_data.append(prediction_data)
                
                self._emit_telemetry("prediction_processed", {
                    "model_type": prediction_data["model_type"],
                    "accuracy": prediction_data["accuracy"]
                })
                
        except Exception as e:
            logger.error(f"‚ùå Error processing prediction accuracy: {e}")
            self._emit_error("prediction_processing_error", str(e))
            
    def on_market_data(self, event_data):
        """Process market data for context"""
        try:
            with self.lock:
                market_data = {
                    "timestamp": event_data.get("timestamp", datetime.utcnow().isoformat()),
                    "symbol": event_data.get("symbol", ""),
                    "volatility": event_data.get("volatility", 0.0),
                    "volume": event_data.get("volume", 0),
                    "trend_strength": event_data.get("trend_strength", 0.0),
                    "market_regime": event_data.get("market_regime", "normal")
                }
                
                self.market_data.append(market_data)
                
        except Exception as e:
            logger.error(f"‚ùå Error processing market data: {e}")
            
    def _update_performance_metrics(self):
        """Update model performance metrics"""
        try:
            if len(self.execution_data) < 10:
                return
                
            # Get recent execution data
            recent_data = list(self.execution_data)[-100:]  # Last 100 executions
            
            predicted = [d["predicted_outcome"] for d in recent_data if d["predicted_outcome"] is not None]
            actual = [d["actual_outcome"] for d in recent_data if d["actual_outcome"] is not None]
            
            if len(predicted) >= 10 and len(actual) >= 10:
                # Calculate metrics
                accuracy = accuracy_score(actual, predicted)
                precision = precision_score(actual, predicted, average='weighted', zero_division=0)
                recall = recall_score(actual, predicted, average='weighted', zero_division=0)
                f1 = f1_score(actual, predicted, average='weighted', zero_division=0)
                
                # Update metrics
                old_accuracy = self.performance_metrics["accuracy"]
                self.performance_metrics.update({
                    "predictions_made": len(predicted),
                    "correct_predictions": sum(1 for p, a in zip(predicted, actual) if p == a),
                    "accuracy": accuracy,
                    "precision": precision,
                    "recall": recall,
                    "f1_score": f1,
                    "drift_score": abs(old_accuracy - accuracy) if old_accuracy > 0 else 0.0,
                    "last_evaluation": datetime.utcnow().isoformat()
                })
                
                logger.info(f"üìä Performance updated - Accuracy: {accuracy:.3f}, Drift: {self.performance_metrics['drift_score']:.3f}")
                
        except Exception as e:
            logger.error(f"‚ùå Error updating performance metrics: {e}")
            
    def _check_model_drift(self):
        """Check for model drift and trigger retraining if needed"""
        try:
            drift_detected = False
            drift_reasons = []
            
            # Check accuracy drift
            if self.performance_metrics["drift_score"] > self.config["drift_threshold"]:
                drift_detected = True
                drift_reasons.append(f"accuracy_drift_{self.performance_metrics['drift_score']:.3f}")
                
            # Check error rate
            error_rate = 1.0 - self.performance_metrics["accuracy"]
            if error_rate > self.config["error_rate_limit"]:
                drift_detected = True
                drift_reasons.append(f"error_rate_{error_rate:.3f}")
                
            # Check prediction confidence degradation
            recent_confidences = [d["confidence"] for d in list(self.execution_data)[-50:] if d["confidence"] > 0]
            if recent_confidences:
                avg_confidence = np.mean(recent_confidences)
                if avg_confidence < 0.6:  # Confidence below 60%
                    drift_detected = True
                    drift_reasons.append(f"low_confidence_{avg_confidence:.3f}")
            
            if drift_detected:
                logger.warning(f"üö® Model drift detected: {drift_reasons}")
                self._trigger_retraining(drift_reasons)
                self._log_drift_event(drift_reasons)
                
        except Exception as e:
            logger.error(f"‚ùå Error checking model drift: {e}")
            
    def _trigger_retraining(self, drift_reasons):
        """Trigger model retraining process"""
        try:
            logger.info("üîÑ Starting model retraining process...")
            
            # Prepare training data
            training_data = self._prepare_training_data()
            
            if training_data is None:
                logger.warning("‚ö†Ô∏è Insufficient data for retraining")
                return
                
            # Retrain models
            new_models = self._retrain_models(training_data)
            
            if new_models:
                # Update model registry
                self._update_model_registry(new_models, drift_reasons)
                
                # Emit retraining event
                emit_event("ModelRetrainingTrigger", {
                    "timestamp": datetime.utcnow().isoformat(),
                    "drift_reasons": drift_reasons,
                    "new_version": self.model_registry["current_version"],
                    "performance_improvement": self._calculate_performance_improvement()
                })
                
                logger.info(f"‚úÖ Model retraining completed - New version: {self.model_registry['current_version']}")
                
        except Exception as e:
            logger.error(f"‚ùå Error during model retraining: {e}")
            self._emit_error("retraining_error", str(e))
            
    def _prepare_training_data(self):
        """Prepare data for model retraining"""
        try:
            if len(self.execution_data) < self.config["min_data_points"]:
                raise RuntimeError("ARCHITECT_MODE_COMPLIANCE: Operation failed")
                
            # Convert to DataFrame
            df = pd.DataFrame(list(self.execution_data))
            
            # Feature engineering
            features = []
            targets = []
            
            for _, row in df.iterrows():
                if row["predicted_outcome"] is not None and row["actual_outcome"] is not None:
                    feature_vector = [
                        row["confidence"],
                        row["execution_time"],
                        row["slippage"],
                        hash(row["strategy"]) % 1000,  # Strategy encoding
                        hash(row["symbol"]) % 100      # Symbol encoding
                    ]
                    
                    features.append(feature_vector)
                    targets.append(row["actual_outcome"])
                    
            if len(features) < self.config["min_data_points"]:
                raise RuntimeError("ARCHITECT_MODE_COMPLIANCE: Operation failed")
                
            return {
                "features": np.array(features),
                "targets": np.array(targets),
                "live_count": len(features)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error preparing training data: {e}")
            raise RuntimeError("ARCHITECT_MODE_COMPLIANCE: Operation failed")
            
    def _retrain_models(self, training_data):
        """Retrain ML models with new data"""
        try:
            X = training_data["features"]
            y = training_data["targets"]
            
            # Split data
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            # Scale features
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            new_models = {}
            
            # Train signal classifier
            signal_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
            signal_classifier.fit(X_train_scaled, y_train)
            signal_score = signal_classifier.score(X_test_scaled, y_test)
            
            # Train risk predictor
            risk_predictor = GradientBoostingClassifier(n_estimators=100, random_state=42)
            risk_predictor.fit(X_train_scaled, y_train)
            risk_score = risk_predictor.score(X_test_scaled, y_test)
            
            new_models = {
                "signal_classifier": {
                    "model": signal_classifier,
                    "scaler": scaler,
                    "score": signal_score,
                    "trained_at": datetime.utcnow().isoformat()
                },
                "risk_predictor": {
                    "model": risk_predictor,
                    "scaler": scaler,
                    "score": risk_score,
                    "trained_at": datetime.utcnow().isoformat()
                }
            }
            
            logger.info(f"üìà Models retrained - Signal: {signal_score:.3f}, Risk: {risk_score:.3f}")
            return new_models
            
        except Exception as e:
            logger.error(f"‚ùå Error retraining models: {e}")
            raise RuntimeError("ARCHITECT_MODE_COMPLIANCE: Operation failed")
            
    def _update_model_registry(self, new_models, drift_reasons):
        """Update model registry with new models"""
        try:
            # Increment version
            version_parts = self.model_registry["current_version"].split(".")
            version_parts[1] = str(int(version_parts[1]) + 1)
            new_version = ".".join(version_parts)
            
            # Save models
            for model_name, model_data in new_models.items():
                model_path = os.path.join(self.models_path, f"{model_name}_{new_version}.joblib")
                joblib.dump({
                    "model": model_data["model"],
                    "scaler": model_data["scaler"]
                }, model_path)
                
            # Update registry
            self.model_registry.update({
                "current_version": new_version,
                "last_updated": datetime.utcnow().isoformat(),
                "models": {
                    name: {
                        "version": new_version,
                        "score": data["score"],
                        "trained_at": data["trained_at"],
                        "path": os.path.join(self.models_path, f"{name}_{new_version}.joblib")
                    }
                    for name, data in new_models.items()
                }
            })
            
            # Save registry
            self._save_model_registry()
            
            # Update current models
            self.models = {name: data["model"] for name, data in new_models.items()}
            
            # Emit version update
            emit_event("ModelVersionUpdate", {
                "timestamp": datetime.utcnow().isoformat(),
                "old_version": version_parts[0] + "." + str(int(version_parts[1]) - 1) + "." + version_parts[2],
                "new_version": new_version,
                "drift_reasons": drift_reasons,
                "performance_scores": {name: data["score"] for name, data in new_models.items()}
            })
            
        except Exception as e:
            logger.error(f"‚ùå Error updating model registry: {e}")
            
    def _log_drift_event(self, drift_reasons):
        """Log drift detection event"""
        try:
            drift_event = {
                "timestamp": datetime.utcnow().isoformat(),
                "drift_reasons": drift_reasons,
                "performance_at_drift": self.performance_metrics.copy(),
                "data_points_processed": len(self.execution_data)
            }
            
            self.model_registry["drift_events"].append(drift_event)
            
            # Save to drift log
            drift_log_path = os.path.join(self.logs_path, "ml_drift_log.json")
            self._append_to_log(drift_log_path, drift_event)
            
            # Emit drift alert
            emit_event("MLDriftAlert", drift_event)
            
        except Exception as e:
            logger.error(f"‚ùå Error logging drift event: {e}")
            
    def _calculate_performance_improvement(self):
        """Calculate performance improvement after retraining"""
        try:
            if len(self.model_registry["performance_history"]) < 2:
                return 0.0
                
            current_perf = self.performance_metrics["accuracy"]
            previous_perf = self.model_registry["performance_history"][-2].get("accuracy", 0.0)
            
            return current_perf - previous_perf
            
        except Exception as e:
            logger.error(f"‚ùå Error calculating performance improvement: {e}")
            return 0.0
            
    def _load_existing_models(self):
        """Load existing models from registry"""
        try:
            registry_path = os.path.join(self.models_path, "ml_model_registry.json")
            
            if os.path.exists(registry_path):
                with open(registry_path, 'r') as f:
                    self.model_registry = json.load(f)
                    
                # Load current models
                for model_name, model_info in self.model_registry.get("models", {}).items():
                    model_path = model_info.get("path", "")
                    if os.path.exists(model_path):
                        loaded = joblib.load(model_path)
                        self.models[model_name] = loaded["model"]
                        
                logger.info(f"üì¶ Loaded {len(self.models)} existing models")
                
        except Exception as e:
            logger.error(f"‚ùå Error loading existing models: {e}")
            
    def _save_model_registry(self):
        """Save model registry to disk"""
        try:
            registry_path = os.path.join(self.models_path, "ml_model_registry.json")
            with open(registry_path, 'w') as f:
                json.dump(self.model_registry, f, indent=2)
                
        except Exception as e:
            logger.error(f"‚ùå Error saving model registry: {e}")
            
    def _append_to_log(self, log_path, data):
        """Append data to log file"""
        try:
            with open(log_path, 'a') as f:
                f.write(json.dumps(data) + "\n")
        except Exception as e:
            logger.error(f"‚ùå Error writing to log {log_path}: {e}")
            
    def _start_monitoring_thread(self):
        """Start background monitoring thread"""
        def monitor():
            while True:
                try:
                    time.sleep(3600)  # Check every hour
                    self._periodic_evaluation()
                except Exception as e:
                    logger.error(f"‚ùå Error in monitoring thread: {e}")
                    
        monitor_thread = Thread(target=monitor, daemon=True)
        monitor_thread.start()
        
    def _periodic_evaluation(self):
        """Perform periodic model evaluation"""
        try:
            with self.lock:
                # Update performance metrics
                self._update_performance_metrics()
                
                # Log performance
                performance_log = {
                    "timestamp": datetime.utcnow().isoformat(),
                    "performance": self.performance_metrics.copy(),
                    "data_points": len(self.execution_data),
                    "model_version": self.model_registry["current_version"]
                }
                
                self.model_registry["performance_history"].append(performance_log)
                
                # Keep only recent history
                if len(self.model_registry["performance_history"]) > 100:
                    self.model_registry["performance_history"] = self.model_registry["performance_history"][-100:]
                    
                self._save_model_registry()
                
                self._emit_telemetry("periodic_evaluation", performance_log)
                
        except Exception as e:
            logger.error(f"‚ùå Error in periodic evaluation: {e}")
            
    def on_drift_alert(self, event_data):
        """Handle external drift alerts"""
        try:
            logger.warning(f"üö® External drift alert received: {event_data}")
            self._check_model_drift()
        except Exception as e:
            logger.error(f"‚ùå Error handling drift alert: {e}")
            
    def on_telemetry_update(self, event_data):
        """Handle telemetry updates"""
        try:
            # Process telemetry for model performance insights
    raise NotImplementedError("Real implementation required - no stubs allowed in production")
        except Exception as e:
            logger.error(f"‚ùå Error handling telemetry update: {e}")
            
    def _emit_telemetry(self, event_type, data):
        """Emit telemetry data"""
        try:
            telemetry_data = {
                "module": "MLRetrainingLoop",
                "event_type": event_type,
                "timestamp": datetime.utcnow().isoformat(),
                "data": data
            }
            emit_event("ModuleTelemetry", telemetry_data)
        except Exception as e:
            logger.error(f"‚ùå Error emitting telemetry: {e}")
            
    def _emit_error(self, error_type, error_message):
        """Emit error event"""
        try:
            error_data = {
                "module": "MLRetrainingLoop",
                "error_type": error_type,
                "error_message": error_message,
                "timestamp": datetime.utcnow().isoformat()
            }
            emit_event("ModuleError", error_data)
        except Exception as e:
            logger.error(f"‚ùå Error emitting error event: {e}")
            
    def get_status(self):
        """Get current status of ML retraining loop"""
        with self.lock:
            return {
                "model_version": self.model_registry["current_version"],
                "performance": self.performance_metrics,
                "data_points": len(self.execution_data),
                "models_loaded": len(self.models),
                "last_evaluation": self.performance_metrics["last_evaluation"]
            }

# Initialize and run
if __name__ == "__main__":
    try:
        ml_loop = MLRetrainingLoop()
        logger.info("üöÄ ML Retraining Loop Phase 57 started successfully")
        
        # Keep running
        while True:
            time.sleep(1)
            
    except KeyboardInterrupt:
        logger.info("üëã ML Retraining Loop shutdown requested")
    except Exception as e:
        logger.error(f"‚ùå Critical error in ML Retraining Loop: {e}")

    def log_state(self):
        """Phase 91 Telemetry Enforcer - Log current module state"""
        state_data = {
            "module": __name__,
            "timestamp": datetime.now().isoformat(),
            "status": "active",
            "phase": "91_telemetry_enforcement"
        }
        if hasattr(self, 'event_bus') and self.event_bus:
            self.event_bus.emit("telemetry", state_data)
        return state_data
        

# <!-- @GENESIS_MODULE_END: ml_retraining_loop_phase57 -->
#!/usr/bin/env python3
"""
GENESIS EventBus Auto-Fix Engine - Phase 95
Automatically fixes critical EventBus violations identified by the Phase 95 validator.
Implements the patches suggested in the focused validation report.
"""
import os
import json
import shutil
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path


# <!-- @GENESIS_MODULE_END: DUPLICATE_phase_95_eventbus_autofix_fixed_recovered_1 -->


# <!-- @GENESIS_MODULE_START: DUPLICATE_phase_95_eventbus_autofix_fixed_recovered_1 -->

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class EventBusAutoFixEngine:
    """
    Auto-fix engine for Phase 95 EventBus violations.
    Implements automated patches for critical EventBus issues.
    """
    
    def __init__(self, workspace_root: str = "."):
        self.workspace_root = Path(workspace_root).absolute()
        self.fixes_applied = []
        self.fixes_failed = []
        
        # Core files
        self.event_bus_file = self.workspace_root / "event_bus.json"
        self.system_tree_file = self.workspace_root / "system_tree.json"
        self.build_status_file = self.workspace_root / "build_status.json"
        self.build_tracker_file = self.workspace_root / "build_tracker.md"
        
        logger.info(f"EventBus Auto-Fix Engine initialized for workspace: {self.workspace_root}")
    
    def apply_auto_fixes(self) -> Dict[str, Any]:
        """
        Main auto-fix entry point.
        Applies automated fixes for known EventBus violations.
        """
        logger.info("ðŸ”§ Starting GENESIS EventBus Phase 95 Auto-Fix...")
        
        report = {
            "phase": 95,
            "engine": "EventBus Auto-Fix Engine",
            "timestamp": datetime.now().isoformat(),
            "status": "running",
            "fixes_attempted": 0,
            "fixes_applied": 0,
            "fixes_failed": 0,
            "applied_fixes": [],
            "failed_fixes": []
        }
        
        try:
            # Step 1: Load core data
            event_bus_data = self._load_event_bus()
            system_tree_data = self._load_system_tree()
            
            if not event_bus_data or not system_tree_data:
                return self._generate_error_report("Failed to load core EventBus data")
            
            # Step 2: Apply automated fixes
            self._fix_missing_telemetry_subscribers(event_bus_data, system_tree_data)
            self._fix_missing_publishers_in_system_tree(event_bus_data, system_tree_data)
            self._cleanup_orphaned_routes(event_bus_data, system_tree_data)
            
            # Step 3: Save updated files
            self._save_updated_files(event_bus_data, system_tree_data)
            
            # Step 4: Generate final report
            report.update({
                "status": "completed",
                "fixes_attempted": len(self.fixes_applied) + len(self.fixes_failed),
                "fixes_applied": len(self.fixes_applied),
                "fixes_failed": len(self.fixes_failed),
                "applied_fixes": self.fixes_applied,
                "failed_fixes": self.fixes_failed
            })
            
            # Step 5: Update build status
            self._update_build_status(report)
            self._log_fixes_to_build_tracker()
            
            if len(self.fixes_applied) > 0:
                logger.info(f"âœ… Applied {len(self.fixes_applied)} EventBus fixes")
            
            if len(self.fixes_failed) > 0:
                logger.warning(f"âš ï¸ {len(self.fixes_failed)} fixes failed")
            
            return report
            
        except Exception as e:
            logger.error(f"Auto-fix engine failed: {str(e)}")
            return self._generate_error_report(str(e))
    
    def _load_event_bus(self) -> Optional[Dict]:
        """Load event_bus.json"""
        try:
            with open(self.event_bus_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"Failed to load event_bus.json: {str(e)}")
            return None
    
    def _load_system_tree(self) -> Optional[Dict]:
        """Load system_tree.json"""
        try:
            with open(self.system_tree_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"Failed to load system_tree.json: {str(e)}")
            return None
    
    def _fix_missing_telemetry_subscribers(self, event_bus_data: Dict, system_tree_data: Dict):
        """Fix routes that have telemetry subscribers but missing publishers"""
        logger.info("ðŸ”§ Fixing missing telemetry subscribers...")
        
        routes = event_bus_data.get('routes', {})
        
        # Add universal telemetry subscriber for orphaned telemetry routes
        telemetry_routes = [k for k in routes.keys() if '_telemetry' in k]
        
        for route_name in telemetry_routes:
            route_config = routes[route_name]
            subscribers = route_config.get('subscribers', [])
            
            # Ensure telemetry_collector is a subscriber for all telemetry routes
            if 'telemetry_collector' not in subscribers:
                route_config['subscribers'] = subscribers + ['telemetry_collector']
                
                self.fixes_applied.append({
                    "type": "add_telemetry_subscriber",
                    "route": route_name,
                    "action": "Added telemetry_collector as subscriber",
                    "success": True
                })
        
        logger.info(f"Fixed {len([f for f in self.fixes_applied if f['type'] == 'add_telemetry_subscriber'])} telemetry routes")
    
    def _fix_missing_publishers_in_system_tree(self, event_bus_data: Dict, system_tree_data: Dict):
        """Add missing publishers to system_tree.json"""
        logger.info("ðŸ”§ Adding missing publishers to system_tree...")
        
        routes = event_bus_data.get('routes', {})
        modules = system_tree_data.get('modules', {})
        
        for route_name, route_config in routes.items():
            publisher = route_config.get('publisher')
            subscribers = route_config.get('subscribers', [])
            
            # Only fix if route has active subscribers but publisher missing from system tree
            if publisher and len(subscribers) > 0 and publisher not in modules:
                # Check if publisher file exists
                potential_file = self.workspace_root / f"{publisher}.py"
                if potential_file.exists():
                    # Add to system tree
                    modules[publisher] = {
                        "file_path": f".\\{publisher}.py",
                        "classes": [],
                        "has_eventbus": True,
                        "has_telemetry": True,
                        "auto_added": True,
                        "added_by": "phase_95_autofix"
                    }
                    
                    self.fixes_applied.append({
                        "type": "add_missing_publisher",
                        "publisher": publisher,
                        "route": route_name,
                        "action": f"Added {publisher} to system_tree.json",
                        "success": True
                    })
                else:
                    self.fixes_failed.append({
                        "type": "add_missing_publisher",
                        "publisher": publisher,
                        "route": route_name,
                        "reason": f"Publisher file {publisher}.py not found",
                        "success": False
                    })
        
        logger.info(f"Added {len([f for f in self.fixes_applied if f['type'] == 'add_missing_publisher'])} missing publishers")
    
    def _cleanup_orphaned_routes(self, event_bus_data: Dict, system_tree_data: Dict):
        """Clean up routes with no active subscribers"""
        logger.info("ðŸ”§ Cleaning up orphaned routes...")
        
        routes = event_bus_data.get('routes', {})
        routes_to_remove = []
        
        for route_name, route_config in routes.items():
            subscribers = route_config.get('subscribers', [])
            publisher = route_config.get('publisher')
            
            # Mark for removal if no subscribers and publisher doesn't exist
            if len(subscribers) == 0 and (not publisher or publisher not in system_tree_data.get('modules', {})):
                routes_to_remove.append(route_name)
        
        # Remove orphaned routes
        for route_name in routes_to_remove:
            del routes[route_name]
            
            self.fixes_applied.append({
                "type": "remove_orphaned_route",
                "route": route_name,
                "action": f"Removed orphaned route {route_name}",
                "success": True
            })
        
        logger.info(f"Removed {len(routes_to_remove)} orphaned routes")
    
    def _save_updated_files(self, event_bus_data: Dict, system_tree_data: Dict):
        """Save updated event_bus.json and system_tree.json"""
        try:
            # Backup original files
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Backup event_bus.json
            backup_event_bus = self.workspace_root / f"event_bus.json.backup_{timestamp}"
            if self.event_bus_file.exists():
                shutil.copy2(self.event_bus_file, backup_event_bus)
            
            # Backup system_tree.json
            backup_system_tree = self.workspace_root / f"system_tree.json.backup_{timestamp}"
            if self.system_tree_file.exists():
                shutil.copy2(self.system_tree_file, backup_system_tree)
            
            # Save updated files
            with open(self.event_bus_file, 'w', encoding='utf-8') as f:
                json.dump(event_bus_data, f, indent=2)
            
            with open(self.system_tree_file, 'w', encoding='utf-8') as f:
                json.dump(system_tree_data, f, indent=2)
            
            logger.info("âœ… Updated EventBus files saved (originals backed up)")
            
        except Exception as e:
            logger.error(f"Failed to save updated files: {str(e)}")
            raise
    
    def _update_build_status(self, report: Dict):
        """Update build_status.json with auto-fix results"""
        try:
            if self.build_status_file.exists():
                with open(self.build_status_file, 'r', encoding='utf-8') as f:
                    build_status = json.load(f)
            else:
                build_status = {}
            
            # Update with auto-fix results
            build_status.update({
                "phase_95_eventbus_autofix": {
                    "timestamp": report['timestamp'],
                    "status": report['status'],
                    "fixes_applied": report['fixes_applied'],
                    "fixes_failed": report['fixes_failed'],
                    "autofix_version": "95.0"
                },
                "last_update": report['timestamp']
            })
            
            with open(self.build_status_file, 'w', encoding='utf-8') as f:
                json.dump(build_status, f, indent=2)
            
            logger.info("âœ… Build status updated with auto-fix results")
            
        except Exception as e:
            logger.error(f"Failed to update build status: {str(e)}")
    
    def _log_fixes_to_build_tracker(self):
        """Log applied fixes to build_tracker.md"""
        try:
            timestamp = datetime.now().isoformat()
            log_entry = f"\n\n## Phase 95 EventBus Auto-Fix - {timestamp}\n"
            log_entry += f"Applied {len(self.fixes_applied)} fixes, {len(self.fixes_failed)} failed\n"
            
            for fix in self.fixes_applied:
                log_entry += f"- âœ… {fix['type']}: {fix['action']}\n"
            
            for fix in self.fixes_failed:
                log_entry += f"- âŒ {fix['type']}: {fix['reason']}\n"
            
            with open(self.build_tracker_file, 'a', encoding='utf-8') as f:
                f.write(log_entry)
            
        except Exception as e:
            logger.error(f"Failed to update build tracker: {str(e)}")
    
    def _generate_error_report(self, error_message: str) -> Dict[str, Any]:
        """Generate error report for auto-fix failure"""
        return {
            "phase": 95,
            "engine": "EventBus Auto-Fix Engine",
            "timestamp": datetime.now().isoformat(),
            "status": "error",
            "error": error_message,
            "fixes_applied": 0,
            "fixes_failed": 0
        }

def main():
    """Main entry point for Phase 95 EventBus auto-fix"""
    try:
        engine = EventBusAutoFixEngine()
        report = engine.apply_auto_fixes()
        
        print("\n" + "="*60)
        print("GENESIS EVENTBUS PHASE 95 AUTO-FIX COMPLETE")
        print("="*60)
        print(f"Status: {report['status']}")
        print(f"Fixes Applied: {report['fixes_applied']}")
        print(f"Fixes Failed: {report['fixes_failed']}")
        print(f"Total Attempted: {report['fixes_attempted']}")
        
        if report['fixes_applied'] > 0:
            print("\nâœ… EventBus fixes applied successfully")
            print("Run the Phase 95 validator again to check remaining issues")
        
        if report['fixes_failed'] > 0:
            print(f"\nâš ï¸ {report['fixes_failed']} fixes require manual attention")
        
        return report
        
    except Exception as e:
        logger.error(f"Phase 95 auto-fix failed: {str(e)}")
        raise

if __name__ == "__main__":
    main()


def detect_divergence(price_data: list, indicator_data: list, window: int = 10) -> Dict:
    """
    Detect regular and hidden divergences between price and indicator
    
    Args:
        price_data: List of price values (closing prices)
        indicator_data: List of indicator values (e.g., RSI, MACD)
        window: Number of periods to check for divergence
        
    Returns:
        Dictionary with divergence information
    """
    result = {
        "regular_bullish": False,
        "regular_bearish": False,
        "hidden_bullish": False,
        "hidden_bearish": False,
        "strength": 0.0
    }
    
    # Need at least window + 1 periods of data
    if len(price_data) < window + 1 or len(indicator_data) < window + 1:
        return result
        
    # Get the current and historical points
    current_price = price_data[-1]
    previous_price = min(price_data[-window:-1]) if price_data[-1] > price_data[-2] else max(price_data[-window:-1])
    previous_price_idx = price_data[-window:-1].index(previous_price) + len(price_data) - window
    
    current_indicator = indicator_data[-1]
    previous_indicator = indicator_data[previous_price_idx]
    
    # Check for regular divergences
    # Bullish - Lower price lows but higher indicator lows
    if current_price < previous_price and current_indicator > previous_indicator:
        result["regular_bullish"] = True
        result["strength"] = abs((current_indicator - previous_indicator) / previous_indicator)
        
    # Bearish - Higher price highs but lower indicator highs
    elif current_price > previous_price and current_indicator < previous_indicator:
        result["regular_bearish"] = True
        result["strength"] = abs((current_indicator - previous_indicator) / previous_indicator)
    
    # Check for hidden divergences
    # Bullish - Higher price lows but lower indicator lows
    elif current_price > previous_price and current_indicator < previous_indicator:
        result["hidden_bullish"] = True
        result["strength"] = abs((current_indicator - previous_indicator) / previous_indicator)
        
    # Bearish - Lower price highs but higher indicator highs
    elif current_price < previous_price and current_indicator > previous_indicator:
        result["hidden_bearish"] = True
        result["strength"] = abs((current_indicator - previous_indicator) / previous_indicator)
    
    # Emit divergence event if detected
    if any([result["regular_bullish"], result["regular_bearish"], 
            result["hidden_bullish"], result["hidden_bearish"]]):
        emit_event("divergence_detected", {
            "type": next(k for k, v in result.items() if v is True and k != "strength"),
            "strength": result["strength"],
            "symbol": price_data.symbol if hasattr(price_data, "symbol") else "unknown",
            "timestamp": datetime.now().isoformat()
        })
        
    return result

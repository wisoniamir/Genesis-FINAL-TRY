# <!-- @GENESIS_MODULE_START: test_phase43_sentiment_fusion_basic -->

from datetime import datetime\n"""
GENESIS Test Suite - Phase 43 Strategy Sentiment Fusion Engine
==============================================================

🧪 TEST MISSION: Basic validation of sentiment fusion capabilities
📊 COVERAGE: Engine initialization, basic fusion logic, telemetry emission
⚙️ VALIDATION: EventBus routing, configuration loading
🔁 ARCHITECT MODE: Compliance testing with real data requirements

Simple test validation for Phase 43 implementation.
"""

import os
import sys
import json
import time
import logging
import datetime
from typing import Dict, Any

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_sentiment_fusion_engine():
    """Test Strategy Sentiment Fusion Engine initialization and basic functionality"""
    print("🧪 Testing Phase 43 Strategy Sentiment Fusion Engine...")
    
    try:
        # Test import
        from strategy_sentiment_fusion_engine import (
            StrategySentimentFusionEngine, 
            get_strategy_sentiment_fusion_engine,
            SentimentRegime,
            SessionBias
        )
        print("✅ Module import successful")
        
        # Test engine initialization
        engine = get_strategy_sentiment_fusion_engine()
        print("✅ Engine initialization successful")
        
        # Test configuration validation
        config_checks = [
            "fusion_weights" in engine.config,
            "sentiment_thresholds" in engine.config,
            "modulation_limits" in engine.config,
            engine.config.get("architect_mode_compliant", False)
        ]
        
        if all(config_checks):
            print("✅ Configuration validation passed")
        else:
            print("❌ Configuration validation failed")
            return False
        
        # Test engine startup
        engine.start()
        time.sleep(2)  # Allow startup
        
        if engine.running:
            print("✅ Engine startup successful")
        else:
            print("❌ Engine startup failed")
            return False
        
        # Test telemetry metrics exist
        required_metrics = [
            "sentiment_alignment_score",
            "session_sentiment_bias",
            "macro_sentiment_impact",
            "fusion_modulation_weight"
        ]
        
        metrics_valid = all(metric in engine.metrics for metric in required_metrics)
        if metrics_valid:
            print("✅ Telemetry metrics initialized")
        else:
            print("❌ Telemetry metrics missing")
            return False
        
        # Test basic event handling (execute_live event)
        try:
            test_news_data = {
                "category": "economic",
                "impact_level": 0.7,
                "sentiment_score": 0.5,
                "timestamp": datetime.datetime.now().isoformat()
            }
            
            # Simulate news sentiment update
            engine._handle_news_sentiment_update({"data": test_news_data})
            
            if len(engine.news_sentiment_buffer) > 0:
                print("✅ Event handling functional")
            else:
                print("⚠️  Event handling test inconclusive")
        
        except Exception as e:
            print(f"⚠️  Event handling test error: {e}")
        
        # Test cleanup
        engine.stop()
        print("✅ Engine shutdown successful")
        
        print("\n🎉 Phase 43 Strategy Sentiment Fusion Engine - BASIC TESTS PASSED")
        print("✅ Module architecture validated")
        print("✅ Architect mode compliance confirmed")
        print("✅ Core functionality operational")
        
        return True
        
    except ImportError as e:
        print(f"❌ Import failed: {e}")
        return False
        
    except Exception as e:
        print(f"❌ Test failed: {e}")
        return False

def test_config_file():
    """Test configuration file creation and validation"""
    print("\n🔧 Testing configuration file...")
    
    config_path = "strategy_sentiment_fusion_config.json"
    
    if os.path.exists(config_path):
        try:
            with open(config_path, 'r') as f:
                config = json.load(f)
            
            required_sections = [
                "fusion_weights",
                "sentiment_thresholds",
                "modulation_limits",
                "compliance"
            ]
            
            if all(section in config for section in required_sections):
                print("✅ Configuration file structure valid")
                
                if config.get("compliance", {}).get("architect_mode", False):
                    print("✅ Architect mode compliance enabled")
                    return True
                else:
                    print("❌ Architect mode compliance not enabled")
                    return False
            else:
                print("❌ Configuration file structure invalid")
                return False
                
        except json.JSONDecodeError as e:
            print(f"❌ Configuration file JSON error: {e}")
            return False
    else:
        print("❌ Configuration file not found")
        return False

def main():
    """Main test execution"""
    print("=" * 60)
    print("GENESIS Phase 43 Strategy Sentiment Fusion Engine Tests")
    print("=" * 60)
    
    tests_passed = 0
    total_tests = 2
    
    # Run tests
    if test_config_file():
        tests_passed += 1
    
    if test_sentiment_fusion_engine():
        tests_passed += 1
    
    # Summary
    print(f"\n📊 Test Summary: {tests_passed}/{total_tests} tests passed")
    
    if tests_passed == total_tests:
        print("🎉 ALL TESTS PASSED - Phase 43 ready for integration")
        return True
    else:
        print("❌ SOME TESTS FAILED - Review and fix before deployment")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)


# <!-- @GENESIS_MODULE_END: test_phase43_sentiment_fusion_basic -->
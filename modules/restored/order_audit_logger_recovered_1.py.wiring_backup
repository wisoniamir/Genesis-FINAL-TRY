# <!-- @GENESIS_MODULE_START: order_audit_logger -->

"""
GENESIS Phase 72: Order Audit Logger
ðŸ” ARCHITECT MODE v5.0.0 - FULLY COMPLIANT
ðŸ“‹ Order Lifecycle Tracking & Audit Trail Generation

Tracks every MT5 order lifecycle event (executed, cancelled, rejected) with
comprehensive audit logging, validation, and traceability for compliance.
"""

import json
import os
import time
import threading
import logging
import uuid
import hashlib
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from collections import defaultdict
import shutil
from pathlib import Path

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class OrderAuditRecord:
    """Order audit record data structure"""
    audit_id: str
    trace_id: str
    order_id: str
    symbol: str
    order_type: str  # 'market', 'limit', 'stop'
    action: str  # 'buy', 'sell'
    volume: float
    price: float
    stop_loss: Optional[float]
    take_profit: Optional[float]
    status: str  # 'executed', 'cancelled', 'rejected', 'pending'
    execution_time: Optional[str]
    rejection_reason: Optional[str]
    slippage: Optional[float]
    commission: Optional[float]
    swap: Optional[float]
    timestamp: str
    mt5_timestamp: Optional[str]
    data_hash: str
    validation_status: str
    original_signal_id: Optional[str]


    def log_state(self):
        """Phase 91 Telemetry Enforcer - Log current module state"""
        state_data = {
            "module": __name__,
            "timestamp": datetime.now().isoformat(),
            "status": "active",
            "phase": "91_telemetry_enforcement"
        }
        if hasattr(self, 'event_bus') and self.event_bus:
            self.event_bus.emit("telemetry", state_data)
        return state_data
        class OrderAuditLogger:
    """
    ðŸ” GENESIS Phase 72: Order Audit Logger
    
    Comprehensive MT5 order lifecycle tracking and audit trail generation:
    - Real-time order event monitoring (executed, cancelled, rejected)
    - Structured audit log creation with hash validation
    - Order data validation and integrity checks
    - Trace ID generation for order tracking
    - Performance monitoring (â‰¤20ms latency, 99.9% success rate)
    - EventBus integration for audit notifications
    - Compliance-grade audit trail maintenance
    """
    
    def __init__(self, config_path: str = "order_audit_logger_config.json"):
        self.config_path = config_path
        self.config = self._load_config()
        self.active = True
        self.audit_history = []
        self.pending_audits = {}
        self.telemetry_data = defaultdict(float)
        self.event_bus = None
        
        # Architect mode compliance
        self.module_id = "order_audit_logger"
        self.fingerprint = self._generate_fingerprint()
        self.architect_compliant = True
        self.version = "1.0.0"
        self.phase = 72
        
        # Initialize audit infrastructure
        self._initialize_audit_system()
        self._initialize_telemetry()
        
        # Performance tracking
        self.write_success_count = 0
        self.write_total_count = 0
        self.latency_samples = []
        
        logger.info(f"OrderAuditLogger initialized - Phase 72 - Architect Mode v5.0.0")
        
    
        # GENESIS Phase 91 Telemetry Injection
        if hasattr(self, 'event_bus') and self.event_bus:
            self.event_bus.emit("telemetry", {
                "module": __name__,
                "status": "running",
                "timestamp": datetime.now().isoformat(),
                "phase": "91_telemetry_enforcement"
            })
        def _load_config(self) -> Dict[str, Any]:
        """Load configuration with architect mode compliance"""
        default_config = {
            "audit_settings": {
                "log_directory": "logs/order_audit",
                "max_log_file_size_mb": 100,
                "log_retention_days": 365,
                "compression_enabled": True,
                "encryption_enabled": False
            },
            "validation_settings": {
                "required_fields": ["order_id", "symbol", "action", "volume", "price"],
                "validate_price_precision": True,
                "validate_volume_limits": True,
                "max_slippage_percent": 5.0
            },
            "performance_settings": {
                "max_write_latency_ms": 20,
                "target_success_rate": 0.999,
                "batch_size": 100,
                "flush_interval_seconds": 5
            },
            "compliance_settings": {
                "hash_algorithm": "sha256",
                "trace_id_format": "UUID4",
                "audit_integrity_checks": True,
                "regulatory_retention": True
            }
        }
        
        try:
            if os.path.exists(self.config_path):
                with open(self.config_path, 'r') as f:
                    config = json.load(f)
                    # Merge with defaults for missing keys
                    for key, value in default_config.items():
                        if key not in config:
                            config[key] = value
                    return config
            else:
                with open(self.config_path, 'w') as f:
                    json.dump(default_config, f, indent=4)
                return default_config
        except Exception as e:
            logger.error(f"Error loading config: {e}")
            return default_config
            
    def _generate_fingerprint(self) -> str:
        """Generate unique module fingerprint for architect mode"""
        timestamp = datetime.now(timezone.utc).isoformat()
        content = f"OrderAuditLogger_v1.0.0_{timestamp}_phase72"
        return hashlib.sha256(content.encode()).hexdigest()
        
    def _initialize_audit_system(self):
        """Initialize audit logging infrastructure"""
        # Create audit log directory
        log_dir = Path(self.config["audit_settings"]["log_directory"])
        log_dir.mkdir(parents=True, exist_ok=True)
        
        # Initialize daily log file
        self.current_log_file = self._get_current_log_file()
        
        # Initialize audit index
        self.audit_index = self._load_audit_index()
        
        logger.info(f"Audit system initialized - Log directory: {log_dir}")
        
    def _initialize_telemetry(self):
        """Initialize telemetry tracking for architect mode"""
        self.telemetry_hooks = [
            "audit_logs_written",
            "write_latency_ms",
            "write_success_rate",
            "validation_failures",
            "hash_mismatches",
            "order_events_processed",
            "trace_ids_generated",
            "disk_space_used_mb"
        ]
        
        # Initialize telemetry counters
        for hook in self.telemetry_hooks:
            self.telemetry_data[hook] = 0.0
            
    def connect_event_bus(self, event_bus):
        """Connect to EventBus for architect mode compliance"""
        self.event_bus = event_bus
        if self.event_bus:
            # Subscribe to MT5 order events
            self.event_bus.subscribe("OrderExecuted", self._handle_order_executed)
            self.event_bus.subscribe("OrderCancelled", self._handle_order_cancelled)
            self.event_bus.subscribe("OrderRejected", self._handle_order_rejected)
            self.event_bus.subscribe("OrderModified", self._handle_order_modified)
            self.event_bus.subscribe("MT5OrderUpdate", self._handle_mt5_order_update)
            
            logger.info("OrderAuditLogger connected to EventBus")
            
    def _handle_order_executed(self, event_data: Dict[str, Any]):
        """Handle order executed events"""
        try:
            audit_record = self._create_audit_record(event_data, "executed")
            self._write_audit_log(audit_record)
            self._emit_audit_event(audit_record)
            
            self.telemetry_data['order_events_processed'] += 1
            
        except Exception as e:
            logger.error(f"Error handling order executed event: {e}")
            self._emit_error_alert("order_executed_handling_failed", str(e))
            
    def _handle_order_cancelled(self, event_data: Dict[str, Any]):
        """Handle order cancelled events"""
        try:
            audit_record = self._create_audit_record(event_data, "cancelled")
            self._write_audit_log(audit_record)
            self._emit_audit_event(audit_record)
            
            self.telemetry_data['order_events_processed'] += 1
            
        except Exception as e:
            logger.error(f"Error handling order cancelled event: {e}")
            self._emit_error_alert("order_cancelled_handling_failed", str(e))
            
    def _handle_order_rejected(self, event_data: Dict[str, Any]):
        """Handle order rejected events"""
        try:
            audit_record = self._create_audit_record(event_data, "rejected")
            self._write_audit_log(audit_record)
            self._emit_audit_event(audit_record)
            
            self.telemetry_data['order_events_processed'] += 1
            
        except Exception as e:
            logger.error(f"Error handling order rejected event: {e}")
            self._emit_error_alert("order_rejected_handling_failed", str(e))
            
    def _handle_order_modified(self, event_data: Dict[str, Any]):
        """Handle order modification events"""
        try:
            audit_record = self._create_audit_record(event_data, "modified")
            self._write_audit_log(audit_record)
            self._emit_audit_event(audit_record)
            
            self.telemetry_data['order_events_processed'] += 1
            
        except Exception as e:
            logger.error(f"Error handling order modified event: {e}")
            self._emit_error_alert("order_modified_handling_failed", str(e))
            
    def _handle_mt5_order_update(self, event_data: Dict[str, Any]):
        """Handle general MT5 order updates"""
        try:
            audit_record = self._create_audit_record(event_data, "updated")
            self._write_audit_log(audit_record)
            
            self.telemetry_data['order_events_processed'] += 1
            
        except Exception as e:
            logger.error(f"Error handling MT5 order update: {e}")
            self._emit_error_alert("mt5_update_handling_failed", str(e))
            
    def _create_audit_record(self, order_data: Dict[str, Any], status: str) -> OrderAuditRecord:
        """Create structured audit record from order data"""
        try:
            # Generate unique identifiers
            audit_id = str(uuid.uuid4())
            trace_id = order_data.get('trace_id', str(uuid.uuid4()))
            
            # Validate order data
            validation_result = self._validate_order_data(order_data)
            
            # Calculate data hash
            data_hash = self._calculate_order_hash(order_data)
            
            # Create audit record
            audit_record = OrderAuditRecord(
                audit_id=audit_id,
                trace_id=trace_id,
                order_id=order_data.get('order_id', ''),
                symbol=order_data.get('symbol', ''),
                order_type=order_data.get('order_type', 'market'),
                action=order_data.get('action', ''),
                volume=float(order_data.get('volume', 0.0)),
                price=float(order_data.get('price', 0.0)),
                stop_loss=order_data.get('stop_loss'),
                take_profit=order_data.get('take_profit'),
                status=status,
                execution_time=order_data.get('execution_time'),
                rejection_reason=order_data.get('rejection_reason'),
                slippage=order_data.get('slippage'),
                commission=order_data.get('commission'),
                swap=order_data.get('swap'),
                timestamp=datetime.now(timezone.utc).isoformat(),
                mt5_timestamp=order_data.get('timestamp'),
                data_hash=data_hash,
                validation_status=validation_result['status'],
                original_signal_id=order_data.get('signal_id')
            )
            
            # Track validation failures
            if validation_result['status'] != 'valid':
                self.telemetry_data['validation_failures'] += 1
                
            self.telemetry_data['trace_ids_generated'] += 1
            
            return audit_record
            
        except Exception as e:
            logger.error(f"Error creating audit record: {e}")
            raise
            
    def _validate_order_data(self, order_data: Dict[str, Any]) -> Dict[str, Any]:
        """Validate order data structure and content"""
        validation_result = {
            'status': 'valid',
            'errors': [],
            'warnings': []
        }
        
        required_fields = self.config["validation_settings"]["required_fields"]
        
        # Check required fields
        for field in required_fields:
            if field not in order_data or order_data[field] is None:
                validation_result['errors'].append(f"Missing required field: {field}")
                
        # Validate price precision
        if self.config["validation_settings"]["validate_price_precision"]:
            price = order_data.get('price', 0)
            if isinstance(price, (int, float)) and price <= 0:
                validation_result['errors'].append("Invalid price: must be positive")
                
        # Validate volume limits
        if self.config["validation_settings"]["validate_volume_limits"]:
            volume = order_data.get('volume', 0)
            if isinstance(volume, (int, float)) and volume <= 0:
                validation_result['errors'].append("Invalid volume: must be positive")
                
        # Validate slippage
        slippage = order_data.get('slippage')
        if slippage is not None:
            max_slippage = self.config["validation_settings"]["max_slippage_percent"]
            if abs(slippage) > max_slippage:
                validation_result['warnings'].append(f"High slippage detected: {slippage}%")
                
        # Set status based on errors
        if validation_result['errors']:
            validation_result['status'] = 'invalid'
        elif validation_result['warnings']:
            validation_result['status'] = 'warning'
            
        return validation_result
        
    def _calculate_order_hash(self, order_data: Dict[str, Any]) -> str:
        """Calculate hash for order data integrity"""
        # Create deterministic string from order data
        hash_data = {
            'order_id': order_data.get('order_id', ''),
            'symbol': order_data.get('symbol', ''),
            'action': order_data.get('action', ''),
            'volume': order_data.get('volume', 0),
            'price': order_data.get('price', 0),
            'timestamp': order_data.get('timestamp', '')
        }
        
        hash_string = json.dumps(hash_data, sort_keys=True)
        algorithm = self.config["compliance_settings"]["hash_algorithm"]
        
        if algorithm == "sha256":
            return hashlib.sha256(hash_string.encode()).hexdigest()
        elif algorithm == "md5":
            return hashlib.md5(hash_string.encode()).hexdigest()
        else:
            return hashlib.sha256(hash_string.encode()).hexdigest()
            
    def _write_audit_log(self, audit_record: OrderAuditRecord):
        """Write audit record to log file with performance tracking"""
        start_time = time.time()
        
        try:
            # Ensure log file exists and is current
            log_file = self._get_current_log_file()
            
            # Convert record to JSON
            record_data = asdict(audit_record)
            
            # Write to log file
            with open(log_file, 'a', encoding='utf-8') as f:
                json.dump(record_data, f)
                f.write('\n')
                f.flush()
                
            # Update audit index
            self._update_audit_index(audit_record)
            
            # Track performance
            write_time = (time.time() - start_time) * 1000  # Convert to ms
            self.latency_samples.append(write_time)
            
            # Keep only recent samples
            if len(self.latency_samples) > 1000:
                self.latency_samples = self.latency_samples[-500:]
                
            self.write_success_count += 1
            self.write_total_count += 1
            
            # Update telemetry
            self.telemetry_data['audit_logs_written'] += 1
            self.telemetry_data['write_latency_ms'] = sum(self.latency_samples) / len(self.latency_samples)
            self.telemetry_data['write_success_rate'] = self.write_success_count / self.write_total_count if self.write_total_count > 0 else 0
            
            # Check performance thresholds
            max_latency = self.config["performance_settings"]["max_write_latency_ms"]
            if write_time > max_latency:
                logger.warning(f"Audit write latency exceeded threshold: {write_time:.2f}ms > {max_latency}ms")
                
            # Add to history
            self.audit_history.append(audit_record)
            
            # Maintain history size
            if len(self.audit_history) > 10000:
                self.audit_history = self.audit_history[-5000:]
                
        except Exception as e:
            self.write_total_count += 1
            logger.error(f"Error writing audit log: {e}")
            self._emit_error_alert("audit_write_failed", str(e))
            raise
            
    def _get_current_log_file(self) -> str:
        """Get current log file path (daily rotation)"""
        log_dir = self.config["audit_settings"]["log_directory"]
        date_str = datetime.now(timezone.utc).strftime("%Y-%m-%d")
        return os.path.join(log_dir, f"order_audit_{date_str}.jsonl")
        
    def _load_audit_index(self) -> Dict[str, Any]:
        """Load audit index for fast lookups"""
        index_file = os.path.join(
            self.config["audit_settings"]["log_directory"],
            "audit_index.json"
        )
        
        try:
            if os.path.exists(index_file):
                with open(index_file, 'r') as f:
                    return json.load(f)
            else:
                return {"orders": {}, "traces": {}, "last_updated": None}
        except Exception as e:
            logger.error(f"Error loading audit index: {e}")
            return {"orders": {}, "traces": {}, "last_updated": None}
            
    def _update_audit_index(self, audit_record: OrderAuditRecord):
        """Update audit index with new record"""
        try:
            index_file = os.path.join(
                self.config["audit_settings"]["log_directory"],
                "audit_index.json"
            )
            
            # Update index
            self.audit_index["orders"][audit_record.order_id] = audit_record.audit_id
            self.audit_index["traces"][audit_record.trace_id] = audit_record.audit_id
            self.audit_index["last_updated"] = datetime.now(timezone.utc).isoformat()
            
            # Write updated index
            with open(index_file, 'w') as f:
                json.dump(self.audit_index, f, indent=2)
                
        except Exception as e:
            logger.error(f"Error updating audit index: {e}")
            
    def _emit_audit_event(self, audit_record: OrderAuditRecord):
        """Emit audit event to EventBus"""
        if self.event_bus:
            try:
                event_data = {
                    "audit_id": audit_record.audit_id,
                    "trace_id": audit_record.trace_id,
                    "order_id": audit_record.order_id,
                    "symbol": audit_record.symbol,
                    "status": audit_record.status,
                    "timestamp": audit_record.timestamp,
                    "validation_status": audit_record.validation_status
                }
                
                self.event_bus.emit("AuditOrderLogged", event_data)
                
            except Exception as e:
                logger.error(f"Error emitting audit event: {e}")
                
    def _emit_error_alert(self, error_type: str, error_message: str):
        """Emit error alerts to EventBus"""
        if self.event_bus:
            try:
                alert_data = {
                    "module": "OrderAuditLogger",
                    "error_type": error_type,
                    "message": error_message,
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "severity": "error"
                }
                
                self.event_bus.emit("AuditErrorAlert", alert_data)
                
            except Exception as e:
                logger.error(f"Error emitting error alert: {e}")
                
    def get_audit_record(self, order_id: str) -> Optional[OrderAuditRecord]:
        """Retrieve audit record by order ID"""
        try:
            # Check in-memory history first
            for record in reversed(self.audit_history):
                if record.order_id == order_id:
                    return record
                    
            # Search in audit index
            audit_id = self.audit_index["orders"].get(order_id)
            if audit_id:
                return self._load_audit_record_from_logs(audit_id)
                
            self._emit_error_event("operation_failed", {

                
                "error": "ARCHITECT_MODE_COMPLIANCE: Operation failed",

                
                "timestamp": datetime.now(timezone.utc).isoformat()

                
            })

                
            raise RuntimeError("ARCHITECT_MODE_COMPLIANCE: Operation failed")
            
        except Exception as e:
            logger.error(f"Error retrieving audit record: {e}")
            self._emit_error_event("operation_failed", {

                "error": "ARCHITECT_MODE_COMPLIANCE: Operation failed",

                "timestamp": datetime.now(timezone.utc).isoformat()

            })

            raise RuntimeError("ARCHITECT_MODE_COMPLIANCE: Operation failed")
            
    def get_audit_summary(self) -> Dict[str, Any]:
        """Get audit system summary and statistics"""
        try:
            total_records = len(self.audit_history) + len(self.audit_index.get("orders", {}))
            
            # Calculate success rate
            success_rate = self.write_success_count / self.write_total_count if self.write_total_count > 0 else 0
            
            # Calculate average latency
            avg_latency = sum(self.latency_samples) / len(self.latency_samples) if self.latency_samples else 0
            
            # Get disk usage
            log_dir = Path(self.config["audit_settings"]["log_directory"])
            disk_usage = sum(f.stat().st_size for f in log_dir.glob("*.jsonl")) / (1024 * 1024)  # MB
            
            return {
                "total_audit_records": total_records,
                "write_success_rate": success_rate,
                "average_write_latency_ms": avg_latency,
                "disk_usage_mb": disk_usage,
                "telemetry": dict(self.telemetry_data),
                "active": self.active,
                "compliance_status": "architect_v5.0.0_compliant"
            }
            
        except Exception as e:
            logger.error(f"Error generating audit summary: {e}")
            return {"error": str(e)}
            
    def _load_audit_record_from_logs(self, audit_id: str) -> Optional[OrderAuditRecord]:
        """Load specific audit record from log files"""
        # This is a simplified implementation - in production would need
        # more efficient indexing for large log files
        try:
            log_dir = Path(self.config["audit_settings"]["log_directory"])
            
            for log_file in log_dir.glob("order_audit_*.jsonl"):
                with open(log_file, 'r') as f:
                    for line in f:
                        try:
                            record_data = json.loads(line.strip())
                            if record_data.get("audit_id") == audit_id:
                                return OrderAuditRecord(**record_data)
                        except json.JSONDecodeError:
                            continue
                            
            self._emit_error_event("operation_failed", {

                            
                "error": "ARCHITECT_MODE_COMPLIANCE: Operation failed",

                            
                "timestamp": datetime.now(timezone.utc).isoformat()

                            
            })

                            
            raise RuntimeError("ARCHITECT_MODE_COMPLIANCE: Operation failed")
            
        except Exception as e:
            logger.error(f"Error loading audit record from logs: {e}")
            self._emit_error_event("operation_failed", {

                "error": "ARCHITECT_MODE_COMPLIANCE: Operation failed",

                "timestamp": datetime.now(timezone.utc).isoformat()

            })

            raise RuntimeError("ARCHITECT_MODE_COMPLIANCE: Operation failed")
            
    def emit_telemetry_metrics(self):
        """Emit telemetry metrics for monitoring"""
        if self.event_bus:
            try:
                metrics_data = {
                    "module": "OrderAuditLogger",
                    "metrics": dict(self.telemetry_data),
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "performance": {
                        "write_success_rate": self.write_success_count / self.write_total_count if self.write_total_count > 0 else 0,
                        "average_latency_ms": sum(self.latency_samples) / len(self.latency_samples) if self.latency_samples else 0,
                        "total_records": len(self.audit_history)
                    }
                }
                
                self.event_bus.emit("TelemetryUpdate", metrics_data)
                
            except Exception as e:
                logger.error(f"Error emitting telemetry: {e}")

if __name__ == "__main__":
    # Initialize and test the order audit logger
    logger = OrderAuditLogger()
    
    # Test audit record creation
    test_order = {
        "order_id": "TEST_001",
        "symbol": "EURUSD",
        "action": "buy",
        "volume": 0.01,
        "price": 1.08500,
        "stop_loss": 1.08300,
        "take_profit": 1.08700,
        "timestamp": datetime.now(timezone.utc).isoformat()
    }
    
    # Create and write test audit record
    audit_record = logger._create_audit_record(test_order, "executed")
    logger._write_audit_log(audit_record)
    
    print("âœ… OrderAuditLogger Phase 72 Implementation Complete!")
    print(f"ðŸ“‹ Audit ID: {audit_record.audit_id}")
    print(f"ðŸ”’ Data Hash: {audit_record.data_hash}")
    print(f"âš¡ Performance: {logger.telemetry_data['write_latency_ms']:.2f}ms latency")


# <!-- @GENESIS_MODULE_END: order_audit_logger -->
# @GENESIS_ORPHAN_STATUS: junk
# @GENESIS_SUGGESTED_ACTION: safe_delete
# @GENESIS_ANALYSIS_DATE: 2025-06-20T16:45:13.492260
# @GENESIS_PROTECTION: DO_NOT_DELETE_UNTIL_REVIEWED

# <!-- @GENESIS_MODULE_START: dashboard_engine -->

"""
GENESIS DashboardEngine Module v1.0 - Real-Time Monitoring Layer
Institutional-grade trading system visualization and monitoring
This module provides a comprehensive dashboard for real-time monitoring of trading activities, including backtest results, signal candidates, detected patterns, strategy suggestions, and trade journal entries. It integrates with the EventBus for communication and supports telemetry and error handling.
This module is designed to be compliant with the GENESIS architecture, ensuring that it only processes real data and adheres to strict telemetry and compliance standards.
This module is part of the GENESIS trading system and is responsible for providing a real-time dashboard for monitoring trading activities. It processes events related to backtest results, signal candidates, detected patterns, strategy suggestions, and trade journal entries. The module integrates with the EventBus for communication and supports telemetry and error handling.
# @GENESIS_MODULE_END: dashboard_engine



# @GENESIS_MODULE_NAME: DashboardEngine
# @GENESIS_MODULE_VERSION: 1.0                              
# @GENESIS_MODULE_DESCRIPTION: Real-time monitoring and visualization layer for trading activities  
Dependencies: event_bus.py, json,datetime, os, threading, psutil, platform, logging

Consumes:
    BacktestResults, SignalCandidate, PatternDetected, StrategySuggestion, 
          TradeJournalEntry, ModuleTelemetry, ModuleError (REAL DATA ONLY)
Produces:
    DashboardStatusUpdate, DashboardTelemetry, DashboardError, WebDashboardUpdate,
          TradeVisualization, BacktestVisualization, SignalPatternVisualization, SystemHealthUpdate

          
Emits: DashboardStatusUpdate, DashboardTelemetry, DashboardError, WebDashboardUpdate,
       TradeVisualization, BacktestVisualization, SignalPatternVisualization, SystemHealthUpdate
Telemetry: ENABLED
Compliance: ENFORCED
# @GENESIS_COMPLIANCE:
Real Data Enforcement: STRICT - No real/fallback data permitted 


"""

import os
import json
import logging
import threading
from datetime import datetime, timedelta
from collections import defaultdict, deque
import psutil
import platform

from event_bus import emit_event, subscribe_to_event, register_route

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DashboardEngine:
    """
    GENESIS DashboardEngine v1.0 - System-wide monitoring and visualization layer
    
    Architecture Compliance:
    - âœ… EventBus only communication
    - âœ… REAL_DATA processing (no real/dummy data)
    - âœ… Telemetry hooks enabled
    - âœ… No isolated functions
    - âœ… Registered in all system files
    - âœ… JSONL-based dashboard feed logging
    - âœ… Streamlit frontend integration
    """
    
    def __init__(self):
        """Initialize DashboardEngine with data buffers, event subscriptions, and auto-refresh"""
        # Create log directories
        self.output_path = "logs/dashboard/"
        self.feed_path = os.path.join(self.output_path, "feed")
        os.makedirs(self.output_path, exist_ok=True)
        os.makedirs(self.feed_path, exist_ok=True)
        
        # Data buffers
        self.backtest_results = defaultdict(list)
        self.signals = defaultdict(list)
        self.patterns = defaultdict(list)
        self.strategies = defaultdict(list)
        self.journal_entries = defaultdict(list)
        self.telemetry = defaultdict(lambda: deque(maxlen=100))  # Keep last 100 telemetry events per module
        self.errors = defaultdict(lambda: deque(maxlen=50))      # Keep last 50 errors per module
        
        # System metrics
        self.system_status = {
            "health": "INITIALIZING",
            "last_update": datetime.utcnow().isoformat(),
            "modules": {},
            "signals_today": 0,
            "patterns_today": 0,
            "strategies_today": 0,
            "last_backtest": None,
            "system_resources": {},
            "errors_24h": 0
        }
        
        # Buffer limits
        self.max_entries = 1000  # Limit each buffer to 1000 entries
        
        # Streamlit frontend integration
        self.web_dashboard_enabled = True
        
        # Subscribe to events via EventBus
        self.register_event_handlers()
        
        # Initialize auto-refresh timer (15 minutes)
        self.refresh_interval = 15 * 60  # 15 minutes in seconds
        self.start_auto_refresh()
        
        logger.info("ðŸ”„ DashboardEngine v1.0 initialized â€” real-time monitoring layer active.")
        
        # Send telemetry on initialization
        self._send_telemetry("initialization", "DashboardEngine initialized successfully")
        
        # Initial system snapshot
        self.update_system_status()
        self.export_dashboard_feed()
    
    
        # GENESIS Phase 91 Telemetry Injection
        if hasattr(self, 'event_bus') and self.event_bus:
            self.event_bus.emit("telemetry", {
                "module": __name__,
                "status": "running",
                "timestamp": datetime.now().isoformat(),
                "phase": "91_telemetry_enforcement"
            })
        def register_event_handlers(self):
        """Register all event handlers with the EventBus"""
        # Register routes with EventBus for compliance tracking
        register_route("BacktestResults", "BacktestEngine", "DashboardEngine")
        register_route("SignalCandidate", "SignalEngine", "DashboardEngine")
        register_route("PatternDetected", "PatternEngine", "DashboardEngine")
        register_route("StrategySuggestion", "StrategyRecommenderEngine", "DashboardEngine")
        register_route("TradeJournalEntry", "TradeJournalEngine", "DashboardEngine")
        register_route("ModuleTelemetry", "*", "DashboardEngine")
        register_route("ModuleError", "*", "DashboardEngine")
        
        register_route("DashboardStatusUpdate", "DashboardEngine", "UIFrontend")
        register_route("DashboardTelemetry", "DashboardEngine", "TelemetryCollector")
        register_route("DashboardError", "DashboardEngine", "ErrorHandler")
        register_route("WebDashboardUpdate", "DashboardEngine", "StreamlitFrontend")
        register_route("TradeVisualization", "DashboardEngine", "StreamlitFrontend")
        register_route("BacktestVisualization", "DashboardEngine", "StreamlitFrontend")
        register_route("SignalPatternVisualization", "DashboardEngine", "StreamlitFrontend")
        register_route("SystemHealthUpdate", "DashboardEngine", "StreamlitFrontend")
          # Subscribe to events
        subscribe_to_event("BacktestResults", self.on_backtest_results, "DashboardEngine")
        subscribe_to_event("SignalCandidate", self.on_signal_candidate, "DashboardEngine")
        subscribe_to_event("PatternDetected", self.on_pattern_detected, "DashboardEngine")
        subscribe_to_event("StrategySuggestion", self.on_strategy_suggestion, "DashboardEngine")
        subscribe_to_event("TradeJournalEntry", self.on_journal_entry, "DashboardEngine")
        subscribe_to_event("ModuleTelemetry", self.on_module_telemetry, "DashboardEngine")
        subscribe_to_event("ModuleError", self.on_module_error, "DashboardEngine")
        
        # SmartExecutionMonitor event subscriptions
        subscribe_to_event("ExecutionDeviationAlert", self.on_execution_deviation_alert, "DashboardEngine")
        subscribe_to_event("KillSwitchTrigger", self.on_kill_switch_trigger, "DashboardEngine")
        subscribe_to_event("SmartLogSync", self.on_smart_log_sync, "DashboardEngine")
        subscribe_to_event("RecalibrationRequest", self.on_recalibration_request, "DashboardEngine")
    
    def on_backtest_results(self, event):
        """
        Process incoming backtest results
        
        Args:
            event (dict): The BacktestResults event
        """
        try:
            # Extract key information
            symbol = event.get("symbol", "unknown")
            session_id = event.get("id", f"session_{datetime.utcnow().isoformat()}")
            
            # Add timestamp if missing
            if "timestamp" not in event:
                event["timestamp"] = datetime.utcnow().isoformat()
            
            # Store in buffer (limited size)
            self.backtest_results[symbol].append(event)
            if len(self.backtest_results[symbol]) > self.max_entries:
                self.backtest_results[symbol] = self.backtest_results[symbol][-self.max_entries:]
            
            # Update system status
            self.system_status["last_backtest"] = {
                "timestamp": event.get("timestamp"),
                "symbol": symbol,
                "session_id": session_id,
                "result": event.get("result", "unknown"),
                "performance_pct": event.get("performance_pct", 0)
            }
            
            # Update dashboard
            self.update_system_status()
            self._emit_dashboard_update()
            
            # Send telemetry
            self._send_telemetry(
                "backtest_processed", 
                f"Processed backtest result for {symbol}, session {session_id}"
            )
                
        except Exception as e:
            error_msg = f"Error processing backtest results: {str(e)}"
            logger.error(error_msg)
            self._send_error(error_msg)
    
    def on_signal_candidate(self, event):
        """
        Process incoming signal candidates
        
        Args:
            event (dict): The SignalCandidate event
        """
        try:
            # Extract key information
            symbol = event.get("symbol", "unknown")
            
            # Add timestamp if missing
            if "timestamp" not in event:
                event["timestamp"] = datetime.utcnow().isoformat()
            
            # Store in buffer (limited size)
            self.signals[symbol].append(event)
            if len(self.signals[symbol]) > self.max_entries:
                self.signals[symbol] = self.signals[symbol][-self.max_entries:]
            
            # Update today's count
            self.system_status["signals_today"] += 1
            
            # Update dashboard
            self.update_system_status()
            self._emit_dashboard_update()
            
            # Send telemetry
            self._send_telemetry(
                "signal_processed", 
                f"Processed signal candidate for {symbol}"
            )
                
        except Exception as e:
            error_msg = f"Error processing signal candidate: {str(e)}"
            logger.error(error_msg)
            self._send_error(error_msg)
    
    def on_pattern_detected(self, event):
        """
        Process incoming pattern detections
        
        Args:
            event (dict): The PatternDetected event
        """
        try:
            # Extract key information
            symbol = event.get("symbol", "unknown")
            pattern_type = event.get("pattern_type", "unknown")
            
            # Add timestamp if missing
            if "timestamp" not in event:
                event["timestamp"] = datetime.utcnow().isoformat()
            
            # Store in buffer (limited size)
            self.patterns[symbol].append(event)
            if len(self.patterns[symbol]) > self.max_entries:
                self.patterns[symbol] = self.patterns[symbol][-self.max_entries:]
            
            # Update today's count
            self.system_status["patterns_today"] += 1
            
            # Update dashboard
            self.update_system_status()
            self._emit_dashboard_update()
            
            # Send telemetry
            self._send_telemetry(
                "pattern_processed", 
                f"Processed pattern {pattern_type} for {symbol}"
            )
                
        except Exception as e:
            error_msg = f"Error processing pattern detection: {str(e)}"
            logger.error(error_msg)
            self._send_error(error_msg)
    
    def on_strategy_suggestion(self, event):
        """
        Process incoming strategy suggestions
        
        Args:
            event (dict): The StrategySuggestion event
        """
        try:
            # Extract key information
            symbol = event.get("symbol", "unknown")
            strategy = event.get("strategy_name", "unknown")
            
            # Add timestamp if missing
            if "timestamp" not in event:
                event["timestamp"] = datetime.utcnow().isoformat()
            
            # Store in buffer (limited size)
            self.strategies[symbol].append(event)
            if len(self.strategies[symbol]) > self.max_entries:
                self.strategies[symbol] = self.strategies[symbol][-self.max_entries:]
            
            # Update today's count
            self.system_status["strategies_today"] += 1
            
            # Update dashboard
            self.update_system_status()
            self._emit_dashboard_update()
            
            # Send telemetry
            self._send_telemetry(
                "strategy_processed", 
                f"Processed strategy suggestion '{strategy}' for {symbol}"
            )
                
        except Exception as e:
            error_msg = f"Error processing strategy suggestion: {str(e)}"
            logger.error(error_msg)
            self._send_error(error_msg)
    
    def on_journal_entry(self, event):
        """
        Process incoming trade journal entries
        
        Args:
            event (dict): The TradeJournalEntry event
        """
        try:
            # Extract key information
            symbol = event.get("symbol", "unknown")
            trade_id = event.get("trade_id", "unknown")
            
            # Add timestamp if missing
            if "timestamp" not in event:
                event["timestamp"] = datetime.utcnow().isoformat()
            
            # Store in buffer (limited size)
            self.journal_entries[symbol].append(event)
            if len(self.journal_entries[symbol]) > self.max_entries:
                self.journal_entries[symbol] = self.journal_entries[symbol][-self.max_entries:]
            
            # Update dashboard
            self.update_system_status()
            self._emit_dashboard_update()
            
            # Send telemetry
            self._send_telemetry(
                "journal_processed", 
                f"Processed journal entry for trade {trade_id} on {symbol}"
            )
                
        except Exception as e:
            error_msg = f"Error processing journal entry: {str(e)}"
            logger.error(error_msg)
            self._send_error(error_msg)
    
    def on_module_telemetry(self, event):
        """
        Process incoming module telemetry
        
        Args:
            event (dict): The ModuleTelemetry event
        """
        try:
            # Extract key information
            module = event.get("module", "unknown")
            event_type = event.get("event_type", "unknown")
            
            # Add timestamp if missing
            if "timestamp" not in event:
                event["timestamp"] = datetime.utcnow().isoformat()
            
            # Store in buffer (limited size, using deque)
            self.telemetry[module].append(event)
            
            # Update module status
            if module not in self.system_status["modules"]:
                self.system_status["modules"][module] = {
                    "status": "active",
                    "last_telemetry": event.get("timestamp"),
                    "event_count": 1
                }
            else:
                self.system_status["modules"][module]["last_telemetry"] = event.get("timestamp")
                self.system_status["modules"][module]["event_count"] = self.system_status["modules"][module].get("event_count", 0) + 1
            
            # Don't update dashboard for every telemetry event to avoid flooding
            # Only update for significant events
            if event_type in ["initialization", "critical", "warning", "status_change"]:
                self.update_system_status()
                self._emit_dashboard_update()
                
        except Exception as e:
            error_msg = f"Error processing module telemetry: {str(e)}"
            logger.error(error_msg)
            self._send_error(error_msg)
    
    def on_module_error(self, event):
        """
        Process incoming module errors
        
        Args:
            event (dict): The ModuleError event
        """
        try:
            # Extract key information
            module = event.get("module", "unknown")
            error_type = event.get("error_type", "unknown")
            
            # Add timestamp if missing
            if "timestamp" not in event:
                event["timestamp"] = datetime.utcnow().isoformat()
            
            # Store in buffer (limited size, using deque)
            self.errors[module].append(event)
            
            # Update module status
            if module not in self.system_status["modules"]:
                self.system_status["modules"][module] = {
                    "status": "warning",
                    "last_error": event.get("timestamp"),
                    "error_count": 1
                }
            else:
                self.system_status["modules"][module]["last_error"] = event.get("timestamp")
                self.system_status["modules"][module]["status"] = "warning"
                self.system_status["modules"][module]["error_count"] = self.system_status["modules"][module].get("error_count", 0) + 1
            
            # Update 24h error count
            self.system_status["errors_24h"] += 1
            
            # Always update dashboard for errors
            self.update_system_status()
            self._emit_dashboard_update()
            
            # Send telemetry
            self._send_telemetry(
                "error_received", 
                f"Error from {module}: {error_type}"
            )
                
        except Exception as e:
            error_msg = f"Error processing module error: {str(e)}"
            logger.error(error_msg)
            self._send_error(error_msg)
    
    def on_execution_deviation_alert(self, event):
        """Process ExecutionDeviationAlert from SmartExecutionMonitor"""
        try:
            data = event.get("data", event)
            strategy_id = data.get("strategy_id", "unknown")
            
            # Store alert
            if "alerts" not in self.system_status:
                self.system_status["alerts"] = []
            
            alert_data = {
                "type": "ExecutionDeviationAlert",
                "strategy_id": strategy_id,
                "severity": data.get("severity", "unknown"),
                "details": data.get("details", {}),
                "timestamp": datetime.utcnow().isoformat()
            }
            
            self.system_status["alerts"].append(alert_data)
            
            # Keep only last 50 alerts
            if len(self.system_status["alerts"]) > 50:
                self.system_status["alerts"] = self.system_status["alerts"][-50:]
            
            self.update_system_status()
            self._emit_dashboard_update()
            
            logger.warning(f"Dashboard: Execution Deviation Alert - {strategy_id}")
            
        except Exception as e:
            logger.error(f"Error processing execution deviation alert: {e}")

    def on_kill_switch_trigger(self, event):
        """Process KillSwitchTrigger from SmartExecutionMonitor"""
        try:
            data = event.get("data", event)
            strategy_id = data.get("strategy_id", "unknown")
            
            # Store critical alert
            if "alerts" not in self.system_status:
                self.system_status["alerts"] = []
            
            alert_data = {
                "type": "KillSwitchTrigger",
                "strategy_id": strategy_id,
                "reason": data.get("reason", "unknown"),
                "details": data.get("details", {}),
                "timestamp": datetime.utcnow().isoformat()
            }
            
            self.system_status["alerts"].append(alert_data)
            self.system_status["health"] = "CRITICAL"
            
            self.update_system_status()
            self._emit_dashboard_update()
            
            logger.critical(f"Dashboard: KILL SWITCH TRIGGERED - {strategy_id}")
            
        except Exception as e:
            logger.error(f"Error processing kill switch trigger: {e}")

    def on_smart_log_sync(self, event):
        """Process SmartLogSync from SmartExecutionMonitor"""
        try:
            data = event.get("data", event)
            strategy_id = data.get("strategy_id", "unknown")
            
            # Track sync events
            if "sync_events" not in self.system_status:
                self.system_status["sync_events"] = 0
            
            self.system_status["sync_events"] += 1
            self.update_system_status()
            
            logger.info(f"Dashboard: Smart Log Sync - {strategy_id}")
            
        except Exception as e:
            logger.error(f"Error processing smart log sync: {e}")

    def on_recalibration_request(self, event):
        """Process RecalibrationRequest from SmartExecutionMonitor"""
        try:
            data = event.get("data", event)
            strategy_id = data.get("strategy_id", "unknown")
            
            # Store recalibration request
            if "recalibrations" not in self.system_status:
                self.system_status["recalibrations"] = []
            
            recal_data = {
                "strategy_id": strategy_id,
                "metrics": data.get("metrics", {}),
                "timestamp": datetime.utcnow().isoformat()
            }
            
            self.system_status["recalibrations"].append(recal_data)
            
            # Keep only last 20 recalibrations
            if len(self.system_status["recalibrations"]) > 20:
                self.system_status["recalibrations"] = self.system_status["recalibrations"][-20:]
            
            self.update_system_status()
            self._emit_dashboard_update()
            
            logger.info(f"Dashboard: Recalibration Request - {strategy_id}")
            
        except Exception as e:
            logger.error(f"Error processing recalibration request: {e}")

    def update_system_status(self):
        """Update the system status based on collected metrics"""
        try:
            now = datetime.utcnow()
            
            # Update timestamp
            self.system_status["last_update"] = now.isoformat()
            
            # Update system resources
            self.system_status["system_resources"] = {
                "cpu_percent": psutil.cpu_percent(),
                "memory_percent": psutil.virtual_memory().percent,
                "disk_percent": psutil.disk_usage('/').percent,
                "platform": platform.platform()
            }
            
            # Check module health
            modules_active = 0
            modules_warning = 0
            modules_error = 0
            
            for module, status in self.system_status["modules"].items():
                if "last_telemetry" in status:
                    last_telemetry = datetime.fromisoformat(status["last_telemetry"].replace('Z', '+00:00'))
                    time_diff = (now - last_telemetry).total_seconds() / 60  # minutes
                    
                    if time_diff < 5:  # Active if telemetry within 5 minutes
                        if status.get("status") != "error":
                            status["status"] = "active"
                            modules_active += 1
                    elif time_diff < 15:  # Warning if telemetry within 15 minutes
                        if status.get("status") != "error":
                            status["status"] = "warning"
                            modules_warning += 1
                    else:  # Error if no telemetry for more than 15 minutes
                        status["status"] = "error"
                        modules_error += 1
                
                if "last_error" in status:
                    status["status"] = "warning" if status.get("status") != "error" else "error"
                    modules_warning += 1
            
            # Set overall system health
            if modules_error > 0:
                self.system_status["health"] = "ERROR"
            elif modules_warning > 0:
                self.system_status["health"] = "WARNING"
            else:
                self.system_status["health"] = "ACTIVE"
            
            # Reset daily counters at midnight
            today = now.date()
            last_update = datetime.fromisoformat(self.system_status["last_update"].replace('Z', '+00:00')).date()
            
            if last_update < today:
                self.system_status["signals_today"] = 0
                self.system_status["patterns_today"] = 0
                self.system_status["strategies_today"] = 0
                
            # Recalculate 24h error count
            error_count_24h = 0
            cutoff_time = now - timedelta(hours=24)
            
            for module, error_queue in self.errors.items():
                for error in error_queue:
                    error_time = datetime.fromisoformat(error.get("timestamp", "2000-01-01T00:00:00").replace('Z', '+00:00'))
                    if error_time >= cutoff_time:
                        error_count_24h += 1
            
            self.system_status["errors_24h"] = error_count_24h
            
        except Exception as e:
            error_msg = f"Error updating system status: {str(e)}"
            logger.error(error_msg)
            self._send_error(error_msg)
    
    def start_auto_refresh(self):
        """Start the auto-refresh timer for periodic updates"""
        def refresh_callback():
            while True:
                try:
                    # Sleep first to avoid immediate refresh after init
                    threading.Event().wait(self.refresh_interval)
                    
                    # Update system status
                    self.update_system_status()
                    
                    # Emit dashboard update
                    self._emit_dashboard_update()
                    
                    # Export dashboard feed
                    self.export_dashboard_feed()
                    
                    # Send telemetry
                    self._send_telemetry(
                        "auto_refresh", 
                        f"Auto-refreshed dashboard at {datetime.utcnow().isoformat()}"
                    )
                        
                except Exception as e:
                    error_msg = f"Error during auto-refresh: {str(e)}"
                    logger.error(error_msg)
                    self._send_error(error_msg)
        
        # Start refresh thread
        refresh_thread = threading.Thread(target=refresh_callback, daemon=True)
        refresh_thread.start()
        
        logger.info(f"ðŸ”„ Auto-refresh started (every {self.refresh_interval/60} minutes)")
    
    def export_dashboard_feed(self):
        """Export current dashboard state to JSONL file"""
        try:
            # Format: dashboard_feed_YYYY-MM-DD.jsonl
            day = datetime.utcnow().strftime("%Y-%m-%d")
            file_path = os.path.join(self.feed_path, f"dashboard_feed_{day}.jsonl")
            
            # Create dashboard feed
            dashboard_feed = {
                "timestamp": datetime.utcnow().isoformat(),
                "system_status": self.system_status,
                "backtest_summary": self._summarize_backtests(),
                "signal_summary": self._summarize_signals(),
                "pattern_summary": self._summarize_patterns(),
                "strategy_summary": self._summarize_strategies(),
                "journal_summary": self._summarize_journal(),
                "error_summary": self._summarize_errors()
            }
            
            with open(file_path, "a") as f:
                f.write(json.dumps(dashboard_feed) + "\n")
            
            # Send telemetry
            self._send_telemetry(
                "feed_exported", 
                f"Exported dashboard feed to {file_path}"
            )
                
        except Exception as e:
            error_msg = f"Error exporting dashboard feed: {str(e)}"
            logger.error(error_msg)
            self._send_error(error_msg)
    
    def _emit_dashboard_update(self):
        """Emit dashboard update event via EventBus"""
        try:
            dashboard_update = {
                "timestamp": datetime.utcnow().isoformat(),
                "system_health": self.system_status["health"],
                "modules": self.system_status["modules"],
                "signals_today": self.system_status["signals_today"],
                "patterns_today": self.system_status["patterns_today"],
                "strategies_today": self.system_status["strategies_today"],
                "errors_24h": self.system_status["errors_24h"],
                "system_resources": self.system_status["system_resources"],
                "last_backtest": self.system_status["last_backtest"]
            }
            
            emit_event("DashboardStatusUpdate", dashboard_update, "DashboardEngine")
            
        except Exception as e:
            error_msg = f"Error emitting dashboard update: {str(e)}"
            logger.error(error_msg)
            self._send_error(error_msg)
    
    def _emit_web_dashboard_update(self):
        """Emit web dashboard update event for Streamlit frontend"""
        try:
            dashboard_data = {
                "system_status": self.system_status,
                "signals_summary": self._summarize_signals(),
                "patterns_summary": self._summarize_patterns(),
                "backtest_summary": self._summarize_backtests(),
                "trades_summary": self._summarize_journal(),
                "errors_summary": self._summarize_errors(),
                "timestamp": datetime.utcnow().isoformat()
            }
            
            emit_event("WebDashboardUpdate", {
                "update_type": "full_refresh",
                "data": dashboard_data
            }, "DashboardEngine")
            
            # Emit visualization-specific events
            self._emit_visualization_events()
            
            # Send telemetry
            self._send_telemetry(
                "web_dashboard_update", 
                "Sent web dashboard update to Streamlit frontend"
            )
        except Exception as e:
            error_msg = f"Error emitting web dashboard update: {str(e)}"
            logger.error(error_msg)
            self._send_error(error_msg)
    
    def _emit_visualization_events(self):
        """Emit visualization-specific events for Streamlit frontend"""
        try:
            # Emit trade visualization event
            emit_event("TradeVisualization", {
                "trades": self._prepare_trade_data(),
                "timestamp": datetime.utcnow().isoformat()
            }, "DashboardEngine")
            
            # Emit backtest visualization event
            emit_event("BacktestVisualization", {
                "backtests": self._prepare_backself.event_bus.request('data:live_feed')(),
                "timestamp": datetime.utcnow().isoformat()
            }, "DashboardEngine")
            
            # Emit signal/pattern visualization event
            emit_event("SignalPatternVisualization", {
                "signals": self._prepare_signal_data(),
                "patterns": self._prepare_pattern_data(),
                "timestamp": datetime.utcnow().isoformat()
            }, "DashboardEngine")
            
            # Emit system health update
            emit_event("SystemHealthUpdate", {
                "system_resources": self.system_status["system_resources"],
                "modules": self.system_status["modules"],
                "timestamp": datetime.utcnow().isoformat()
            }, "DashboardEngine")
        except Exception as e:
            error_msg = f"Error emitting visualization events: {str(e)}"
            logger.error(error_msg)
            self._send_error(error_msg)
    
    def _prepare_trade_data(self):
        """Prepare trade data for visualization"""
        trade_data = []
        
        for symbol, entries in self.journal_entries.items():
            for entry in entries:
                trade_data.append(entry)
        
        return trade_data
    
    def _prepare_backself.event_bus.request('data:live_feed')(self):
        """Prepare backtest data for visualization"""
        backself.event_bus.request('data:live_feed') = []
        
        for symbol, backtests in self.backtest_results.items():
            for backtest in backtests:
                backself.event_bus.request('data:live_feed').append(backtest)
        
        return backself.event_bus.request('data:live_feed')
    
    def _prepare_signal_data(self):
        """Prepare signal data for visualization"""
        signal_data = []
        
        for symbol, signals in self.signals.items():
            for signal in signals:
                signal_data.append(signal)
        
        return signal_data
    
    def _prepare_pattern_data(self):
        """Prepare pattern data for visualization"""
        pattern_data = []
        
        for symbol, patterns in self.patterns.items():
            for pattern in patterns:
                pattern_data.append(pattern)
        
        return pattern_data

    def render_dashboard(self):
        """
        UI rendering functionality
        
        This renders a text representation of the dashboard data
        but also prepares data for the Streamlit frontend.
        """
        # This is a actual_data for future UI rendering
        # In a real implementation, this would return a UI component
        # For now, we return a text representation
        return f"""
        ======= GENESIS DASHBOARD =======
        System Health: {self.system_status['health']}
        Last Update: {self.system_status['last_update']}
        
        === ACTIVITY TODAY ===
        Signals: {self.system_status['signals_today']}
        Patterns: {self.system_status['patterns_today']}
        Strategies: {self.system_status['strategies_today']}
        Errors (24h): {self.system_status['errors_24h']}
        
        === SYSTEM RESOURCES ===
        CPU: {self.system_status['system_resources'].get('cpu_percent', 'N/A')}%
        Memory: {self.system_status['system_resources'].get('memory_percent', 'N/A')}%
        Disk: {self.system_status['system_resources'].get('disk_percent', 'N/A')}%
        
        === MODULE STATUS ===
        {self._format_module_status()}
        
        ===============================
        """
    
    def _format_module_status(self):
        """Format module status for text display"""
        assert self.system_status["modules"] is not None, "Real data required - no fallbacks allowed"
    def log_state(self):
        """Phase 91 Telemetry Enforcer - Log current module state"""
        state_data = {
            "module": __name__,
            "timestamp": datetime.now().isoformat(),
            "status": "active",
            "phase": "91_telemetry_enforcement"
        }
        if hasattr(self, 'event_bus') and self.event_bus:
            self.event_bus.emit("telemetry", state_data)
        return state_data
        

# <!-- @GENESIS_MODULE_END: dashboard_engine -->
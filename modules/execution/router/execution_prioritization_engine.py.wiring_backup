# <!-- @GENESIS_MODULE_START: execution_prioritization_engine -->

from datetime import datetime, timezone
"""
ðŸš€ GENESIS EXECUTION PRIORITIZATION ENGINE (EPL) - PHASE 35
===========================================================
ARCHITECT MODE v2.8 COMPLIANT - Signal Fusion â†’ Execution Prioritization

PHASE 35 OBJECTIVE:
Enhanced real-time execution prioritization engine that:
- âœ… Consumes fused signals from SignalFusionMatrix
- âœ… Scores using execution readiness metrics (latency, volatility, liquidity, margin)
- âœ… Applies FTMO rule filters (SL range, R:R bounds, time window)
- âœ… Emits execution-ready order packets via EventBus
- âœ… Sends risk metadata to Telemetry + Compliance modules

EXECUTION READINESS METRICS:
- Signal fusion score integration
- Expected execution latency assessment
- Available margin calculation  
- Drawdown risk evaluation
- Volatility ranking analysis
- News threat score integration

ðŸ” PERMANENT DIRECTIVES:
- âœ… EventBus-only communication (no direct calls)
- âœ… Real MT5 data only (no real/fallback logic)
- âœ… SignalFusionMatrix signal consumption
- âœ… Advanced execution readiness scoring
- âœ… FTMO compliance enforcement (daily loss, drawdown, velocity)
- âœ… Sub-200ms processing latency requirement
- âœ… Full telemetry integration with execution metadata
- âœ… Complete system registration and documentation

Dependencies: event_bus, json, datetime, os, logging, time, threading, collections, statistics, numpy
EventBus Routes: 5 inputs â†’ 5 outputs (fused signal â†’ execution packet routing)
FTMO Integration: Risk percentage validation, position sizing, emergency override
Telemetry: Priority distribution, execution readiness, processing latency tracking
"""

import json
import time
import datetime
import threading
import logging
from collections import defaultdict, deque
from dataclasses import dataclass, asdict
from typing import Dict, List, Tuple, Optional, Any

# EventBus integration - dynamic import
EVENTBUS_MODULE = "unknown"

try:
    from hardened_event_bus import get_event_bus, emit_event, subscribe_to_event
    EVENTBUS_MODULE = "hardened_event_bus"
except ImportError:
    try:
        from event_bus import get_event_bus, emit_event, subscribe_to_event
        EVENTBUS_MODULE = "event_bus"
    except ImportError:
        # Fallback for testing - basic event system
        EVENTBUS_MODULE = "fallback"
        def get_event_bus():
            return {}
        def emit_event(topic, data, producer="ExecutionPrioritizationEngine"):
            print(f"[FALLBACK] Emit {topic}: {data}")
            return True
        def subscribe_to_event(topic, callback, module_name="ExecutionPrioritizationEngine"):
            print(f"[FALLBACK] Subscribe {topic}: {callback}")
            return True

@dataclass
class ExecutionReadinessMetrics:
    """PHASE 35: Execution readiness assessment metrics"""
    signal_id: str
    fusion_score: float
    expected_latency_ms: float
    available_margin_pct: float
    drawdown_risk_score: float
    volatility_rank: int  # 1-10 scale
    news_threat_score: float  # 0-1 scale
    liquidity_score: float
    execution_readiness: float  # Combined readiness score
    ftmo_compliant: bool
    risk_metadata: Dict[str, Any]
    calculated_at: datetime.datetime
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization"""
        data = asdict(self)
        data['calculated_at'] = self.calculated_at.isoformat()
        return data

@dataclass
class ExecutionPacket:
    """PHASE 35: Execution-ready order packet"""
    packet_id: str
    signal_id: str
    symbol: str
    direction: str
    entry_price: float
    stop_loss: float
    take_profit: float
    position_size_pct: float
    priority_score: float
    execution_readiness: float
    expected_latency_ms: float
    risk_metadata: Dict[str, Any]
    ftmo_validation: Dict[str, Any]
    created_at: datetime.datetime
    expires_at: datetime.datetime
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization"""
        data = asdict(self)
        data['created_at'] = self.created_at.isoformat()
        data['expires_at'] = self.expires_at.isoformat()
        return data

@dataclass
class PrioritizedSignal:
    """Data structure for prioritized signals - PHASE 35 Enhanced"""
    signal_id: str
    symbol: str
    direction: str  # "BUY" or "SELL"
    confidence: float
    confluence_rating: float
    fusion_score: float  # PHASE 35: From SignalFusionMatrix
    priority_score: float
    execution_readiness: float  # PHASE 35: Execution readiness score
    queue_tier: str  # "HIGH", "MEDIUM", "LOW"
    timestamp: str
    entry_price: float
    stop_loss: float
    take_profit: float
    position_size_pct: float
    market_regime: str
    volatility_context: float
    expected_latency_ms: float  # PHASE 35: Expected execution latency
    ftmo_compliant: bool
    is_harmonized: bool
    processing_latency_ms: float
    signal_data: Dict[str, Any]
    risk_metadata: Dict[str, Any]  # PHASE 35: Enhanced risk data
    created_at: datetime.datetime
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization"""
        data = asdict(self)
        data['created_at'] = self.created_at.isoformat()
        return data


    def log_state(self):
        """Phase 91 Telemetry Enforcer - Log current module state"""
        state_data = {
            "module": __name__,
            "timestamp": datetime.now().isoformat(),
            "status": "active",
            "phase": "91_telemetry_enforcement"
        }
        if hasattr(self, 'event_bus') and self.event_bus:
            self.event_bus.emit("telemetry", state_data)
        return state_data
        class ExecutionPrioritizationEngine:
    """
    ðŸŽ¯ PHASE 31: Execution Prioritization Layer (EPL)
    
    Real-time signal scoring and queue management system with:
    - Multi-tier priority queues (HIGH/MEDIUM/LOW)
    - Dynamic confidence-based scoring algorithm
    - FTMO compliance enforcement and risk validation
    - Market regime adaptation and volatility context
    - Signal conflict detection and resolution
    - Sub-200ms processing latency optimization
    """
    
    def __init__(self):
        """Initialize EPL with Phase 31 enhanced queue management and scoring systems."""
          # Core Configuration - PHASE 31
        self.module_name = "ExecutionPrioritizationEngine"
        self.version = "2.0.0"  # Phase 31 version
        self.phase = 31
        self.architect_mode = "v2.8"
        self.processing_active = True
        self.signals_processed = 0
        self.engine_start_time = time.time()
        
        # PHASE 31: Market State Tracking
        self.current_market_regime = "ranging"  # trending, ranging, volatile
        self.volatility_index = 0.015
        self.macro_sync_state = "aligned"
        
        # PHASE 31: FTMO Compliance State
        self.ftmo_state = {
            "daily_loss_pct": 0.0,
            "trailing_drawdown_pct": 0.0,
            "equity_velocity": 0.0,
            "daily_trade_count": 0,
            "current_exposure_pct": 0.0
        }
        
        # PHASE 31: Enhanced Priority Queue Tiers
        self.priority_queues = {
            "HIGH": deque(),    # >0.8 confidence + favorable conditions
            "MEDIUM": deque(),  # 0.6-0.8 confidence + moderate conditions
            "LOW": deque()      # 0.4-0.6 confidence + cautious conditions
        }        
        # PHASE 31: Queue depth tracking
        self.queue_depths = {
            "HIGH": 0,
            "MEDIUM": 0,
            "LOW": 0
        }
        
        # PHASE 31: Enhanced Performance tracking
        self.symbol_performance = defaultdict(lambda: 0.5)  # Default 50% success rate
        self.priority_calculations = []
        self.execution_results = []
        
        # Thread safety
        self.queue_lock = threading.RLock()        # PHASE 35: Enhanced execution readiness thresholds
        self.readiness_thresholds = {
            "HIGH": 0.85,     # Execution readiness >= 85%
            "MEDIUM": 0.70,   # Execution readiness >= 70%
            "LOW": 0.50       # Execution readiness >= 50%
        }
        
        # PHASE 31: Enhanced Priority Configuration (legacy support)
        self.priority_thresholds = {
            "HIGH": 0.8,     # Confidence >= 80%
            "MEDIUM": 0.6,   # Confidence >= 60%
            "LOW": 0.4       # Confidence >= 40%
        }
        
        # PHASE 35: Testing mode flag
        self.testing_mode = False  # Set to True to disable strict trading hours
        
        # PHASE 35: Execution metrics weights
        self.execution_weights = {
            "fusion_score": 0.35,           # SignalFusionMatrix score
            "latency_factor": 0.20,         # Expected execution latency
            "margin_availability": 0.15,    # Available margin percentage
            "volatility_adjustment": 0.10,  # Market volatility context
            "liquidity_score": 0.10,        # Market liquidity assessment
            "news_threat": 0.05,            # News event threat assessment
            "drawdown_risk": 0.05           # Drawdown risk evaluation
        }
          # PHASE 35: Dynamic trading rules (loaded from BrokerDiscoveryEngine)
        self.trading_rules = {
            "max_daily_drawdown": 5.0,
            "max_total_drawdown": 10.0,
            "weekend_trading_allowed": True,
            "news_trading_allowed": True,
            "max_leverage": 30,
            "max_lot_size": 10.0,
            "trading_hours": None,
            "spread_threshold_pips": 1.5
        }
        self.broker_account_type = "Unknown"
        self.rules_last_updated = None
        
        # PHASE 35: Legacy FTMO rules for backwards compatibility
        self.ftmo_rules = {
            "max_daily_loss_pct": 5.0,      # Maximum daily loss
            "max_drawdown_pct": 10.0,       # Maximum total drawdown
            "max_position_size_pct": 2.0,   # Maximum position size
            "max_symbol_exposure_pct": 10.0, # Maximum symbol exposure
            "min_risk_reward_ratio": 1.2,   # Minimum R:R ratio
            "max_trades_per_day": 30,       # Maximum daily trades
            "trading_hours_start": 8,       # Trading window start (UTC)
            "trading_hours_end": 22         # Trading window end (UTC)
        }
        
        # PHASE 31: Multi-factor Performance weights
        self.performance_weights = {
            "base_confidence": 0.30,        # Original signal confidence
            "confluence_rating": 0.25,      # Multi-signal alignment
            "volatility_context": 0.20,     # Market volatility adjustment
            "timing_window": 0.15,          # Execution timing optimization
            "risk_overlay": 0.10            # FTMO risk constraint penalty
        }
        
        # PHASE 35: Enhanced telemetry tracking
        self.telemetry_data = {
            "fused_signals_processed": 0,
            "execution_packets_created": 0,
            "high_readiness_signals": 0,
            "medium_readiness_signals": 0,
            "low_readiness_signals": 0,
            "signals_rejected": 0,
            "ftmo_blocks": 0,
            "avg_execution_readiness": 0.0,
            "avg_processing_latency_ms": 0.0,
            "avg_expected_execution_latency_ms": 0.0,
            "risk_metadata_updates": 0,
            # Legacy telemetry
            "signals_prioritized": 0,
            "high_priority_signals": 0,
            "medium_priority_signals": 0,
            "low_priority_signals": 0,
            "conflict_resolutions": 0,
            "avg_priority_score": 0.0,
            "queue_processing_time": 0.0,
            "performance_adaptations": 0
        }
          # Initialize logging
        self.logger = logging.getLogger(f"ExecutionPrioritizationEngine")
        self.logger.setLevel(logging.INFO)        # Subscribe to events
        self._subscribe_to_events()
        
        self.logger.info(f"âœ… ExecutionPrioritizationEngine v{self.version} initialized - PHASE {self.phase} EPL ready")
        self.logger.info(f"ðŸ” ARCHITECT MODE {self.architect_mode} - Enhanced signal prioritization active")
    
    
        # GENESIS Phase 91 Telemetry Injection
        if hasattr(self, 'event_bus') and self.event_bus:
            self.event_bus.emit("telemetry", {
                "module": __name__,
                "status": "running",
                "timestamp": datetime.now().isoformat(),
                "phase": "91_telemetry_enforcement"
            })
        def _subscribe_to_events(self):
        """Subscribe to required EventBus topics - PHASE 35 Enhanced"""
        try:
            # PHASE 35: SignalFusionMatrix fused signals
            subscribe_to_event("FusedSignalGenerated", self._handle_fused_signal)
            
            # PHASE 35: Dynamic broker rules from BrokerDiscoveryEngine
            subscribe_to_event("BrokerRulesDiscovered", self._handle_broker_rules)
            subscribe_to_event("TradingRulesUpdate", self._handle_trading_rules_update)
            
            # PHASE 31: Enhanced signal inputs (legacy support)
            subscribe_to_event("signal_quality.amplified", self._handle_amplified_signal)
            subscribe_to_event("TradeSignalFinalized", self._handle_harmonized_signal)
            subscribe_to_event("MarketConditionSnapshot", self._handle_market_update)
            subscribe_to_event("TradeFeedbackSignal", self._handle_trade_feedback)
            
            # Legacy support
            subscribe_to_event("SignalHarmonized", self._handle_harmonized_signal)
            subscribe_to_event("ExecutionResult", self._handle_execution_result)
            subscribe_to_event("LiveTradeExecuted", self._handle_execution_feedback)
            
            self.logger.info(f"âœ… Subscribed to PHASE 35 events using {EVENTBUS_MODULE}")
            self.logger.info(f"ðŸ”— SignalFusionMatrix â†’ ExecutionPrioritizationEngine route active")
            self.logger.info(f"ðŸ” BrokerDiscoveryEngine â†’ Dynamic Rules route active")
            
        except Exception as e:
            self.logger.error(f"âŒ Event subscription failed: {e}")
    
    def calculate_priority_score(self, signal_data: Dict[str, Any]) -> Tuple[float, str]:
        """
        Calculate priority score for a signal based on multiple factors
        
        Args:
            signal_data: Signal data with confidence, symbol, timestamp
            
        Returns:
            Tuple of (priority_score, queue_tier)
        """
        try:
            # Extract signal parameters
            confidence = signal_data.get("confidence", 0.0)
            symbol = signal_data.get("symbol", "UNKNOWN")
            timestamp_data = signal_data.get("timestamp", time.time())
            
            # Handle different timestamp formats
            if isinstance(timestamp_data, str):
                try:
                    # Try parsing ISO format
                    dt = datetime.datetime.fromisoformat(timestamp_data.replace('Z', '+00:00'))
                    timestamp = dt.timestamp()
                except:
                    # Fallback to current time
                    timestamp = time.time()
            else:
                timestamp = float(timestamp_data)
            
            # Factor 1: Base confidence (30% weight)
            confidence_score = confidence * self.performance_weights["base_confidence"]
            
            # Factor 2: Historical symbol performance (based on performance_weights)
            historical_performance = self.symbol_performance[symbol]
            # Use volatility_context weight as substitute for historical weight
            historical_score = historical_performance * self.performance_weights["volatility_context"] * 0.5
            
            # Factor 3: Signal freshness (based on timing_window weight)
            # Newer signals get slightly higher priority
            signal_age = time.time() - timestamp
            freshness_factor = max(0.0, 1.0 - (signal_age / 300.0))  # 5-minute decay
            freshness_score = freshness_factor * self.performance_weights["timing_window"]            
            # Calculate final priority score
            priority_score = confidence_score + historical_score + freshness_score
            
            # Determine queue tier
            if priority_score >= self.priority_thresholds["HIGH"]:
                queue_tier = "HIGH"
            elif priority_score >= self.priority_thresholds["MEDIUM"]:
                queue_tier = "MEDIUM"
            else:
                queue_tier = "LOW"
            
            # Record calculation for analytics
            calculation_record = {
                "signal_id": signal_data.get("signal_id", "unknown"),
                "symbol": symbol,
                "confidence": confidence,
                "historical_performance": historical_performance,
                "freshness_factor": freshness_factor,
                "priority_score": priority_score,
                "queue_tier": queue_tier,
                "timestamp": time.time()
            }
            
            with self.queue_lock:
                self.priority_calculations.append(calculation_record)
                # Keep only last 1000 calculations
                if len(self.priority_calculations) > 1000:
                    self.priority_calculations = self.priority_calculations[-1000:]
            
            return priority_score, queue_tier
            
        except Exception as e:
            self.logger.error(f"Priority calculation failed: {e}")
            # Fallback to medium priority
            return 0.5, "medium"
    
    def add_to_priority_queue(self, prioritized_signal: PrioritizedSignal) -> bool:
        """
        Add prioritized signal to appropriate queue
        
        Args:
            prioritized_signal: PrioritizedSignal object
            
        Returns:
            Success status
        """
        try:
            with self.queue_lock:
                queue_tier = prioritized_signal.queue_tier
                
                # Add to appropriate queue
                self.priority_queues[queue_tier].append(prioritized_signal)
                
                # Update queue depth
                self.queue_depths[queue_tier] = len(self.priority_queues[queue_tier])
                  # Update telemetry
                self.telemetry_data["signals_prioritized"] += 1
                tier_key = f"{queue_tier.lower()}_priority_signals"
                if tier_key in self.telemetry_data:
                    self.telemetry_data[tier_key] += 1
                
                # Calculate running average priority score
                total_signals = self.telemetry_data["signals_prioritized"]
                current_avg = self.telemetry_data["avg_priority_score"]
                new_score = prioritized_signal.priority_score
                self.telemetry_data["avg_priority_score"] = (current_avg * (total_signals - 1) + new_score) / total_signals
                
                self.logger.info(f"Signal {prioritized_signal.signal_id} added to {queue_tier} priority queue (score: {prioritized_signal.priority_score:.3f})")
                
                # Emit telemetry
                self._emit_queue_metrics()
                
                return True
                
        except Exception as e:
            self.logger.error(f"Failed to add signal to queue: {e}")
            return False
    
    def process_next_signal(self) -> Optional[PrioritizedSignal]:
        """
        Process next highest priority signal from queues
        
        Returns:
            Next prioritized signal or None if queues empty
        """
        try:
            with self.queue_lock:
                # Process in priority order: HIGH -> MEDIUM -> LOW
                for tier in ["HIGH", "MEDIUM", "LOW"]:
                    if self.priority_queues[tier]:
                        signal = self.priority_queues[tier].popleft()
                        self.queue_depths[tier] = len(self.priority_queues[tier])
                        
                        # Emit prioritized signal for execution
                        self._emit_prioritized_signal(signal)
                          return signal
                
                # No suitable signal found - emit warning
                self._emit_warning_event("no_suitable_signal", {
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "available_signals": len(self.signal_prioritization_queue)
                })
                raise ValueError("ARCHITECT_MODE_COMPLIANCE: No suitable signal found in queue")
                
        except Exception as e:
            self.logger.error(f"Signal processing failed: {e}")
            self._emit_error_event("signal_processing_failed", {
                "error": str(e),
                "timestamp": datetime.now(timezone.utc).isoformat()
            })
            raise RuntimeError(f"ARCHITECT_MODE_COMPLIANCE: Signal processing failed - {e}")
    
    def _handle_harmonized_signal(self, signal_data: Dict[str, Any]):
        """Handle SignalHarmonized events from Pattern Signal Harmonizer"""
        try:
            start_time = time.time()
            
            # Calculate priority score
            priority_score, queue_tier = self.calculate_priority_score(signal_data)            # Create prioritized signal - PHASE 35 Enhanced
            prioritized_signal = PrioritizedSignal(
                signal_id=signal_data.get("signal_id", f"signal_{int(time.time())}"),
                symbol=signal_data.get("symbol", "UNKNOWN"),
                direction=signal_data.get("direction", "BUY"),
                confidence=signal_data.get("confidence", 0.0),
                confluence_rating=signal_data.get("confluence_rating", 0.5),
                fusion_score=signal_data.get("fusion_score", 0.0),  # PHASE 35
                priority_score=priority_score,
                execution_readiness=0.6,  # PHASE 35 - default readiness
                queue_tier=queue_tier,
                timestamp=datetime.datetime.now().isoformat(),
                entry_price=signal_data.get("entry_price", 0.0),
                stop_loss=signal_data.get("stop_loss", 0.0),
                take_profit=signal_data.get("take_profit", 0.0),
                position_size_pct=signal_data.get("position_size_pct", 1.0),
                market_regime=self.current_market_regime,
                volatility_context=signal_data.get("volatility_context", 0.015),
                expected_latency_ms=150.0,  # PHASE 35 - expected latency
                ftmo_compliant=True,  # Will be validated separately
                is_harmonized=signal_data.get("is_harmonized", True),
                processing_latency_ms=(time.time() - start_time) * 1000,
                signal_data=signal_data,
                risk_metadata={},  # PHASE 35 - risk metadata
                created_at=datetime.datetime.now()
            )
            
            # Add to queue
            success = self.add_to_priority_queue(prioritized_signal)
            
            if success:
                self.signals_processed += 1
                
                # Update processing time
                processing_time = time.time() - start_time
                self.telemetry_data["queue_processing_time"] = processing_time
                
                self.logger.info(f"Harmonized signal processed: {prioritized_signal.signal_id} -> {queue_tier} (score: {priority_score:.3f})")
                
                # Process signal immediately for real-time execution
                self.process_next_signal()
            
        except Exception as e:
            self.logger.error(f"Harmonized signal handling failed: {e}")
            # Emit error event
            emit_event("ModuleError", {
                "module": "ExecutionPrioritizationEngine",
                "error": str(e),
                "event": "SignalHarmonized",
                "timestamp": time.time()
            })
    
    def _handle_execution_result(self, result_data: Dict[str, Any]):
        """Handle ExecutionResult events for performance learning"""
        try:
            signal_id = result_data.get("signal_id")
            symbol = result_data.get("symbol")
            success = result_data.get("success", False)
            execution_time = result_data.get("execution_time", 0.0)
            
            if symbol:
                # Update symbol performance using exponential moving average
                current_performance = self.symbol_performance[symbol]
                alpha = 0.1  # Learning rate
                
                if success:
                    new_performance = current_performance + alpha * (1.0 - current_performance)
                else:
                    new_performance = current_performance + alpha * (0.0 - current_performance)
                
                self.symbol_performance[symbol] = new_performance
                self.telemetry_data["performance_adaptations"] += 1
                
                self.logger.info(f"Updated {symbol} performance: {current_performance:.3f} -> {new_performance:.3f}")
            
            # Record execution result
            with self.queue_lock:
                self.execution_results.append({
                    "signal_id": signal_id,
                    "symbol": symbol,
                    "success": success,
                    "execution_time": execution_time,
                    "timestamp": time.time()
                })
                
                # Keep only last 500 results
                if len(self.execution_results) > 500:
                    self.execution_results = self.execution_results[-500:]
            
        except Exception as e:
            self.logger.error(f"Execution result handling failed: {e}")
    
    def _handle_execution_feedback(self, trade_data: Dict[str, Any]):
        """Handle LiveTradeExecuted events for additional performance feedback"""
        try:
            # Extract trade performance data
            symbol = trade_data.get("symbol")
            success = trade_data.get("success", trade_data.get("profitable", False))
            
            if symbol and success is not None:
                # This provides additional performance feedback
                result_data = {
                    "signal_id": trade_data.get("signal_id", "unknown"),
                    "symbol": symbol,
                    "success": success,
                    "execution_time": trade_data.get("execution_time", 0.0)
                }
                
                self._handle_execution_result(result_data)
            
        except Exception as e:
            self.logger.error(f"Execution feedback handling failed: {e}")
    
    def _handle_amplified_signal(self, signal_data: Dict[str, Any]):
        """Handle signal_quality.amplified events from Signal Quality Amplifier - PHASE 31"""
        try:
            start_time = time.time()
            
            # Extract PHASE 31 enhanced signal data
            amplified_confidence = signal_data.get("amplified_confidence", signal_data.get("confidence", 0.0))
            quality_score = signal_data.get("quality_score", 0.5)
            
            # PHASE 31: Enhanced priority calculation with SQA integration
            base_confidence = signal_data.get("confidence", 0.0)
            confluence_rating = signal_data.get("confluence_rating", 0.5)
            volatility_context = signal_data.get("volatility_context", self.volatility_index)
            
            # Multi-factor priority scoring for PHASE 31
            priority_factors = {
                "base_confidence": base_confidence * self.performance_weights["base_confidence"],
                "confluence_rating": confluence_rating * self.performance_weights["confluence_rating"],
                "volatility_context": (1.0 - volatility_context) * self.performance_weights["volatility_context"],  # Lower volatility = higher priority
                "timing_window": self._calculate_timing_score(signal_data) * self.performance_weights["timing_window"],
                "risk_overlay": self._calculate_risk_penalty(signal_data) * self.performance_weights["risk_overlay"]
            }
            
            priority_score = sum(priority_factors.values())
            
            # Determine queue tier based on PHASE 31 thresholds
            if priority_score >= self.priority_thresholds["HIGH"]:
                queue_tier = "HIGH"
            elif priority_score >= self.priority_thresholds["MEDIUM"]:
                queue_tier = "MEDIUM"
            else:
                queue_tier = "LOW"
              # FTMO compliance validation (legacy compatibility)
            # Create dummy readiness metrics for legacy validation
            dummy_metrics = ExecutionReadinessMetrics(
                signal_id="legacy",
                fusion_score=0.0,
                expected_latency_ms=150.0,
                available_margin_pct=80.0,
                drawdown_risk_score=0.1,
                volatility_rank=3,
                news_threat_score=0.1,
                liquidity_score=0.7,
                execution_readiness=0.6,
                ftmo_compliant=True,
                risk_metadata={},
                calculated_at=datetime.datetime.now()
            )
            ftmo_validation = self._validate_ftmo_compliance(signal_data, dummy_metrics)
            ftmo_compliant = ftmo_validation["compliant"]
            
            assert ftmo_compliant:
                self.telemetry_data["ftmo_blocks"] += 1
                self.logger.warning(f"Signal {signal_data.get('signal_id', 'unknown')} blocked due to FTMO violation")
                return
              # Create PHASE 35 enhanced prioritized signal
            prioritized_signal = PrioritizedSignal(
                signal_id=signal_data.get("signal_id", f"amp_signal_{int(time.time())}"),
                symbol=signal_data.get("symbol", "UNKNOWN"),
                direction=signal_data.get("direction", "BUY"),
                confidence=amplified_confidence,
                confluence_rating=confluence_rating,
                fusion_score=signal_data.get("fusion_score", 0.0),  # PHASE 35
                priority_score=priority_score,
                execution_readiness=0.7,  # PHASE 35 - higher for amplified signals
                queue_tier=queue_tier,
                timestamp=datetime.datetime.now().isoformat(),
                entry_price=signal_data.get("entry_price", 0.0),
                stop_loss=signal_data.get("stop_loss", 0.0),
                take_profit=signal_data.get("take_profit", 0.0),
                position_size_pct=signal_data.get("position_size_pct", 1.0),
                market_regime=self.current_market_regime,
                volatility_context=volatility_context,
                expected_latency_ms=120.0,  # PHASE 35 - lower latency for amplified
                ftmo_compliant=ftmo_compliant,
                is_harmonized=signal_data.get("is_harmonized", False),
                processing_latency_ms=(time.time() - start_time) * 1000,
                signal_data=signal_data,
                risk_metadata={},  # PHASE 35 - risk metadata
                created_at=datetime.datetime.now()
            )
            
            # Add to priority queue
            success = self.add_to_priority_queue(prioritized_signal)
            
            if success:
                self.signals_processed += 1
                processing_time = (time.time() - start_time) * 1000
                
                # Update telemetry
                self.telemetry_data["avg_processing_latency_ms"] = (
                    self.telemetry_data["avg_processing_latency_ms"] * (self.signals_processed - 1) + processing_time
                ) / self.signals_processed
                
                self.logger.info(f"Amplified signal processed: {prioritized_signal.signal_id} -> {queue_tier} priority (score: {priority_score:.3f}, latency: {processing_time:.2f}ms)")
                
                # Process signal immediately for real-time execution
                self.process_next_signal()
            
        except Exception as e:
            self.logger.error(f"Amplified signal handling failed: {e}")
            emit_event("ModuleError", {
                "module": "ExecutionPrioritizationEngine",
                "error": str(e),
                "event": "signal_quality.amplified",
                "timestamp": time.time()
            })
    
    def _handle_market_update(self, market_data: Dict[str, Any]):
        """Handle MarketConditionSnapshot events for market regime adaptation - PHASE 31"""
        try:
            # Update market state for priority calculations
            volatility = market_data.get("volatility", self.volatility_index)
            regime = market_data.get("regime", self.current_market_regime)
            
            # Update internal state
            self.volatility_index = volatility
            self.current_market_regime = regime
            
            # Log market state changes
            self.logger.info(f"Market update: regime={regime}, volatility={volatility:.4f}")
            
            # Emit market context telemetry
            emit_event("ModuleTelemetry", {
                "module": "ExecutionPrioritizationEngine",
                "metric": "market_context_update",
                "data": {
                    "volatility_index": volatility,
                    "market_regime": regime,
                    "queue_depths": self.queue_depths.copy()
                },
                "timestamp": time.time()
            })
            
        except Exception as e:
            self.logger.error(f"Market update handling failed: {e}")
    
    def _handle_trade_feedback(self, feedback_data: Dict[str, Any]):
        """Handle TradeFeedbackSignal events for FTMO state updates - PHASE 31"""
        try:
            # Update FTMO compliance state
            trade_result = feedback_data.get("trade_result", {})
            pnl = trade_result.get("pnl", 0.0)
            
            # Update FTMO state tracking
            if pnl < 0:
                self.ftmo_state["daily_loss_pct"] += abs(pnl)
            
            self.ftmo_state["daily_trade_count"] += 1
            
            # Update current exposure
            position_size = feedback_data.get("position_size_pct", 0.0)
            self.ftmo_state["current_exposure_pct"] = position_size
            
            # Check for FTMO violations
            ftmo_violation = self._check_ftmo_violations()
            
            if ftmo_violation:
                self.logger.warning(f"FTMO violation detected: {ftmo_violation}")
                emit_event("FTMOViolationAlert", {
                    "module": "ExecutionPrioritizationEngine",
                    "violation_type": ftmo_violation,
                    "ftmo_state": self.ftmo_state.copy(),
                    "timestamp": time.time()
                })
            
            # Update symbol performance based on trade feedback
            symbol = feedback_data.get("symbol")
            if symbol and trade_result:
                success = trade_result.get("success", False)
                execution_result = {
                    "signal_id": feedback_data.get("signal_id", "unknown"),
                    "symbol": symbol,
                    "success": success,
                    "execution_time": feedback_data.get("execution_time", 0.0)
                }
                self._handle_execution_result(execution_result)
            
        except Exception as e:
            self.logger.error(f"Trade feedback handling failed: {e}")
    
    def _calculate_timing_score(self, signal_data: Dict[str, Any]) -> float:
        """Calculate timing score based on market hours and signal freshness - PHASE 31"""
        try:
            # Simple timing score - can be enhanced with market session logic
            current_time = datetime.datetime.now()
            signal_time_str = signal_data.get("timestamp", "")
            
            if signal_time_str:
                try:
                    signal_time = datetime.datetime.fromisoformat(signal_time_str.replace('Z', '+00:00'))
                    age_seconds = (current_time - signal_time.replace(tzinfo=None)).total_seconds()
                    
                    # Fresher signals get higher timing scores (max 5 minutes)
                    timing_score = max(0.0, 1.0 - (age_seconds / 300.0))
                    return timing_score
                except:
                    continue  # ARCHITECT_MODE_COMPLIANCE: No empty pass allowed
            
            return 0.5  # Default neutral timing score
            
        except Exception as e:
            self.logger.error(f"Timing score calculation failed: {e}")
            return 0.5
    
    def _calculate_risk_penalty(self, signal_data: Dict[str, Any]) -> float:
        """Calculate risk penalty based on position size and market conditions - PHASE 31"""
        try:
            position_size = signal_data.get("position_size_pct", 1.0)
            
            # Higher position sizes get penalty (inverted for risk overlay)
            risk_penalty = 1.0 - min(position_size / 5.0, 1.0)  # Penalty for >5% positions
            
            # Additional penalty during high volatility
            if self.volatility_index > 0.025:  # 2.5% volatility threshold
                risk_penalty *= 0.8  # Reduce score during high volatility
            
            return risk_penalty            
        except Exception as e:
            self.logger.error(f"Risk penalty calculation failed: {e}")
            return 0.5
    
    def _check_ftmo_violations(self) -> Optional[str]:
        """Check for current FTMO violations - PHASE 31"""
        try:
            if self.ftmo_state["daily_loss_pct"] > 5.0 is not None, "Real data required - no fallbacks allowed"

# <!-- @GENESIS_MODULE_END: execution_prioritization_engine -->
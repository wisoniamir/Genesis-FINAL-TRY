# <!-- @GENESIS_MODULE_START: validate_phase92b_completion -->

from event_bus import EventBus
#!/usr/bin/env python3
"""
ğŸ¯ GENESIS PHASE 92B FINAL STATUS VALIDATOR
Comprehensive validation of all Phase 92B deliverables and system status
"""

import json
import os
import logging
from datetime import datetime, timezone

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger('Phase92BValidator')

def validate_phase92b_completion():
    """Validate all Phase 92B deliverables and system status"""
    
    print("ğŸ” GENESIS PHASE 92B COMPLETION VALIDATION")
    print("=" * 60)
    
    validation_results = {
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "phase": "92B_core_system_reconnection",
        "status": "validating",
        "modules": {},
        "files": {},
        "tests": {},
        "compliance": {}
    }
    
    # 1. Validate Core Modules
    print("\nğŸ“¦ VALIDATING CORE MODULES:")
    core_modules = {
        "mt5_sync_adapter.py": "MT5 data synchronization",
        "backtest_engine_simple.py": "Real MT5 backtest engine",
        "live_trade_analyzer.py": "Live position analysis",
        "dashboard_linkage_patch.py": "GUI button integration"
    }
    
    for module, description in core_modules.items():
        exists = os.path.exists(module)
        if exists:
            size = os.path.getsize(module)
            print(f"  âœ… {module} ({size:,} bytes) - {description}")
            validation_results["modules"][module] = {"exists": True, "size": size, "description": description}
        else:
            print(f"  âŒ {module} - MISSING")
            validation_results["modules"][module] = {"exists": False, "description": description}
    
    # 2. Validate Output Files
    print("\nğŸ“„ VALIDATING OUTPUT FILES:")
    output_files = {
        "backtest_results.json": "Backtest analysis results",
        "backtest_summary.md": "Human-readable backtest summary",
        "manual_trade_evaluation.json": "Live position analysis",
        "telemetry/backtest_summary.json": "Dashboard backtest integration",
        "telemetry/manual_trade_scores.json": "Dashboard live scores",
        "logs/execution_log.json": "System execution log"
    }
    
    for file_path, description in output_files.items():
        exists = os.path.exists(file_path)
        if exists:
            size = os.path.getsize(file_path)
            # Check if file contains real data (not empty or minimal)
            is_substantive = size > 100  # Basic check for meaningful content
            print(f"  âœ… {file_path} ({size:,} bytes) - {description}")
            validation_results["files"][file_path] = {
                "exists": True, 
                "size": size, 
                "substantive": is_substantive,
                "description": description
            }
        else:
            print(f"  âŒ {file_path} - MISSING")
            validation_results["files"][file_path] = {"exists": False, "description": description}
    
    # 3. Validate Test Results
    print("\nğŸ§ª VALIDATING TEST RESULTS:")
    test_files = {
        "test_backtest_results.json": "Backtest engine test results",
        "system_validation_results.json": "System validation results"
    }
    
    for test_file, description in test_files.items():
        exists = os.path.exists(test_file)
        if exists:
            try:
                with open(test_file, 'r') as f:
                    self.event_bus.request('data:live_feed') = json.load(f)
                    
                # Check for error indicators
                has_errors = "error" in self.event_bus.request('data:live_feed') or any("error" in str(v) for v in self.event_bus.request('data:live_feed').values())
                print(f"  âœ… {test_file} - {description} {'(âŒ ERRORS DETECTED)' if has_errors else '(âœ… CLEAN)'}")
                validation_results["tests"][test_file] = {
                    "exists": True,
                    "has_errors": has_errors,
                    "description": description
                }
            except Exception as e:
                print(f"  âš ï¸ {test_file} - EXISTS BUT UNREADABLE: {e}")
                validation_results["tests"][test_file] = {
                    "exists": True,
                    "has_errors": True,
                    "error": str(e)
                }
        else:
            print(f"  âŒ {test_file} - MISSING")
            validation_results["tests"][test_file] = {"exists": False, "description": description}
    
    # 4. Validate System Status Files
    print("\nâš™ï¸ VALIDATING SYSTEM STATUS:")
    system_files = {
        "dashboard_lock_state.json": "Dashboard operational state",
        "dashboard_button_status.json": "Button handler status",
        "build_tracker.md": "Build progress tracking",
        "PHASE_92B_COMPLETION_REPORT.md": "Phase completion documentation"
    }
    
    for sys_file, description in system_files.items():
        exists = os.path.exists(sys_file)
        if exists:
            size = os.path.getsize(sys_file)
            print(f"  âœ… {sys_file} ({size:,} bytes) - {description}")
            validation_results["compliance"][sys_file] = {
                "exists": True,
                "size": size,
                "description": description
            }
        else:
            print(f"  âŒ {sys_file} - MISSING")
            validation_results["compliance"][sys_file] = {"exists": False, "description": description}
    
    # 5. Overall Assessment
    print("\nğŸ“Š PHASE 92B COMPLETION ASSESSMENT:")
    
    total_modules = len(core_modules)
    working_modules = sum(1 for m in validation_results["modules"].values() if m.get("exists", False))
    
    total_outputs = len(output_files)
    existing_outputs = sum(1 for f in validation_results["files"].values() if f.get("exists", False))
    
    total_tests = len(test_files)
    passing_tests = sum(1 for t in validation_results["tests"].values() 
                       if t.get("exists", False) and not t.get("has_errors", True))
    
    total_compliance = len(system_files)
    compliant_files = sum(1 for c in validation_results["compliance"].values() if c.get("exists", False))
    
    print(f"  ğŸ“¦ Core Modules: {working_modules}/{total_modules} ({working_modules/total_modules:.1%})")
    print(f"  ğŸ“„ Output Files: {existing_outputs}/{total_outputs} ({existing_outputs/total_outputs:.1%})")
    print(f"  ğŸ§ª Tests: {passing_tests}/{total_tests} ({passing_tests/total_tests:.1%})")
    print(f"  âš™ï¸ Compliance: {compliant_files}/{total_compliance} ({compliant_files/total_compliance:.1%})")
    
    # Calculate overall completion score
    overall_score = (
        (working_modules/total_modules) * 0.4 +
        (existing_outputs/total_outputs) * 0.3 +
        (passing_tests/total_tests) * 0.2 +
        (compliant_files/total_compliance) * 0.1
    )
    
    validation_results["overall_score"] = overall_score
    validation_results["completion_percentage"] = overall_score * 100
    
    print(f"\nğŸ¯ OVERALL COMPLETION SCORE: {overall_score:.1%}")
    
    if overall_score >= 0.95:
        status = "âœ… EXCELLENT - PHASE 92B FULLY COMPLETE"
        validation_results["status"] = "completed_excellent"
    elif overall_score >= 0.85:
        status = "âœ… GOOD - PHASE 92B SUBSTANTIALLY COMPLETE"
        validation_results["status"] = "completed_good"
    elif overall_score >= 0.70:
        status = "âš ï¸ PARTIAL - PHASE 92B MOSTLY COMPLETE"
        validation_results["status"] = "partial_completion"
    else:
        status = "âŒ INCOMPLETE - PHASE 92B NEEDS MORE WORK"
        validation_results["status"] = "incomplete"
    
    print(f"\nğŸ† PHASE 92B STATUS: {status}")
    
    # 6. Next Steps Recommendation
    print(f"\nğŸ”® NEXT STEPS:")
    if overall_score >= 0.90:
        print("  âœ… System ready for Phase 92C advanced analytics integration")
        print("  âœ… All core functionality operational with real MT5 data")
        print("  âœ… Dashboard fully connected and responsive")
    else:
        print("  âš ï¸ Address missing components before proceeding to Phase 92C")
        print("  âš ï¸ Ensure all tests are passing")
        print("  âš ï¸ Verify real data integration is complete")
    
    # Save validation results
    with open("phase_92b_validation_results.json", 'w') as f:
        json.dump(validation_results, f, indent=2)
    
    print(f"\nğŸ’¾ Validation results saved to: phase_92b_validation_results.json")
    
    return validation_results

def main():
    """Run Phase 92B completion validation"""
    try:
        results = validate_phase92b_completion()
        
        print(f"\n" + "=" * 60)
        print(f"ğŸ‰ GENESIS PHASE 92B VALIDATION COMPLETE")
        print(f"ğŸ“Š Completion Score: {results['completion_percentage']:.1f}%")
        print(f"â° Validation Time: {results['timestamp']}")
        print(f"ğŸš€ Status: {results['status'].upper()}")
        print(f"=" * 60)
        
        return results
        
    except Exception as e:
        logger.error(f"Validation failed: {e}")
        return {"error": str(e), "status": "validation_failed"}

if __name__ == "__main__":
    main()


# <!-- @GENESIS_MODULE_END: validate_phase92b_completion -->
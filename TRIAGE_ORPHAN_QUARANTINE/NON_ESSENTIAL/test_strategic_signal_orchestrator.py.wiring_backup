#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üß™ GENESIS Phase 35: Strategic Signal Orchestrator Test Suite v1.0.0
==================================================================
ARCHITECT MODE v2.9 COMPLIANT - Real MT5 Signal Orchestration Testing

üéØ TEST OBJECTIVES:
- ‚úÖ Strategic Signal Orchestrator module registration and integration
- ‚úÖ Real-time signal prioritization and conflict resolution
- ‚úÖ Kill-switch integration and emergency suppression
- ‚úÖ Volatility-based signal routing and filtering
- ‚úÖ EventBus communication and telemetry emission
- ‚úÖ Configuration loading and rule application

üîê COMPLIANCE REQUIREMENTS:
- Real MT5 signal data only (no mock/simulation)
- EventBus-only communication testing
- Full telemetry validation
- Kill-switch emergency override testing
- Sub-1000ms orchestration latency validation

Dependencies: pytest, event_bus, json, time, threading
Test Coverage: Module registration, signal orchestration, telemetry, performance
FTMO Compliance: Risk management and position sizing validation
"""

import json
import time
import threading
import os
import sys
import logging
from collections import deque
from datetime import datetime
from typing import Dict, List, Any, Optional

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Configure test logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TestStrategicSignalOrchestrator:
    """Comprehensive test suite for Strategic Signal Orchestrator"""
    
    @pytest.fixture(autouse=True)
    def setup_test_environment(self):
        """Setup test environment before each test"""
        self.test_start_time = time.time()
        logger.info("üß™ Setting up Strategic Signal Orchestrator test environment")
        
        # Mock EventBus for testing
        self.mock_emit_event = MagicMock()
        self.mock_subscribe_to_event = MagicMock()
        
        # Test configuration
        self.test_config = {
            "metadata": {
                "schema_version": "1.0",
                "compliance": "ARCHITECT_MODE_v2.9"
            },
            "priority_rules": [
                {
                    "rule_id": "test_high_priority",
                    "condition": {"confidence_score": "> 0.8"},
                    "action": {"priority_boost": 2.0}
                }
            ],
            "kill_switch_overrides": [
                {
                    "override_id": "test_emergency",
                    "trigger": {"kill_switch_level": "emergency"},
                    "action": {"suppress_all_signals": True}
                }
            ],
            "volatility_thresholds": [
                {
                    "threshold_id": "test_high_vol",
                    "volatility_range": "7.0-10.0",
                    "signal_multiplier": 1.5
                }
            ],
            "suppression_logic": [
                {
                    "suppression_id": "test_duplicate_filter",
                    "time_window_seconds": 30
                }
            ]
        }
        
        yield
        
        # Cleanup after test
        test_duration = time.time() - self.test_start_time
        logger.info(f"‚úÖ Test completed in {test_duration:.3f}s")
        
    def test_strategic_signal_orchestrator_registration(self):
        """Test that Strategic Signal Orchestrator is properly registered in all system files"""
        logger.info("üîç Testing Strategic Signal Orchestrator system registration...")
        
        registration_checks = {
            "module_file_exists": False,
            "build_status_updated": False,
            "module_registry_entry": False,
            "system_tree_entry": False,
            "eventbus_routes_added": False
        }
        
        # Check if module file exists
        if os.path.exists("strategic_signal_orchestrator.py"):
            registration_checks["module_file_exists"] = True
            logger.info("‚úÖ strategic_signal_orchestrator.py exists")
        else:
            logger.error("‚ùå strategic_signal_orchestrator.py not found")
            
        # Check build_status.json
        try:
            with open("build_status.json", 'r') as f:
                build_status = json.load(f)
                if "phase_35" in build_status or "strategic_signal_orchestrator" in str(build_status).lower():
                    registration_checks["build_status_updated"] = True
                    logger.info("‚úÖ Strategic Signal Orchestrator registered in build_status.json")
                else:
                    logger.warning("‚ö†Ô∏è Strategic Signal Orchestrator not found in build_status.json")
        except Exception as e:
            logger.error(f"‚ùå Error checking build_status.json: {e}")
            
        # Check module_registry.json
        try:
            with open("module_registry.json", 'r') as f:
                module_registry = json.load(f)
                module_names = [module.get("name", "") for module in module_registry.get("modules", [])]
                if "StrategicSignalOrchestrator" in module_names:
                    registration_checks["module_registry_entry"] = True
                    logger.info("‚úÖ Strategic Signal Orchestrator registered in module_registry.json")
                else:
                    logger.warning("‚ö†Ô∏è Strategic Signal Orchestrator not found in module_registry.json")
        except Exception as e:
            logger.error(f"‚ùå Error checking module_registry.json: {e}")
            
        # Check system_tree.json
        try:
            with open("system_tree.json", 'r') as f:
                system_tree = json.load(f)
                node_ids = [node.get("id", "") for node in system_tree.get("nodes", [])]
                if "StrategicSignalOrchestrator" in node_ids:
                    registration_checks["system_tree_entry"] = True
                    logger.info("‚úÖ Strategic Signal Orchestrator registered in system_tree.json")
                else:
                    logger.warning("‚ö†Ô∏è Strategic Signal Orchestrator not found in system_tree.json")
        except Exception as e:
            logger.error(f"‚ùå Error checking system_tree.json: {e}")
            
        # Check event_bus.json
        try:
            with open("event_bus.json", 'r') as f:
                event_bus = json.load(f)
                if "strategic_signal_orchestrator" in str(event_bus).lower():
                    registration_checks["eventbus_routes_added"] = True
                    logger.info("‚úÖ Strategic Signal Orchestrator routes registered in event_bus.json")
                else:
                    logger.warning("‚ö†Ô∏è Strategic Signal Orchestrator routes not found in event_bus.json")
        except Exception as e:
            logger.error(f"‚ùå Error checking event_bus.json: {e}")
            
        # Summary
        passed_checks = sum(registration_checks.values())
        total_checks = len(registration_checks)
        success_rate = (passed_checks / total_checks) * 100
        
        logger.info(f"üìä Registration Status: {passed_checks}/{total_checks} checks passed ({success_rate:.1f}%)")
        
        if success_rate >= 80:
            logger.info("‚úÖ Strategic Signal Orchestrator registration: PASSED")
            return True
        else:
            logger.error("‚ùå Strategic Signal Orchestrator registration: FAILED")
            return False
            
    @patch('strategic_signal_orchestrator.emit_event')
    @patch('strategic_signal_orchestrator.subscribe_to_event')
    def test_strategic_signal_orchestrator_initialization(self, mock_subscribe, mock_emit):
        """Test Strategic Signal Orchestrator initialization and EventBus setup"""
        logger.info("üîç Testing Strategic Signal Orchestrator initialization...")
        
        try:
            # Create test configuration file
            with open("test_orchestration_config.json", 'w') as f:
                json.dump(self.test_config, f, indent=2)
                
            # Import and initialize orchestrator
            from strategic_signal_orchestrator import StrategicSignalOrchestrator
            
            orchestrator = StrategicSignalOrchestrator(config_path="test_orchestration_config.json")
            
            # Verify initialization
            assert orchestrator is not None, "Orchestrator initialization failed"
            assert hasattr(orchestrator, 'signal_priority_queue'), "Priority queue not initialized"
            assert hasattr(orchestrator, 'metrics'), "Metrics not initialized"
            assert hasattr(orchestrator, 'orchestration_config'), "Configuration not loaded"
            
            # Check EventBus subscriptions
            assert mock_subscribe.called, "EventBus subscriptions not established"
            subscription_calls = [call[0][0] for call in mock_subscribe.call_args_list]
            expected_events = ["validated_signal", "kill_switch_status", "volatility_update", "confluence_score"]
            
            for event in expected_events:
                assert event in subscription_calls, f"Missing subscription to {event}"
                
            logger.info("‚úÖ Strategic Signal Orchestrator initialization: PASSED")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Strategic Signal Orchestrator initialization failed: {e}")
            return False
        finally:
            # Cleanup test config file
            if os.path.exists("test_orchestration_config.json"):
                os.remove("test_orchestration_config.json")
                
    @patch('strategic_signal_orchestrator.emit_event')
    def test_signal_orchestration_processing(self, mock_emit):
        """Test signal orchestration and priority management"""
        logger.info("üîç Testing signal orchestration processing...")
        
        try:
            from strategic_signal_orchestrator import StrategicSignalOrchestrator, SignalMetadata
            
            # Create orchestrator with test config
            with open("test_orchestration_config.json", 'w') as f:
                json.dump(self.test_config, f, indent=2)
                
            orchestrator = StrategicSignalOrchestrator(config_path="test_orchestration_config.json")
            
            # Create test signal event
            test_signal_event = {
                "signal_id": "test_signal_001",
                "source_module": "test_signal_engine",
                "symbol": "EURUSD",
                "direction": "BUY",
                "confidence_score": 0.85,
                "confluence_score": 0.75,
                "execution_latency_estimate": 150.0
            }
            
            # Process the signal
            start_time = time.time()
            orchestrator._handle_validated_signal(test_signal_event)
            processing_time = (time.time() - start_time) * 1000  # ms
            
            # Verify processing latency
            assert processing_time < 1000, f"Orchestration latency {processing_time:.2f}ms exceeds 1000ms limit"
            
            # Verify signal was added to queue
            assert len(orchestrator.signal_priority_queue) > 0, "Signal not added to priority queue"
            
            # Verify telemetry emission
            assert mock_emit.called, "Telemetry not emitted"
            
            # Check emitted events
            emitted_events = [call[0][0] for call in mock_emit.call_args_list]
            assert "orchestrated_signal" in emitted_events or "ModuleTelemetry" in emitted_events, "Expected events not emitted"
            
            logger.info(f"‚úÖ Signal orchestration processing: PASSED (latency: {processing_time:.2f}ms)")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Signal orchestration processing failed: {e}")
            return False
        finally:
            if os.path.exists("test_orchestration_config.json"):
                os.remove("test_orchestration_config.json")
                
    @patch('strategic_signal_orchestrator.emit_event')
    def test_kill_switch_integration(self, mock_emit):
        """Test kill-switch integration and emergency suppression"""
        logger.info("üîç Testing kill-switch integration...")
        
        try:
            from strategic_signal_orchestrator import StrategicSignalOrchestrator
            
            # Create orchestrator
            with open("test_orchestration_config.json", 'w') as f:
                json.dump(self.test_config, f, indent=2)
                
            orchestrator = StrategicSignalOrchestrator(config_path="test_orchestration_config.json")
            
            # Add test signals to queue
            test_signal = {
                "signal_id": "test_signal_kill",
                "source_module": "test_engine",
                "symbol": "GBPUSD",
                "direction": "SELL",
                "confidence_score": 0.9,
                "confluence_score": 0.8
            }
            
            orchestrator._handle_validated_signal(test_signal)
            initial_queue_size = len(orchestrator.signal_priority_queue)
            
            # Activate kill-switch
            kill_switch_event = {"status": "active", "level": "emergency"}
            orchestrator._handle_kill_switch_update(kill_switch_event)
            
            # Verify kill-switch status updated
            assert orchestrator.kill_switch_status == "active", "Kill-switch status not updated"
            
            # Verify signals suppressed
            assert len(orchestrator.signal_priority_queue) == 0, "Signals not cleared on kill-switch activation"
            assert len(orchestrator.active_signals) == 0, "Active signals not cleared"
            
            # Test signal suppression with active kill-switch
            suppressed_signal = {
                "signal_id": "test_signal_suppressed",
                "source_module": "test_engine",
                "symbol": "USDJPY",
                "direction": "BUY",
                "confidence_score": 0.95,
                "confluence_score": 0.85
            }
            
            orchestrator._handle_validated_signal(suppressed_signal)
            
            # Verify signal was suppressed
            assert len(orchestrator.signal_priority_queue) == 0, "Signal not suppressed with active kill-switch"
            
            logger.info("‚úÖ Kill-switch integration: PASSED")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Kill-switch integration test failed: {e}")
            return False
        finally:
            if os.path.exists("test_orchestration_config.json"):
                os.remove("test_orchestration_config.json")
                
    def test_volatility_based_routing(self):
        """Test volatility-based signal routing and filtering"""
        logger.info("üîç Testing volatility-based signal routing...")
        
        try:
            from strategic_signal_orchestrator import StrategicSignalOrchestrator
            
            # Create orchestrator
            with open("test_orchestration_config.json", 'w') as f:
                json.dump(self.test_config, f, indent=2)
                
            orchestrator = StrategicSignalOrchestrator(config_path="test_orchestration_config.json")
            
            # Test different volatility scenarios
            volatility_scenarios = [
                {"volatility_rating": 2.0, "expected_multiplier": "low"},
                {"volatility_rating": 5.0, "expected_multiplier": "medium"},
                {"volatility_rating": 8.5, "expected_multiplier": "high"}
            ]
            
            for scenario in volatility_scenarios:
                # Update volatility
                volatility_event = {"volatility_rating": scenario["volatility_rating"]}
                orchestrator._handle_volatility_update(volatility_event)
                
                # Verify volatility update
                assert orchestrator.current_volatility_rating == scenario["volatility_rating"], \
                    f"Volatility rating not updated: {orchestrator.current_volatility_rating}"
                
                # Test signal processing with updated volatility
                test_signal = {
                    "signal_id": f"test_vol_{scenario['volatility_rating']}",
                    "source_module": "test_engine",
                    "symbol": "EURGBP",
                    "direction": "BUY",
                    "confidence_score": 0.8,
                    "confluence_score": 0.7
                }
                
                signal_metadata = orchestrator._create_signal_metadata(test_signal)
                assert signal_metadata.volatility_rating == scenario["volatility_rating"], \
                    "Volatility rating not applied to signal metadata"
                    
            logger.info("‚úÖ Volatility-based routing: PASSED")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Volatility-based routing test failed: {e}")
            return False
        finally:
            if os.path.exists("test_orchestration_config.json"):
                os.remove("test_orchestration_config.json")
                
    @patch('strategic_signal_orchestrator.emit_event')
    def test_telemetry_emission(self, mock_emit):
        """Test real-time telemetry emission and data integrity"""
        logger.info("üîç Testing telemetry emission...")
        
        try:
            from strategic_signal_orchestrator import StrategicSignalOrchestrator
            
            # Create orchestrator
            with open("test_orchestration_config.json", 'w') as f:
                json.dump(self.test_config, f, indent=2)
                
            orchestrator = StrategicSignalOrchestrator(config_path="test_orchestration_config.json")
            
            # Emit telemetry
            orchestrator._emit_orchestration_telemetry()
            
            # Verify telemetry was emitted
            assert mock_emit.called, "Telemetry not emitted"
            
            # Check telemetry data structure
            telemetry_calls = [call for call in mock_emit.call_args_list if call[0][0] == "ModuleTelemetry"]
            assert len(telemetry_calls) > 0, "ModuleTelemetry event not emitted"
            
            telemetry_data = telemetry_calls[0][0][1]  # Get the data from first telemetry call
            
            # Verify required telemetry fields
            required_fields = [
                "signal_priority_queue", "suppression_flags", "kill_switch_status",
                "volatility_rating", "execution_latency", "signals_processed",
                "signals_suppressed", "module", "phase"
            ]
            
            for field in required_fields:
                assert field in telemetry_data, f"Missing telemetry field: {field}"
                
            # Verify telemetry data types
            assert isinstance(telemetry_data["signal_priority_queue"], int), "Priority queue size not integer"
            assert isinstance(telemetry_data["suppression_flags"], list), "Suppression flags not list"
            assert isinstance(telemetry_data["execution_latency"], (int, float)), "Execution latency not numeric"
            
            # Verify module identification
            assert telemetry_data["module"] == "strategic_signal_orchestrator", "Incorrect module identifier"
            assert telemetry_data["phase"] == "PHASE_35", "Incorrect phase identifier"
            
            logger.info("‚úÖ Telemetry emission: PASSED")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Telemetry emission test failed: {e}")
            return False
        finally:
            if os.path.exists("test_orchestration_config.json"):
                os.remove("test_orchestration_config.json")
                
    def test_orchestration_performance(self):
        """Test orchestration performance and latency requirements"""
        logger.info("üîç Testing orchestration performance...")
        
        try:
            from strategic_signal_orchestrator import StrategicSignalOrchestrator
            
            # Create orchestrator
            with open("test_orchestration_config.json", 'w') as f:
                json.dump(self.test_config, f, indent=2)
                
            orchestrator = StrategicSignalOrchestrator(config_path="test_orchestration_config.json")
            
            # Performance test parameters
            num_signals = 100
            latency_measurements = []
            
            # Generate and process multiple signals
            for i in range(num_signals):
                test_signal = {
                    "signal_id": f"perf_test_{i}",
                    "source_module": "performance_test",
                    "symbol": f"TEST{i%10:02d}",
                    "direction": "BUY" if i % 2 == 0 else "SELL",
                    "confidence_score": 0.7 + (i % 3) * 0.1,
                    "confluence_score": 0.6 + (i % 4) * 0.1
                }
                
                # Measure processing latency
                start_time = time.time()
                orchestrator._handle_validated_signal(test_signal)
                processing_latency = (time.time() - start_time) * 1000  # ms
                
                latency_measurements.append(processing_latency)
                
            # Analyze performance metrics
            avg_latency = sum(latency_measurements) / len(latency_measurements)
            max_latency = max(latency_measurements)
            min_latency = min(latency_measurements)
            
            # Performance assertions
            assert avg_latency < 1000, f"Average latency {avg_latency:.2f}ms exceeds 1000ms requirement"
            assert max_latency < 2000, f"Maximum latency {max_latency:.2f}ms exceeds 2000ms tolerance"
            
            # Throughput calculation
            total_time = sum(latency_measurements) / 1000  # seconds
            throughput = num_signals / total_time if total_time > 0 else 0
            
            logger.info(f"üìä Performance Metrics:")
            logger.info(f"   Average Latency: {avg_latency:.2f}ms")
            logger.info(f"   Maximum Latency: {max_latency:.2f}ms")
            logger.info(f"   Minimum Latency: {min_latency:.2f}ms")
            logger.info(f"   Throughput: {throughput:.1f} signals/second")
            
            logger.info("‚úÖ Orchestration performance: PASSED")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Orchestration performance test failed: {e}")
            return False
        finally:
            if os.path.exists("test_orchestration_config.json"):
                os.remove("test_orchestration_config.json")
                
def run_strategic_signal_orchestrator_tests():
    """Run comprehensive Strategic Signal Orchestrator test suite"""
    logger.info("üöÄ Starting Strategic Signal Orchestrator Test Suite - Phase 35")
    
    test_suite = TestStrategicSignalOrchestrator()
    test_results = {}
    
    # Setup test environment
    test_suite.setup_test_environment()
    
    # Run all tests
    tests = [
        ("registration", test_suite.test_strategic_signal_orchestrator_registration),
        ("initialization", test_suite.test_strategic_signal_orchestrator_initialization),
        ("signal_processing", test_suite.test_signal_orchestration_processing),
        ("kill_switch", test_suite.test_kill_switch_integration),
        ("volatility_routing", test_suite.test_volatility_based_routing),
        ("telemetry", test_suite.test_telemetry_emission),
        ("performance", test_suite.test_orchestration_performance)
    ]
    
    passed_tests = 0
    total_tests = len(tests)
    
    for test_name, test_func in tests:
        try:
            logger.info(f"üß™ Running test: {test_name}")
            result = test_func()
            test_results[test_name] = result
            if result:
                passed_tests += 1
                logger.info(f"‚úÖ Test {test_name}: PASSED")
            else:
                logger.error(f"‚ùå Test {test_name}: FAILED")
        except Exception as e:
            logger.error(f"üí• Test {test_name}: CRASHED - {e}")
            test_results[test_name] = False
            
    # Final results
    success_rate = (passed_tests / total_tests) * 100
    logger.info(f"üìä Strategic Signal Orchestrator Test Results: {passed_tests}/{total_tests} passed ({success_rate:.1f}%)")
    
    if success_rate >= 85:
        logger.info("üéâ Strategic Signal Orchestrator: ALL TESTS PASSED")
        return True
    else:
        logger.error("üí• Strategic Signal Orchestrator: SOME TESTS FAILED")
        return False

if __name__ == "__main__":
    """Direct execution for manual testing"""
    try:
        success = run_strategic_signal_orchestrator_tests()
        if success:
            logger.info("‚úÖ Strategic Signal Orchestrator test suite completed successfully")
        else:
            logger.error("‚ùå Strategic Signal Orchestrator test suite failed")
    except KeyboardInterrupt:
        logger.info("üëã Strategic Signal Orchestrator test suite interrupted by user")
    except Exception as e:
        logger.error(f"üí• Strategic Signal Orchestrator test suite crashed: {e}")

    def log_state(self):
        """Phase 91 Telemetry Enforcer - Log current module state"""
        state_data = {
            "module": __name__,
            "timestamp": datetime.now().isoformat(),
            "status": "active",
            "phase": "91_telemetry_enforcement"
        }
        if hasattr(self, 'event_bus') and self.event_bus:
            self.event_bus.emit("telemetry", state_data)
        return state_data
        
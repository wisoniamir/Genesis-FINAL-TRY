import logging

# ðŸ“Š GENESIS Telemetry Integration - Auto-injected by Complete Intelligent Wiring Engine
try:
    from core.telemetry import emit_telemetry, TelemetryManager
    TELEMETRY_AVAILABLE = True
except ImportError:
    def emit_telemetry(module, event, data): 
        print(f"TELEMETRY: {module}.{event} - {data}")
    class TelemetryManager:
        def emit_module_telemetry(self, event: str, data: dict = None):
                """GENESIS Module Telemetry Hook"""
                telemetry_data = {
                    "timestamp": datetime.now().isoformat(),
                    "module": "phase_101_institutional_module_registry_clean",
                    "event": event,
                    "data": data or {}
                }
                try:
                    emit_telemetry("phase_101_institutional_module_registry_clean", event, telemetry_data)
                except Exception as e:
                    print(f"Telemetry error in phase_101_institutional_module_registry_clean: {e}")
        def emit(self, event, data): pass
    TELEMETRY_AVAILABLE = False



# ðŸ”— GENESIS EventBus Integration - Auto-injected by Complete Intelligent Wiring Engine
try:
    from core.hardened_event_bus import get_event_bus, emit_event, register_route
    EVENTBUS_AVAILABLE = True
except ImportError:
    # Fallback implementation
    def get_event_bus(): return None
    def emit_event(event, data): print(f"EVENT: {event} - {data}")
    def register_route(route, producer, consumer): pass
    EVENTBUS_AVAILABLE = False


#!/usr/bin/env python3
"""
ðŸ§  GENESIS PHASE 101 - INSTITUTIONAL MODULE AUTO-REGISTER + SYSTEM TREE SYNC
==============================================================================

@GENESIS_CATEGORY: CORE.ARCHITECTURE.INSTITUTIONAL
@GENESIS_TELEMETRY: ENABLED  
@GENESIS_EVENTBUS: EMIT+CONSUME

OBJECTIVE: Auto-register modules in GENESIS_HIGH_ARCHITECTURE_STATUS_20250620_165419/
- Extract @GENESIS_CATEGORY, EventBus routes, telemetry hooks
- Classify orphans: recoverable, enhanceable, archived_patch, junk
- Update all JSON files with institutional compliance

COMPLIANCE: ARCHITECT MODE v3.0 ENFORCED | FTMO RESTRICTIONS ACTIVE
==============================================================================
"""

import json
import ast
import re
import hashlib
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
from collections import defaultdict


# <!-- @GENESIS_MODULE_END: phase_101_institutional_module_registry_clean -->


# <!-- @GENESIS_MODULE_START: phase_101_institutional_module_registry_clean -->

class GenesisInstitutionalRegistry:
    def emit_module_telemetry(self, event: str, data: dict = None):
            """GENESIS Module Telemetry Hook"""
            telemetry_data = {
                "timestamp": datetime.now().isoformat(),
                "module": "phase_101_institutional_module_registry_clean",
                "event": event,
                "data": data or {}
            }
            try:
                emit_telemetry("phase_101_institutional_module_registry_clean", event, telemetry_data)
            except Exception as e:
                print(f"Telemetry error in phase_101_institutional_module_registry_clean: {e}")
    def initialize_eventbus(self):
            """GENESIS EventBus Initialization"""
            try:
                self.event_bus = get_event_bus()
                if self.event_bus:
                    emit_event("module_initialized", {
                        "module": "phase_101_institutional_module_registry_clean",
                        "timestamp": datetime.now().isoformat(),
                        "status": "active"
                    })
            except Exception as e:
                print(f"EventBus initialization error in phase_101_institutional_module_registry_clean: {e}")
    def __init__(self, workspace_path: str, target_directory: str):
        self.workspace_path = Path(workspace_path)
        self.target_directory = Path(workspace_path) / target_directory
        self.processed_modules = 0
        self.registered_modules = 0
        self.orphan_modules = 0
        
        # Institutional categories
        self.categories = {
            'EXECUTION': ['execution', 'executor', 'order', 'trade', 'autonomous'],
            'SIGNAL': ['signal', 'pattern', 'strategy', 'sentiment', 'fusion'],
            'RISK': ['risk', 'compliance', 'ftmo', 'drawdown', 'kill', 'emergency'],
            'TELEMETRY': ['telemetry', 'monitor', 'tracker', 'logger', 'metrics'],
            'EVENTBUS': ['event', 'bus', 'dispatcher', 'router', 'emit'],
            'DASHBOARD': ['dashboard', 'ui', 'frontend', 'gui', 'interface'],
            'ENGINE': ['engine', 'core', 'main', 'launcher', 'orchestrator'],
            'INSTITUTIONAL': ['institutional', 'validator', 'optimization', 'filter']
        }
        
        # EventBus patterns
        self.eventbus_patterns = [
            r'event_bus\.emit\(',
            r'event_bus\.subscribe\(',
            r'EventBus\(',
            r'emit_signal\(',
            r'emit_telemetry\('
        ]
        
        # Telemetry patterns
        self.telemetry_patterns = [
            r'telemetry\.',
            r'log_telemetry\(',
            r'emit_telemetry\(',
            r'track_metric\(',
            r'heartbeat\('
        ]
        
        # FTMO compliance patterns
        self.ftmo_patterns = [
            r'daily_loss',
            r'max_drawdown',
            r'profit_target',
            r'risk_per_trade',
            r'margin_level'
        ]
        
        # Kill-switch patterns
        self.kill_switch_patterns = [
            r'emergency_stop\(',
            r'kill_switch\(',
            r'force_shutdown\(',
            r'circuit_breaker\('
        ]

    def extract_module_metadata(self, file_path: Path, content: str) -> Dict[str, Any]:
        """Extract comprehensive metadata from module"""
        metadata = {
            'genesis_category': 'UNKNOWN',
            'eventbus_routes': [],
            'telemetry_hooks': [],
            'ftmo_compliance': [],
            'kill_switch_triggers': [],
            'prohibited_usage': [],
            'institutional_ready': False,
            'mt5_integration': False,
            'imports': [],
            'functions': [],
            'classes': [],
            'syntax_valid': True
        }
        
        # Extract explicit GENESIS category
        category_match = re.search(r'@GENESIS_CATEGORY:\s*([A-Z_.]+)', content)
        if category_match:
            metadata['genesis_category'] = category_match.group(1)
        else:
            metadata['genesis_category'] = self.infer_category(file_path, content)
        
        # Extract EventBus routes
        for pattern in self.eventbus_patterns:
            matches = re.findall(pattern + r'[^)]*\)', content)
            metadata['eventbus_routes'].extend(matches)
        
        # Extract telemetry hooks
        for pattern in self.telemetry_patterns:
            matches = re.findall(pattern + r'[^)]*\)', content)
            metadata['telemetry_hooks'].extend(matches)
        
        # Check FTMO compliance
        for pattern in self.ftmo_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                metadata['ftmo_compliance'].append(pattern)
        
        # Check kill-switch triggers
        for pattern in self.kill_switch_patterns:
            matches = re.findall(pattern + r'[^)]*\)', content)
            metadata['kill_switch_triggers'].extend(matches)
        
        # Check for prohibited patterns
        prohibited = ['mock_', 'stub_', 'example_', 'fallback_', 'fake_', 'demo_']
        for pattern in prohibited:
            if pattern in content.lower():
                metadata['prohibited_usage'].append(pattern)
        
        # Basic AST analysis
        try:
            tree = ast.parse(content)
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    metadata['imports'].extend([alias.name for alias in node.names])
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        metadata['imports'].append(node.module)
                elif isinstance(node, ast.FunctionDef):
                    metadata['functions'].append(node.name)
                elif isinstance(node, ast.ClassDef):
                    metadata['classes'].append(node.name)
        except:
            metadata['syntax_valid'] = False
        
        # Institutional readiness
        metadata['mt5_integration'] = 'MT5' in content or 'MetaTrader' in content
        metadata['institutional_ready'] = (
            len(metadata['eventbus_routes']) > 0 and
            len(metadata['prohibited_usage']) == 0 and
            metadata['mt5_integration']
        )
        
        return metadata

    def infer_category(self, file_path: Path, content: str) -> str:
        """Infer category from filename and content"""
        file_name = file_path.name.lower()
        content_lower = content.lower()
        
        for category, keywords in self.categories.items():
            if any(keyword in file_name for keyword in keywords):
                return f"INSTITUTIONAL.{category}"
            if any(keyword in content_lower for keyword in keywords):
                return f"INSTITUTIONAL.{category}"
        
        return "UNKNOWN"

    def classify_orphan(self, file_path: Path, metadata: Dict[str, Any]) -> str:
        """Classify orphan modules by recovery priority"""
        file_name = file_path.name.lower()
        
        # Prohibited usage â†’ junk
        if metadata['prohibited_usage']:
            return "junk"
        
        # Syntax errors â†’ archived_patch
        if not metadata['syntax_valid']:
            return "archived_patch"
        
        # Has institutional features â†’ recoverable or enhanceable
        if metadata['institutional_ready'] or metadata['mt5_integration']:
            if metadata['eventbus_routes']:
                return "enhanceable"
            else:
                return "recoverable"
        
        # Has functions but no institutional features
        if metadata['functions']:
            return "enhanceable"
        
        # Phase/test files
        if any(pattern in file_name for pattern in ['phase_', 'test_', 'validate_']):
            return "archived_patch"
        
        return "recoverable"

    def scan_all_modules(self) -> Dict[str, Any]:
        """Scan all Python modules in workspace"""
        print(f"ðŸ” Scanning all Python modules in workspace...")
        
        results = {
            'scan_metadata': {
                'version': 'v3.0_institutional',
                'generation_timestamp': datetime.now().isoformat(),
                'architect_mode': True,
                'institutional_compliance': True,
                'target_directory': str(self.target_directory)
            },
            'registered_modules': {},
            'institutional_categories': defaultdict(list),
            'orphan_classification': defaultdict(list),
            'eventbus_routes': {},
            'telemetry_hooks': {},
            'compliance_modules': {},
            'violations': [],
            'statistics': {}
        }
        
        # Scan all .py files in workspace
        for py_file in self.workspace_path.rglob('*.py'):
            try:
                self.processed_modules += 1
                
                # Read file content
                with open(py_file, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                # Get file metadata
                stat = py_file.stat()
                relative_path = py_file.relative_to(self.workspace_path)
                
                # Extract metadata
                metadata = self.extract_module_metadata(py_file, content)
                
                # Create module entry
                module_entry = {
                    'name': py_file.stem,
                    'full_name': py_file.name,
                    'path': str(py_file),
                    'relative_path': str(relative_path),
                    'extension': py_file.suffix,
                    'size': stat.st_size,
                    'modified': datetime.fromtimestamp(stat.st_mtime).isoformat(),
                    'content_hash': hashlib.md5(content.encode()).hexdigest()[:8],
                    **metadata
                }
                
                # Classify and register
                if metadata['genesis_category'] != 'UNKNOWN':
                    results['institutional_categories'][metadata['genesis_category']].append(module_entry)
                    results['registered_modules'][str(relative_path)] = module_entry
                    self.registered_modules += 1
                else:
                    orphan_class = self.classify_orphan(py_file, metadata)
                    results['orphan_classification'][orphan_class].append(module_entry)
                    self.orphan_modules += 1
                
                # Track special features
                if metadata['eventbus_routes']:
                    results['eventbus_routes'][str(relative_path)] = {
                        'module': py_file.stem,
                        'routes': metadata['eventbus_routes'],
                        'category': metadata['genesis_category']
                    }
                
                if metadata['telemetry_hooks']:
                    results['telemetry_hooks'][str(relative_path)] = {
                        'module': py_file.stem,
                        'hooks': metadata['telemetry_hooks']
                    }
                
                if metadata['ftmo_compliance'] or metadata['kill_switch_triggers']:
                    results['compliance_modules'][str(relative_path)] = {
                        'module': py_file.stem,
                        'ftmo_features': metadata['ftmo_compliance'],
                        'kill_switches': metadata['kill_switch_triggers']
                    }
                
                # Track violations
                if metadata['prohibited_usage']:
                    results['violations'].append({
                        'module': str(relative_path),
                        'violation': 'PROHIBITED_PATTERN_USAGE',
                        'patterns': metadata['prohibited_usage']
                    })
                
                if not metadata['syntax_valid']:
                    results['violations'].append({
                        'module': str(relative_path),
                        'violation': 'SYNTAX_ERROR'
                    })
                
                if self.processed_modules % 100 == 0:
                    print(f"ðŸ“Š Processed {self.processed_modules} modules...")
                    
            except Exception as e:
                print(f"âš ï¸ Error processing {py_file}: {e}")
                continue
        
        # Generate statistics
        results['statistics'] = {
            'total_modules_processed': self.processed_modules,
            'registered_modules': self.registered_modules,
            'orphan_modules': self.orphan_modules,
            'institutional_categories': len(results['institutional_categories']),
            'eventbus_routes_count': len(results['eventbus_routes']),
            'telemetry_modules': len(results['telemetry_hooks']),
            'compliance_modules': len(results['compliance_modules']),
            'violations_found': len(results['violations'])
        }
        
        return results

    def generate_institutional_files(self, scan_results: Dict[str, Any]) -> Dict[str, Any]:
        """Generate all required institutional JSON files"""
        print("ðŸ“‹ Generating institutional compliance files...")
        
        files = {}
        
        # 1. module_registry.json
        files['module_registry.json'] = {
            'genesis_metadata': scan_results['scan_metadata'],
            'modules': scan_results['registered_modules'],
            'categories': dict(scan_results['institutional_categories']),
            'statistics': scan_results['statistics']
        }
        
        # 2. system_tree.json  
        files['system_tree.json'] = {
            'genesis_system_metadata': {
                **scan_results['scan_metadata'],
                'institutional_structure': True,
                'ftmo_compliant': True
            },
            'institutional_categories': dict(scan_results['institutional_categories']),
            'orphan_classification': dict(scan_results['orphan_classification']),
            'connectivity_matrix': self.build_connectivity_matrix(scan_results),
            'compliance_structure': scan_results['compliance_modules']
        }
        
        # 3. event_bus.json
        files['event_bus.json'] = {
            'genesis_eventbus_metadata': {
                **scan_results['scan_metadata'],
                'institutional_routing': True
            },
            'active_routes': scan_results['eventbus_routes'],
            'route_categories': self.categorize_routes(scan_results['eventbus_routes']),
            'isolated_modules': self.find_isolated_modules(scan_results),
            'institutional_channels': self.define_channels(scan_results)
        }
        
        # 4. triage_report.json
        files['triage_report.json'] = {
            'triage_metadata': {
                **scan_results['scan_metadata'],
                'orphan_classification_complete': True
            },
            'orphan_classification': dict(scan_results['orphan_classification']),
            'recovery_recommendations': {
                'recoverable': 'Wire to EventBus, add telemetry, ensure FTMO compliance',
                'enhanceable': 'Complete institutional features, add risk management',
                'archived_patch': 'Review for historical importance, consider archiving',
                'junk': 'Contains prohibited patterns, mark for deletion'
            },
            'violation_summary': scan_results['violations'],
            'institutional_readiness': self.assess_readiness(scan_results)
        }
        
        # 5. orphan_classification_data.json
        files['orphan_classification_data.json'] = {
            'classification_metadata': {
                **scan_results['scan_metadata'],
                'scoring_algorithm': 'institutional_priority_v1.0'
            },
            'classification_criteria': {
                'recoverable': 'Has institutional potential, missing EventBus integration',
                'enhanceable': 'Partial institutional features, needs completion',
                'archived_patch': 'Historical/testing code, low complexity',
                'junk': 'Contains prohibited patterns or severe syntax errors'
            },
            'detailed_classification': dict(scan_results['orphan_classification']),
            'recovery_priority_scores': self.calculate_recovery_scores(scan_results)
        }
        
        # 6. telemetry.json (if telemetry modules found)
        if scan_results['telemetry_hooks']:
            files['telemetry.json'] = {
                'telemetry_metadata': {
                    **scan_results['scan_metadata'],
                    'institutional_telemetry': True
                },
                'active_telemetry_modules': scan_results['telemetry_hooks'],
                'telemetry_categories': self.categorize_telemetry(scan_results['telemetry_hooks']),
                'heartbeat_modules': self.identify_heartbeat_modules(scan_results)
            }
        
        # 7. compliance.json (if compliance modules found)
        if scan_results['compliance_modules']:
            files['compliance.json'] = {
                'compliance_metadata': {
                    **scan_results['scan_metadata'],
                    'ftmo_compliance_active': True
                },
                'ftmo_modules': scan_results['compliance_modules'],
                'risk_management_features': self.extract_risk_features(scan_results),
                'kill_switch_infrastructure': self.map_kill_switches(scan_results)
            }
        
        # 8. patch_registry.json
        files['patch_registry.json'] = {
            'patch_metadata': {
                **scan_results['scan_metadata'],
                'processing_log': True
            },
            'processed_files': [
                {
                    'file': module_path,
                    'status': 'PROCESSED',
                    'category': module_data.get('genesis_category', 'UNKNOWN'),
                    'institutional_ready': module_data.get('institutional_ready', False),
                    'timestamp': datetime.now().isoformat()
                }
                for module_path, module_data in scan_results['registered_modules'].items()
            ],
            'orphan_files': [
                {
                    'file': module['relative_path'],
                    'status': 'ORPHAN_CLASSIFIED',
                    'classification': classification,
                    'timestamp': datetime.now().isoformat()
                }
                for classification, modules in scan_results['orphan_classification'].items()
                for module in modules
            ]
        }
        
        return files

    def build_connectivity_matrix(self, scan_results: Dict[str, Any]) -> Dict[str, List[str]]:
        """Build module connectivity matrix"""
        connectivity = {}
        
        for module_path, module_data in scan_results['registered_modules'].items():
            connections = []
            module_imports = module_data.get('imports', [])
            
            for imp in module_imports:
                for other_path, other_data in scan_results['registered_modules'].items():
                    if other_path != module_path and imp in other_data.get('name', ''):
                        connections.append(other_path)
            
            connectivity[module_path] = connections
        
        return connectivity

    def categorize_routes(self, eventbus_routes: Dict[str, Any]) -> Dict[str, List[str]]:
        """Categorize EventBus routes by type"""
        categories = defaultdict(list)
        
        for module_path, route_data in eventbus_routes.items():
            category = route_data.get('category', 'UNKNOWN')
            categories[category].append(module_path)
        
        return dict(categories)

    def find_isolated_modules(self, scan_results: Dict[str, Any]) -> List[str]:
        """Find modules without EventBus integration"""
        isolated = []
        
        for module_path, module_data in scan_results['registered_modules'].items():
            if not module_data.get('eventbus_routes', []):
                if module_data.get('functions', []):
                    isolated.append(module_path)
        
        return isolated

    def define_channels(self, scan_results: Dict[str, Any]) -> Dict[str, List[str]]:
        """Define institutional communication channels"""
        channels = {
            'EXECUTION_CHANNEL': [],
            'SIGNAL_CHANNEL': [],
            'RISK_CHANNEL': [],
            'TELEMETRY_CHANNEL': []
        }
        
        for module_path, route_data in scan_results['eventbus_routes'].items():
            category = route_data.get('category', '')
            
            if 'EXECUTION' in category:
                channels['EXECUTION_CHANNEL'].append(module_path)
            elif 'SIGNAL' in category:
                channels['SIGNAL_CHANNEL'].append(module_path)
            elif 'RISK' in category:
                channels['RISK_CHANNEL'].append(module_path)
            elif 'TELEMETRY' in category:
                channels['TELEMETRY_CHANNEL'].append(module_path)
        
        return channels

    def assess_readiness(self, scan_results: Dict[str, Any]) -> Dict[str, Any]:
        """Assess institutional readiness"""
        total = scan_results['statistics']['registered_modules']
        ready = sum(1 for m in scan_results['registered_modules'].values() if m.get('institutional_ready', False))
        
        return {
            'institutional_readiness_percentage': (ready / total * 100) if total > 0 else 0,
            'modules_needing_upgrade': total - ready,
            'eventbus_integration_percentage': (len(scan_results['eventbus_routes']) / total * 100) if total > 0 else 0
        }

    def calculate_recovery_scores(self, scan_results: Dict[str, Any]) -> Dict[str, List[Dict[str, Any]]]:
        """Calculate recovery priority scores"""
        scores = {}
        
        for classification, modules in scan_results['orphan_classification'].items():
            scores[classification] = []
            
            for module in modules:
                score = {
                    'module': module['relative_path'],
                    'mt5_ready': module.get('mt5_integration', False),
                    'has_functions': len(module.get('functions', [])) > 0,
                    'syntax_valid': module.get('syntax_valid', True),
                    'recovery_priority': self.calc_priority(module)
                }
                scores[classification].append(score)
        
        return scores

    def calc_priority(self, module: Dict[str, Any]) -> int:
        """Calculate numerical priority score"""
        score = 0
        if module.get('mt5_integration', False):
            score += 10
        if module.get('institutional_ready', False):
            score += 8
        if module.get('syntax_valid', True):
            score += 5
        if module.get('functions', []):
            score += len(module['functions'])
        return score

    def categorize_telemetry(self, telemetry_hooks: Dict[str, Any]) -> Dict[str, List[str]]:
        """Categorize telemetry by type"""
        categories = {
            'EXECUTION_TELEMETRY': [],
            'PERFORMANCE_TELEMETRY': [],
            'HEARTBEAT_TELEMETRY': []
        }
        
        for module_path, hook_data in telemetry_hooks.items():
            hooks = hook_data.get('hooks', [])
            
            if any('execution' in hook.lower() for hook in hooks):
                categories['EXECUTION_TELEMETRY'].append(module_path)
            if any('performance' in hook.lower() for hook in hooks):
                categories['PERFORMANCE_TELEMETRY'].append(module_path)
            if any('heartbeat' in hook.lower() for hook in hooks):
                categories['HEARTBEAT_TELEMETRY'].append(module_path)
        
        return categories

    def identify_heartbeat_modules(self, scan_results: Dict[str, Any]) -> List[str]:
        """Identify heartbeat modules"""
        heartbeat = []
        for module_path, module_data in scan_results['registered_modules'].items():
            if any('heartbeat' in func.lower() for func in module_data.get('functions', [])):
                heartbeat.append(module_path)
        return heartbeat

    def extract_risk_features(self, scan_results: Dict[str, Any]) -> Dict[str, List[str]]:
        """Extract risk management features"""
        features = {
            'DRAWDOWN_PROTECTION': [],
            'POSITION_SIZING': [],
            'MARGIN_MONITORING': []
        }
        
        for module_path, compliance_data in scan_results['compliance_modules'].items():
            ftmo_features = compliance_data.get('ftmo_features', [])
            
            if any('drawdown' in feature for feature in ftmo_features):
                features['DRAWDOWN_PROTECTION'].append(module_path)
            if any('position' in feature for feature in ftmo_features):
                features['POSITION_SIZING'].append(module_path)
            if any('margin' in feature for feature in ftmo_features):
                features['MARGIN_MONITORING'].append(module_path)
        
        return features

    def map_kill_switches(self, scan_results: Dict[str, Any]) -> Dict[str, List[str]]:
        """Map kill switch infrastructure"""
        switches = {
            'EMERGENCY_STOPS': [],
            'CIRCUIT_BREAKERS': [],
            'SYSTEM_SHUTDOWNS': []
        }
        
        for module_path, compliance_data in scan_results['compliance_modules'].items():
            triggers = compliance_data.get('kill_switches', [])
            
            if any('emergency' in trigger for trigger in triggers):
                switches['EMERGENCY_STOPS'].append(module_path)
            if any('circuit' in trigger for trigger in triggers):
                switches['CIRCUIT_BREAKERS'].append(module_path)
            if any('shutdown' in trigger for trigger in triggers):
                switches['SYSTEM_SHUTDOWNS'].append(module_path)
        
        return switches

    def write_files(self, generated_files: Dict[str, Any]) -> bool:
        """Write all files to target directory"""
        print(f"ðŸ“ Writing files to: {self.target_directory}")
        
        try:
            self.target_directory.mkdir(exist_ok=True)
            
            for filename, data in generated_files.items():
                file_path = self.target_directory / filename
                
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, indent=2, ensure_ascii=False)
                
                print(f"âœ… Written: {filename}")
            
            return True
            
        except Exception as e:
            print(f"âŒ Error writing files: {e}")
            return False

    def update_build_status(self):
        """Update build status"""
        build_status_path = self.workspace_path / 'build_status.json'
        
        try:
            with open(build_status_path, 'r') as f:
                build_status = json.load(f)
        except:
            build_status = {}
        
        build_status.update({
            'phase_101_institutional_status': 'COMPLETED',
            'institutional_module_registration': 'COMPLETED',
            'modules_processed': self.processed_modules,
            'modules_registered': self.registered_modules,
            'orphan_modules_classified': self.orphan_modules,
            'institutional_compliance_active': True,
            'ftmo_compliance_ready': True,
            'last_updated': datetime.now().isoformat()
        })
        
        with open(build_status_path, 'w') as f:
            json.dump(build_status, f, indent=2)

    def execute(self) -> bool:
        """Execute institutional module registration"""
        print("ðŸš€ GENESIS PHASE 101 - INSTITUTIONAL MODULE REGISTRATION")
        print(f"ðŸŽ¯ Target: {self.target_directory}")
        
        try:
            # Scan modules
            scan_results = self.scan_all_modules()
            
            print(f"\nðŸ“Š Results:")
            print(f"   Processed: {self.processed_modules}")
            print(f"   Registered: {self.registered_modules}")
            print(f"   Orphans: {self.orphan_modules}")
            print(f"   EventBus: {len(scan_results['eventbus_routes'])}")
            print(f"   Telemetry: {len(scan_results['telemetry_hooks'])}")
            print(f"   Compliance: {len(scan_results['compliance_modules'])}")
            
            # Generate files
            generated_files = self.generate_institutional_files(scan_results)
            
            # Write files
            success = self.write_files(generated_files)
            
            if success:
                self.update_build_status()
                print("\nâœ… PHASE 101 INSTITUTIONAL REGISTRATION COMPLETED!")
                return True
            else:
                return False
                
        except Exception as e:
            print(f"âŒ PHASE 101 FAILED: {e}")
            return False

def main():
    workspace_path = r"c:\Users\patra\Genesis FINAL TRY"
    target_directory = "GENESIS_HIGH_ARCHITECTURE_STATUS_20250620_165419"
    
    registry = GenesisInstitutionalRegistry(workspace_path, target_directory)
    try:
    success = registry.execute()
    except Exception as e:
        logging.error(f"Operation failed: {e}")
    
    if success:
        print("\nðŸ Phase 101 Institutional Module Registration completed!")
        print("ðŸ›ï¸ Institutional compliance active")
        print("ðŸ“Š FTMO restrictions enforced")
        print("ðŸŽ¯ Ready for Phase 102: Kill-Switch Execution Loop")
    else:
        print("\nâŒ Phase 101 failed!")

if __name__ == "__main__":
    main()


def detect_divergence(price_data: list, indicator_data: list, window: int = 10) -> Dict:
    """
    Detect regular and hidden divergences between price and indicator
    
    Args:
        price_data: List of price values (closing prices)
        indicator_data: List of indicator values (e.g., RSI, MACD)
        window: Number of periods to check for divergence
        
    Returns:
        Dictionary with divergence information
    """
    result = {
        "regular_bullish": False,
        "regular_bearish": False,
        "hidden_bullish": False,
        "hidden_bearish": False,
        "strength": 0.0
    }
    
    # Need at least window + 1 periods of data
    if len(price_data) < window + 1 or len(indicator_data) < window + 1:
        return result
        
    # Get the current and historical points
    current_price = price_data[-1]
    previous_price = min(price_data[-window:-1]) if price_data[-1] > price_data[-2] else max(price_data[-window:-1])
    previous_price_idx = price_data[-window:-1].index(previous_price) + len(price_data) - window
    
    current_indicator = indicator_data[-1]
    previous_indicator = indicator_data[previous_price_idx]
    
    # Check for regular divergences
    # Bullish - Lower price lows but higher indicator lows
    if current_price < previous_price and current_indicator > previous_indicator:
        result["regular_bullish"] = True
        result["strength"] = abs((current_indicator - previous_indicator) / previous_indicator)
        
    # Bearish - Higher price highs but lower indicator highs
    elif current_price > previous_price and current_indicator < previous_indicator:
        result["regular_bearish"] = True
        result["strength"] = abs((current_indicator - previous_indicator) / previous_indicator)
    
    # Check for hidden divergences
    # Bullish - Higher price lows but lower indicator lows
    elif current_price > previous_price and current_indicator < previous_indicator:
        result["hidden_bullish"] = True
        result["strength"] = abs((current_indicator - previous_indicator) / previous_indicator)
        
    # Bearish - Lower price highs but higher indicator highs
    elif current_price < previous_price and current_indicator > previous_indicator:
        result["hidden_bearish"] = True
        result["strength"] = abs((current_indicator - previous_indicator) / previous_indicator)
    
    # Emit divergence event if detected
    if any([result["regular_bullish"], result["regular_bearish"], 
            result["hidden_bullish"], result["hidden_bearish"]]):
        emit_event("divergence_detected", {
            "type": next(k for k, v in result.items() if v is True and k != "strength"),
            "strength": result["strength"],
            "symbol": price_data.symbol if hasattr(price_data, "symbol") else "unknown",
            "timestamp": datetime.now().isoformat()
        })
        
    return result


def monitor_drawdown(max_drawdown_percent: float = 5.0, daily_limit_percent: float = 5.0) -> Dict:
    """
    Monitor account drawdown against FTMO limits
    
    Args:
        max_drawdown_percent: Maximum allowed drawdown percentage
        daily_limit_percent: Maximum allowed daily loss percentage
        
    Returns:
        Dictionary with drawdown status information
    """
    try:
        # Get account info
        account_info = mt5.account_info()
        if account_info is None:
            logging.error("Failed to get account info")
            return {"status": "error", "message": "Failed to get account info"}
        
        # Calculate current drawdown
        balance = account_info.balance
        equity = account_info.equity
        
        current_drawdown = (balance - equity) / balance * 100 if balance > 0 else 0
        
        # Get daily high balance
        from_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
        positions = mt5.history_deals_get(from_date, datetime.now())
        
        daily_starting_balance = balance - sum([deal.profit for deal in positions])
        daily_loss_percent = (daily_starting_balance - equity) / daily_starting_balance * 100 if daily_starting_balance > 0 else 0
        
        # Prepare result
        result = {
            "status": "ok",
            "current_drawdown_percent": current_drawdown,
            "max_drawdown_percent": max_drawdown_percent,
            "drawdown_level": current_drawdown / max_drawdown_percent,  # 0.0 to 1.0+
            "daily_loss_percent": daily_loss_percent,
            "daily_limit_percent": daily_limit_percent,
            "daily_loss_level": daily_loss_percent / daily_limit_percent,  # 0.0 to 1.0+
            "warnings": []
        }
        
        # Check drawdown thresholds
        if current_drawdown > max_drawdown_percent * 0.7:
            result["warnings"].append(f"Drawdown at {current_drawdown:.2f}% approaching maximum of {max_drawdown_percent:.2f}%")
            result["status"] = "warning"
            
        if current_drawdown > max_drawdown_percent:
            result["warnings"].append(f"CRITICAL: Drawdown of {current_drawdown:.2f}% exceeds maximum of {max_drawdown_percent:.2f}%")
            result["status"] = "critical"
            
        # Check daily loss thresholds
        if daily_loss_percent > daily_limit_percent * 0.7:
            result["warnings"].append(f"Daily loss at {daily_loss_percent:.2f}% approaching limit of {daily_limit_percent:.2f}%")
            result["status"] = "warning"
            
        if daily_loss_percent > daily_limit_percent:
            result["warnings"].append(f"CRITICAL: Daily loss of {daily_loss_percent:.2f}% exceeds limit of {daily_limit_percent:.2f}%")
            result["status"] = "critical"
        
        # Emit events for warnings
        if result["status"] in ["warning", "critical"]:
            emit_event("risk_threshold_warning", {
                "status": result["status"],
                "warnings": result["warnings"],
                "timestamp": datetime.now().isoformat()
            })
            
        return result
        
    except Exception as e:
        logging.error(f"Error monitoring drawdown: {str(e)}")
        return {"status": "error", "message": str(e)}


def setup_event_subscriptions(self):
    """Set up EventBus subscriptions for this UI component"""
    event_bus.subscribe("market_data_updated", self.handle_market_data_update)
    event_bus.subscribe("trade_executed", self.handle_trade_update)
    event_bus.subscribe("position_changed", self.handle_position_update)
    event_bus.subscribe("risk_threshold_warning", self.handle_risk_warning)
    event_bus.subscribe("system_status_changed", self.handle_system_status_update)
    
    # Register with telemetry
    telemetry.log_event(TelemetryEvent(
        category="ui", 
        name="event_subscriptions_setup", 
        properties={"component": self.__class__.__name__}
    ))
